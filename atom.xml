<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>WhiteTail&#39;s Blog</title>
  
  
  <link href="https://whitetail-o.github.io/atom.xml" rel="self"/>
  
  <link href="https://whitetail-o.github.io/"/>
  <updated>2024-02-29T14:27:10.824Z</updated>
  <id>https://whitetail-o.github.io/</id>
  
  <author>
    <name>WhiteTail</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>常见反射方案总结</title>
    <link href="https://whitetail-o.github.io/2023/11/01/%E5%B8%B8%E8%A7%81%E5%8F%8D%E5%B0%84%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/"/>
    <id>https://whitetail-o.github.io/2023/11/01/%E5%B8%B8%E8%A7%81%E5%8F%8D%E5%B0%84%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/</id>
    <published>2023-11-01T11:24:32.000Z</published>
    <updated>2024-02-29T14:27:10.824Z</updated>
    
    <content type="html"><![CDATA[<h1 id="a-SSR"><a href="#a-SSR" class="headerlink" title="a). SSR"></a>a). SSR</h1><p><strong>优点：</strong> 实现简单，效果较好；</p><p><strong>缺点：</strong></p><ol><li>只能反射屏幕内的物体（屏幕空间算法的通病）；<ul><li><strong>解决方式：</strong>SSR作为主方案，Reflection Probe作为备选项，在SSR失效的地方（如屏幕边缘）对两者做平滑过渡；</li></ul></li><li>需要Ray Marching、频繁读取纹理，可能造成IO瓶颈；</li><li>被反射物只有漫反射的时候才是完全物理正确的；</li><li>Ray Marching次数限制，容易出现物体断裂；<ul><li><strong>解决方法：</strong> 一般会引入<strong>Thickness</strong>来防止物体出现断裂，即ray marching的点除了深度需要大于深度图的深度值，还需要步进的步数小于Thickness；</li></ul></li></ol><p><strong>优化：</strong></p><ol><li>Hierarchical Z；<ul><li>Mip生成高效算法可参考AMD 的 Single Pass Downsampler、Unity中贴图Mip生成（Unity参考的是Nv的<a href="https://github.com/Microsoft/DirectX-Graphics-Samples/blob/master/MiniEngine/Core/Shaders/GenerateMipsCS.hlsli">DirectX-Graphics-Samples/MiniEngine/Core/Shaders/GenerateMipsCS.hlsli at master · microsoft/DirectX-Graphics-Samples (github.com)</a>）。</li></ul></li><li>Dither；</li><li>下采样；</li></ol><h1 id="b-Stochastic-SSR"><a href="#b-Stochastic-SSR" class="headerlink" title="b). Stochastic SSR"></a>b). Stochastic SSR</h1><p><strong>针对情况：</strong> Gloosy物体（对于普通SSR来说，只可通过roughness对反射图进行blur）</p><span id="more"></span><p>整体思路为</p><ol><li><p>将屏幕划分为Tile，进行一次低分辨率的光线步进，评估Tile的重要性，需要多少射线</p></li><li><p>根据<strong>材质粗糙度</strong>判断使用何种的RayMarching</p></li><li><ul><li><strong>昂贵的射线（用于smooth表面）</strong>：借助<strong>Hi-Z</strong>的精确tracing，能得到准确的命中点</li></ul></li><li><ul><li><strong>便宜的射线（用于粗糙表面）</strong>：简单的线性步进，反正之后会粗滤波</li></ul></li><li><p>使用<strong>重要性采样</strong>求RayMarching结果</p></li><li><p>时域空域光线<strong>复用</strong>（本质是计算 brdf/p(x) 的加权和），进行插值滤波</p></li></ol><h2 id="Tile评估"><a href="#Tile评估" class="headerlink" title="Tile评估"></a>Tile评估</h2><ol><li><p>将屏幕划分为多个Tile，对于每一个Tile以1/8分辨率发射射线</p></li><li><p>判断射线（的反射光线）是否击中</p></li><li><ol><li>若所有光线都没命中，则跳过这个Tile的步进</li><li>根据命中的比例和命中信息的差异，判断这个Tile中的像素需要多少个光线</li><li>根据着色点的粗糙度，决定使用何种RayMarching</li></ol></li></ol><h1 id="c-平面反射"><a href="#c-平面反射" class="headerlink" title="c). 平面反射"></a>c). 平面反射</h1><p><strong>缺点：</strong> 可能增加一倍的Draw Call；</p><p><strong>优化手段：</strong> </p><ol><li>剔除影响不明显的小物件；</li><li>如反射物为镜子之类的，可以<strong>结合Portal或者手动计算</strong>去剔除镜子外的物件；</li></ol><h1 id="d-IBL-Relection-Probe"><a href="#d-IBL-Relection-Probe" class="headerlink" title="d). IBL+Relection Probe"></a>d). IBL+Relection Probe</h1><p>略过</p><h1 id="e-Pixel-Projected-Reflection-PPR、SSPR"><a href="#e-Pixel-Projected-Reflection-PPR、SSPR" class="headerlink" title="e). Pixel Projected Reflection(PPR、SSPR)"></a>e). Pixel Projected Reflection(PPR、SSPR)</h1><p>PPR 将整个图像，按照平面的位置进行翻转，在屏幕中进行投影，即可直接得到反射的位置，写入数据并得到一张反射的贴图。</p><p><img src="/2023/11/01/%E5%B8%B8%E8%A7%81%E5%8F%8D%E5%B0%84%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/v2-2eaa5f56c2c7d7ba4db44ca06ad73a42_r.png" alt="v2-2eaa5f56c2c7d7ba4db44ca06ad73a42_r"></p><p>因为场景中的像素，并不能完全保证覆盖整个反射平面，因此往往会产生一些缝隙。UE4中采用一种简单的修复缝隙的方式，是在写入偏移时，将目标像素周围2x2像素直接全部写入偏移值。</p><ol><li>根据深度图，还原场景深度，算出对应点世界坐标，将其投影到平面上，然后将其在屏幕中的偏移量，将偏移量进行编码，写入到 Intermediate Buffer当中；</li><li>从Intermediate Buffer中还原出屏幕空间的偏移，采样屏幕中相应坐标的像素点，将结果写入到反射图中；</li><li>使用反射图，绘制出反射面的效果。</li></ol><hr><p>【参考资料】</p><p><a href="https://zhuanlan.zhihu.com/p/313845354">游戏中的全局光照(五) Reflection Probe、SSR和PPR - 张亚坤的文章 - 知乎</a></p><p><a href="https://zhuanlan.zhihu.com/p/38303394">Unity StochasticSSR-01 - CGBull的文章 - 知乎</a></p><p><a href="https://zhuanlan.zhihu.com/p/605734440">Stochastic Screen Space Reflections论文阅读 - Reuben的文章 - 知乎</a></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;a-SSR&quot;&gt;&lt;a href=&quot;#a-SSR&quot; class=&quot;headerlink&quot; title=&quot;a). SSR&quot;&gt;&lt;/a&gt;a). SSR&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt; 实现简单，效果较好；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;只能反射屏幕内的物体（屏幕空间算法的通病）；&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;解决方式：&lt;/strong&gt;SSR作为主方案，Reflection Probe作为备选项，在SSR失效的地方（如屏幕边缘）对两者做平滑过渡；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;需要Ray Marching、频繁读取纹理，可能造成IO瓶颈；&lt;/li&gt;
&lt;li&gt;被反射物只有漫反射的时候才是完全物理正确的；&lt;/li&gt;
&lt;li&gt;Ray Marching次数限制，容易出现物体断裂；&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;解决方法：&lt;/strong&gt; 一般会引入&lt;strong&gt;Thickness&lt;/strong&gt;来防止物体出现断裂，即ray marching的点除了深度需要大于深度图的深度值，还需要步进的步数小于Thickness；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;优化：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hierarchical Z；&lt;ul&gt;
&lt;li&gt;Mip生成高效算法可参考AMD 的 Single Pass Downsampler、Unity中贴图Mip生成（Unity参考的是Nv的&lt;a href=&quot;https://github.com/Microsoft/DirectX-Graphics-Samples/blob/master/MiniEngine/Core/Shaders/GenerateMipsCS.hlsli&quot;&gt;DirectX-Graphics-Samples/MiniEngine/Core/Shaders/GenerateMipsCS.hlsli at master · microsoft/DirectX-Graphics-Samples (github.com)&lt;/a&gt;）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Dither；&lt;/li&gt;
&lt;li&gt;下采样；&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;b-Stochastic-SSR&quot;&gt;&lt;a href=&quot;#b-Stochastic-SSR&quot; class=&quot;headerlink&quot; title=&quot;b). Stochastic SSR&quot;&gt;&lt;/a&gt;b). Stochastic SSR&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;针对情况：&lt;/strong&gt; Gloosy物体（对于普通SSR来说，只可通过roughness对反射图进行blur）&lt;/p&gt;</summary>
    
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="整理" scheme="https://whitetail-o.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/%E6%95%B4%E7%90%86/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="算法" scheme="https://whitetail-o.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="反射" scheme="https://whitetail-o.github.io/tags/%E5%8F%8D%E5%B0%84/"/>
    
  </entry>
  
  <entry>
    <title>半透明排序总结</title>
    <link href="https://whitetail-o.github.io/2023/08/05/%E5%8D%8A%E9%80%8F%E6%98%8E%E6%8E%92%E5%BA%8F/"/>
    <id>https://whitetail-o.github.io/2023/08/05/%E5%8D%8A%E9%80%8F%E6%98%8E%E6%8E%92%E5%BA%8F/</id>
    <published>2023-08-05T11:24:32.000Z</published>
    <updated>2023-09-03T08:15:24.992Z</updated>
    
    <content type="html"><![CDATA[<h1 id="OIT-Order-Independent-Transparency"><a href="#OIT-Order-Independent-Transparency" class="headerlink" title="OIT(Order Independent Transparency)"></a>OIT(Order Independent Transparency)</h1><h2 id="a-Depth-Peeling-深度剥离"><a href="#a-Depth-Peeling-深度剥离" class="headerlink" title="a). Depth Peeling(深度剥离)"></a>a). Depth Peeling(深度剥离)</h2><p><img src="/2023/08/05/%E5%8D%8A%E9%80%8F%E6%98%8E%E6%8E%92%E5%BA%8F/image-20230817143032060.png" alt="image-20230817143032060"></p><ul><li><strong>优点：</strong><ul><li>遍历都是无序的，也就是说不依赖对物体的排序，所以也就不会出现半透明排序的问题；</li><li>基本无硬件要求</li></ul></li><li><strong>缺点：</strong><ul><li>需要重复多次Pass进行深度剥离，性能开销大；</li></ul></li></ul><h2 id="b-Per-Pixel-Linked-Lists-L-L"><a href="#b-Per-Pixel-Linked-Lists-L-L" class="headerlink" title="b). Per-Pixel Linked Lists(L.L)"></a>b). Per-Pixel Linked Lists(L.L)</h2><p><img src="/2023/08/05/%E5%8D%8A%E9%80%8F%E6%98%8E%E6%8E%92%E5%BA%8F/v2-90dde925b1db37ccedb64859560a1ea1_b.jpg" alt="v2-90dde925b1db37ccedb64859560a1ea1_b"></p><p>在 Pixel Shader 中使用两个可写的纹理（DX11，SM 5.0，UAV），一个屏幕大小的链表头纹理（Start Offset buffer），一个屏幕大小 N 倍的链表节点纹理（ Fragment &amp; Link buffer）。链表头纹理的每个像素存储每个像素链表在节点纹理中的偏移量。</p><p><img src="/2023/08/05/%E5%8D%8A%E9%80%8F%E6%98%8E%E6%8E%92%E5%BA%8F/v2-fd030b2ba60255a3d750c02fc4c272cb_b.jpg" alt="v2-fd030b2ba60255a3d750c02fc4c272cb_b"></p><ul><li><strong>优点：</strong><ul><li>比 Depth Peeling 快了很多。性能开销也比 Depth Peeling 更加节省</li></ul></li></ul><ul><li><strong>缺点：</strong><ul><li>节点纹理具体需要多大无法事先做准确的预估，因此显存的具体消耗不可控（因此多用于离线渲染）</li><li>仅支持DX11、SM5.0以上；</li></ul></li></ul><span id="more"></span><h2 id="c-MLAB-Multi-Layer-Alpha-Blending"><a href="#c-MLAB-Multi-Layer-Alpha-Blending" class="headerlink" title="c). MLAB(Multi-Layer Alpha Blending)"></a>c). MLAB(Multi-Layer Alpha Blending)</h2><p>不像 A-buffer 对每一层片元都进行存储，而是根据深度 z 将片元划分为多组，先对每组的片元混合后，只存储这一组的颜色、透明度和深度，最后对各组按顺序进行混合。</p><p><img src="/2023/08/05/%E5%8D%8A%E9%80%8F%E6%98%8E%E6%8E%92%E5%BA%8F/v2-81773fb4095f15c89300030d4fc36226_b.jpg" alt="v2-81773fb4095f15c89300030d4fc36226_b"></p><ul><li><strong>优点：</strong> 内存大小固定，无L.L的问题；</li><li><strong>缺点：</strong> 对于单个层内，不透明顺序未知，可能造成Artifact；</li></ul><h2 id="d-Weighted-Sum-amp-Weighted-Averaging-WS-amp-WA"><a href="#d-Weighted-Sum-amp-Weighted-Averaging-WS-amp-WA" class="headerlink" title="d). Weighted Sum &amp; Weighted Averaging(WS &amp; WA)"></a>d). Weighted Sum &amp; Weighted Averaging(WS &amp; WA)</h2><p>从传统的“逐层 over”的算法出发，列出其展开式，分析其中不依赖排序的因子，从而进行简化近似。</p><ul><li><strong>优点：</strong>开销小；</li><li><strong>缺点：</strong>在alpha较大时有明显的Artifact；</li></ul><h2 id="e-Adaptive-Transparency"><a href="#e-Adaptive-Transparency" class="headerlink" title="e). Adaptive Transparency"></a>e). Adaptive Transparency</h2><p>Adaptive Transparency，简称 AT，是 Intel 提出的一种 OIT 技术。其核心思想是通过修改经典混合公式本身来改进 Per-Pixel Linked Lists 方法的内存和性能问题。</p><ul><li>引入能见度函数（阶梯下降）；</li></ul><h1 id="其他做法"><a href="#其他做法" class="headerlink" title="其他做法"></a>其他做法</h1><h2 id="a-PreZ（详见百人计划3-5-Early-z和Z-prepass）"><a href="#a-PreZ（详见百人计划3-5-Early-z和Z-prepass）" class="headerlink" title="a). PreZ（详见百人计划3.5 Early-z和Z-prepass）"></a>a). PreZ（详见百人计划3.5 Early-z和Z-prepass）</h2><ul><li><p>第一个Pass（<strong>Z-Prepass</strong>）：仅写入深度；</p></li><li><p>第二个Pass：关闭深度写入，并将深度测试比较符改为等于；</p></li></ul><h2 id="b-顶点顺序"><a href="#b-顶点顺序" class="headerlink" title="b). 顶点顺序"></a>b). 顶点顺序</h2><p>模型保存为OBJ（FBX等），其中每个顶点都有顶点编号，引擎渲染就会按顶点编号的顺序进行渲染。</p><p>对于一个多层的面，可以先创建内部的点，在创建外部的点，保证内部顶点编号小于外部，使其先渲染内部再渲染外部。</p><p><a href="https://zhuanlan.zhihu.com/p/370981866">Shader学习 （19）如何获得正确的半透明排序 - 九猫的文章 - 知乎</a></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;OIT-Order-Independent-Transparency&quot;&gt;&lt;a href=&quot;#OIT-Order-Independent-Transparency&quot; class=&quot;headerlink&quot; title=&quot;OIT(Order Independent Transparency)&quot;&gt;&lt;/a&gt;OIT(Order Independent Transparency)&lt;/h1&gt;&lt;h2 id=&quot;a-Depth-Peeling-深度剥离&quot;&gt;&lt;a href=&quot;#a-Depth-Peeling-深度剥离&quot; class=&quot;headerlink&quot; title=&quot;a). Depth Peeling(深度剥离)&quot;&gt;&lt;/a&gt;a). Depth Peeling(深度剥离)&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/2023/08/05/%E5%8D%8A%E9%80%8F%E6%98%8E%E6%8E%92%E5%BA%8F/image-20230817143032060.png&quot; alt=&quot;image-20230817143032060&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;遍历都是无序的，也就是说不依赖对物体的排序，所以也就不会出现半透明排序的问题；&lt;/li&gt;
&lt;li&gt;基本无硬件要求&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;需要重复多次Pass进行深度剥离，性能开销大；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;b-Per-Pixel-Linked-Lists-L-L&quot;&gt;&lt;a href=&quot;#b-Per-Pixel-Linked-Lists-L-L&quot; class=&quot;headerlink&quot; title=&quot;b). Per-Pixel Linked Lists(L.L)&quot;&gt;&lt;/a&gt;b). Per-Pixel Linked Lists(L.L)&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/2023/08/05/%E5%8D%8A%E9%80%8F%E6%98%8E%E6%8E%92%E5%BA%8F/v2-90dde925b1db37ccedb64859560a1ea1_b.jpg&quot; alt=&quot;v2-90dde925b1db37ccedb64859560a1ea1_b&quot;&gt;&lt;/p&gt;
&lt;p&gt;在 Pixel Shader 中使用两个可写的纹理（DX11，SM 5.0，UAV），一个屏幕大小的链表头纹理（Start Offset buffer），一个屏幕大小 N 倍的链表节点纹理（ Fragment &amp;amp; Link buffer）。链表头纹理的每个像素存储每个像素链表在节点纹理中的偏移量。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/08/05/%E5%8D%8A%E9%80%8F%E6%98%8E%E6%8E%92%E5%BA%8F/v2-fd030b2ba60255a3d750c02fc4c272cb_b.jpg&quot; alt=&quot;v2-fd030b2ba60255a3d750c02fc4c272cb_b&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;比 Depth Peeling 快了很多。性能开销也比 Depth Peeling 更加节省&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;节点纹理具体需要多大无法事先做准确的预估，因此显存的具体消耗不可控（因此多用于离线渲染）&lt;/li&gt;
&lt;li&gt;仅支持DX11、SM5.0以上；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="整理" scheme="https://whitetail-o.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/%E6%95%B4%E7%90%86/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="算法" scheme="https://whitetail-o.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="排序" scheme="https://whitetail-o.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>剔除总结</title>
    <link href="https://whitetail-o.github.io/2023/08/01/%E5%89%94%E9%99%A4%E6%80%BB%E7%BB%93/"/>
    <id>https://whitetail-o.github.io/2023/08/01/%E5%89%94%E9%99%A4%E6%80%BB%E7%BB%93/</id>
    <published>2023-08-01T11:24:32.000Z</published>
    <updated>2023-08-15T12:21:50.672Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0-前言"><a href="#0-前言" class="headerlink" title="0). 前言"></a>0). 前言</h1><p>最近实际做项目的时候发现对自身知识体系做整理的重要性，因此之后会慢慢做一些总结和思维导图，比如剔除、GI（GI方案、反射、AO等）、阴影等。本篇就以剔除开始；</p><h1 id="a-粗粒度剔除（CPU为主）"><a href="#a-粗粒度剔除（CPU为主）" class="headerlink" title="a). 粗粒度剔除（CPU为主）"></a>a). 粗粒度剔除（CPU为主）</h1><p>包括视锥剔除和遮挡剔除，为物体层面。</p><ul><li><strong>发生阶段：CPU应用阶段</strong>；</li></ul><h2 id="a-1-视锥剔除"><a href="#a-1-视锥剔除" class="headerlink" title="a.1). 视锥剔除"></a>a.1). 视锥剔除</h2><p>CPU阶段，物体的AABB包围盒与视锥体6个面分别作判断，剔除包围盒完全处于视锥体外的物体；</p><h2 id="a-2-遮挡剔除"><a href="#a-2-遮挡剔除" class="headerlink" title="a.2). 遮挡剔除"></a>a.2). 遮挡剔除</h2><h3 id="a-2-1-基于Occlusion-Query"><a href="#a-2-1-基于Occlusion-Query" class="headerlink" title="a.2.1). 基于Occlusion Query"></a>a.2.1). 基于Occlusion Query</h3><p>在深度测试时得到待剔除物体相关数据，在应用程序阶段执行。</p><ul><li><strong>Occlusion Query:</strong> 在绘制命令执行前向GPU插入一条查询，在绘制结束后的某个时刻，从GPU将查询结果回读到内存中，得到<strong>某次DrawCall中通过Depth Test的Sample数量</strong>。</li></ul><ul><li><strong>基础做法：</strong> <ol><li>用<strong>Depth-Only</strong>的Pass将场景整体绘制一遍，将物体（的包围盒）深度写入Z-Buffer中；</li><li>使用<strong>物体的包围盒</strong>传入GPU进行<strong>Occlusion Query</strong>。如query得到的sample数大于0，则表示该物体（部分）可见，<strong>剔除掉Sample等于0的物体</strong>；</li><li>执行正常的渲染流程；</li></ol></li></ul><ul><li><strong>缺点：</strong><ol><li>对于复杂场景，Depth-Only也有较大的开销；</li><li>需要将查询结果读回内存（VRAM -&gt; System RAM），需要走PCI-E（IMR架构）；<ul><li>常见的解决方法：回读上一帧Occlusion Query的结果，但可能导致一定的错误（但之后深度测试也可保证画面正确，因此此处出错只是增加了一部分渲染开销）；</li></ul></li></ol></li></ul><h3 id="a-2-2-基于Software-Rasterization（软件剔除）"><a href="#a-2-2-基于Software-Rasterization（软件剔除）" class="headerlink" title="a.2.2). 基于Software Rasterization（软件剔除）"></a>a.2.2). 基于Software Rasterization（软件剔除）</h3><p>最早由Frostbite提出，用于战地3的剔除方案。</p><ul><li>CPU构造一个低分辨率的Z-Buffer，在其中绘制一些场景中较大的遮挡物（美术设定的一些大物体+地形）；</li><li>在构造好的Z-Buffer上，绘制小物体的包围盒，执行类似Occlusion Query的操作进行剔除；</li></ul><p><img src="/2023/08/01/%E5%89%94%E9%99%A4%E6%80%BB%E7%BB%93/image-20230814111511843.png" alt="image-20230814111511843"></p><span id="more"></span><ul><li><strong>相比于基于Occlusion Query的方案：</strong><ul><li><strong>优点：</strong> 纯CPU，集成方便，避免GPU Stall；</li><li><strong>缺点：</strong> 需要美术设定大物体的遮挡，对CPU性能有一定消耗，对于CPU负载大的场景可能造成负优化；</li></ul></li></ul><h2 id="a-3-PVS-Potentially-Visible-Set"><a href="#a-3-PVS-Potentially-Visible-Set" class="headerlink" title="a.3). PVS(Potentially Visible Set)"></a>a.3). PVS(Potentially Visible Set)</h2><p>潜在可见集。PVS的基本思想为：<strong>离线</strong>的把场景划分成许多个块，这些分块的划分可能是均匀的3D网格，也能是自适应大小的3D网格。完成网格划分之后会<strong>计算网格之间的可见性或场景中每个物体对当前网格的可见集用</strong>于之后剔除。</p><p><img src="/2023/08/01/%E5%89%94%E9%99%A4%E6%80%BB%E7%BB%93/image-20230814104133507.png" alt="image-20230814104133507"></p><h2 id="a-4-Portal"><a href="#a-4-Portal" class="headerlink" title="a.4). Portal"></a>a.4). Portal</h2><p><img src="/2023/08/01/%E5%89%94%E9%99%A4%E6%80%BB%E7%BB%93/image-20230814104234702.png" alt="image-20230814104234702"></p><p>这种方式也是将场景划分成Cell，不同的是，烘焙时保存的是每<strong>两个相邻Cell之间的连通性</strong>。</p><p>这样，在运行时，根据摄影机所在的位置的Cell和观察方向，就可以根据Cell间的连通性信息，快速计算出目标物体是否处于可见范围内。Unity自带的遮挡剔除就是使用改方法（<strong>Umbra</strong>）</p><p><strong>优点</strong>（相较于PVS）：可以剔除动态物体，同时提供了些许的静态遮挡物体变化的灵活性（如有扇可以开关的门，当门被打开后，就可以将门两侧的Cell的连通打开）；</p><p><strong>缺点：</strong> 相较于视锥剔除的通用性来说其应用场景更受限制，且需要手工标定；</p><h2 id="a-5-层级剔除（Layer-Culling-Mask）"><a href="#a-5-层级剔除（Layer-Culling-Mask）" class="headerlink" title="a.5). 层级剔除（Layer Culling Mask）"></a>a.5). 层级剔除（Layer Culling Mask）</h2><p>对特定Layer的物体进行选择性剔除</p><h2 id="a-6-距离剔除（LOD同理）"><a href="#a-6-距离剔除（LOD同理）" class="headerlink" title="a.6). 距离剔除（LOD同理）"></a>a.6). 距离剔除（LOD同理）</h2><h1 id="b-硬件剔除（GPU为主）"><a href="#b-硬件剔除（GPU为主）" class="headerlink" title="b). 硬件剔除（GPU为主）"></a>b). 硬件剔除（GPU为主）</h1><h2 id="b-1-Hiz-Culling"><a href="#b-1-Hiz-Culling" class="headerlink" title="b.1). Hiz Culling"></a>b.1). Hiz Culling</h2><ul><li><strong>发生阶段：</strong> 在Geometry Shader得到待剔除物体，在下一Pass的Vertex Shader渲染。剔除可通过Compute Shader实现；</li></ul><ul><li><strong>具体实现：</strong><ol><li>拿到上一帧深度buffer，利用深度buffer构造深度的mipmap，每一层mip中像素的值是上一级mip中对应位置的深度最大值（最远处）；</li><li>将场景物体分为：上一帧已有物体（集合1）、当前帧新增物体（集合2）；</li><li>对于集合1，根据其包围盒在屏幕上的大小取对应级别的Hi-z map图，通过深度比较进行剔除；</li><li>根据3剔除结果绘制集合1，更新z buffer；</li><li>利用新的z buffer建立mipmap深度图，对集合2进行剔除；</li><li>绘制集合2的物体，更新z buffer；</li></ol></li></ul><h2 id="b-2-Clipping-amp-Backface-Culling"><a href="#b-2-Clipping-amp-Backface-Culling" class="headerlink" title="b.2). Clipping &amp; Backface Culling"></a>b.2). Clipping &amp; Backface Culling</h2><p>Clipping处于顶点被转换到NDC后，Backface Culling处于图元装配后根据顶点绕序进行剔除；</p><h2 id="b-3-Early-Z"><a href="#b-3-Early-Z" class="headerlink" title="b.3). Early-Z"></a>b.3). Early-Z</h2><p><strong>发生阶段：</strong> 光栅化后，FS前（Z-Cull后）；</p><p><strong>对象：</strong> 2x2 Pixel Quad；</p><ul><li>Tips：<ol><li><a href="https://www.cnblogs.com/timlly/p/11471507.html">深入GPU硬件架构及运行机制 - 0向往0 - 博客园 (cnblogs.com)</a><ul><li>解释了Early-Z为何需要有Late-Z，除了失效情况，还可解决深度数据冲突（depth data harzard）</li></ul></li></ol></li></ul><h2 id="b-4-Z-Cull"><a href="#b-4-Z-Cull" class="headerlink" title="b.4). Z-Cull"></a>b.4). Z-Cull</h2><p><strong>发生阶段：</strong> 光栅化后，FS前（Early-Z前）；</p><p><strong>对象：</strong>较为粗粒度，为Pixel Tile（如8*8的像素块）</p><h2 id="b-5-Depth-Test"><a href="#b-5-Depth-Test" class="headerlink" title="b.5). Depth Test"></a>b.5). Depth Test</h2><p><strong>发生阶段：</strong> 逐片元操作（输出合并）；</p><p><strong>对象：</strong> fragment；</p><p><a href="https://www.cnblogs.com/timlly/p/11471507.html">深入GPU硬件架构及运行机制 - 0向往0 - 博客园 (cnblogs.com)</a></p><ul><li>解释了Early-Z为何需要有Late-Z，除了失效情况，还可解决深度数据冲突（depth data harzard）</li></ul><h2 id="b-6-HSR-Forward-Pixel-Kill"><a href="#b-6-HSR-Forward-Pixel-Kill" class="headerlink" title="b.6). HSR/Forward Pixel Kill"></a>b.6). HSR/Forward Pixel Kill</h2><p>TBDR架构中，光栅化后，light pass前。</p><ul><li><strong>对比于Early-Z：</strong> early-z需要物体排序，对于不透明物体如果从后往前排序，那early-z无法解决overdraw。而HSR/FPK，可以起到完全解决overdraw（在全部fragment生成后，进入到FS前筛选出最前面的fragment）；</li></ul><h1 id="c-其他剔除"><a href="#c-其他剔除" class="headerlink" title="c). 其他剔除"></a>c). 其他剔除</h1><ul><li><p>Forward+ 的 Light culling</p></li><li><p>……</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;0-前言&quot;&gt;&lt;a href=&quot;#0-前言&quot; class=&quot;headerlink&quot; title=&quot;0). 前言&quot;&gt;&lt;/a&gt;0). 前言&lt;/h1&gt;&lt;p&gt;最近实际做项目的时候发现对自身知识体系做整理的重要性，因此之后会慢慢做一些总结和思维导图，比如剔除、GI（GI方案、反射、AO等）、阴影等。本篇就以剔除开始；&lt;/p&gt;
&lt;h1 id=&quot;a-粗粒度剔除（CPU为主）&quot;&gt;&lt;a href=&quot;#a-粗粒度剔除（CPU为主）&quot; class=&quot;headerlink&quot; title=&quot;a). 粗粒度剔除（CPU为主）&quot;&gt;&lt;/a&gt;a). 粗粒度剔除（CPU为主）&lt;/h1&gt;&lt;p&gt;包括视锥剔除和遮挡剔除，为物体层面。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;发生阶段：CPU应用阶段&lt;/strong&gt;；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;a-1-视锥剔除&quot;&gt;&lt;a href=&quot;#a-1-视锥剔除&quot; class=&quot;headerlink&quot; title=&quot;a.1). 视锥剔除&quot;&gt;&lt;/a&gt;a.1). 视锥剔除&lt;/h2&gt;&lt;p&gt;CPU阶段，物体的AABB包围盒与视锥体6个面分别作判断，剔除包围盒完全处于视锥体外的物体；&lt;/p&gt;
&lt;h2 id=&quot;a-2-遮挡剔除&quot;&gt;&lt;a href=&quot;#a-2-遮挡剔除&quot; class=&quot;headerlink&quot; title=&quot;a.2). 遮挡剔除&quot;&gt;&lt;/a&gt;a.2). 遮挡剔除&lt;/h2&gt;&lt;h3 id=&quot;a-2-1-基于Occlusion-Query&quot;&gt;&lt;a href=&quot;#a-2-1-基于Occlusion-Query&quot; class=&quot;headerlink&quot; title=&quot;a.2.1). 基于Occlusion Query&quot;&gt;&lt;/a&gt;a.2.1). 基于Occlusion Query&lt;/h3&gt;&lt;p&gt;在深度测试时得到待剔除物体相关数据，在应用程序阶段执行。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Occlusion Query:&lt;/strong&gt; 在绘制命令执行前向GPU插入一条查询，在绘制结束后的某个时刻，从GPU将查询结果回读到内存中，得到&lt;strong&gt;某次DrawCall中通过Depth Test的Sample数量&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;基础做法：&lt;/strong&gt; &lt;ol&gt;
&lt;li&gt;用&lt;strong&gt;Depth-Only&lt;/strong&gt;的Pass将场景整体绘制一遍，将物体（的包围盒）深度写入Z-Buffer中；&lt;/li&gt;
&lt;li&gt;使用&lt;strong&gt;物体的包围盒&lt;/strong&gt;传入GPU进行&lt;strong&gt;Occlusion Query&lt;/strong&gt;。如query得到的sample数大于0，则表示该物体（部分）可见，&lt;strong&gt;剔除掉Sample等于0的物体&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;执行正常的渲染流程；&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;ol&gt;
&lt;li&gt;对于复杂场景，Depth-Only也有较大的开销；&lt;/li&gt;
&lt;li&gt;需要将查询结果读回内存（VRAM -&amp;gt; System RAM），需要走PCI-E（IMR架构）；&lt;ul&gt;
&lt;li&gt;常见的解决方法：回读上一帧Occlusion Query的结果，但可能导致一定的错误（但之后深度测试也可保证画面正确，因此此处出错只是增加了一部分渲染开销）；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;a-2-2-基于Software-Rasterization（软件剔除）&quot;&gt;&lt;a href=&quot;#a-2-2-基于Software-Rasterization（软件剔除）&quot; class=&quot;headerlink&quot; title=&quot;a.2.2). 基于Software Rasterization（软件剔除）&quot;&gt;&lt;/a&gt;a.2.2). 基于Software Rasterization（软件剔除）&lt;/h3&gt;&lt;p&gt;最早由Frostbite提出，用于战地3的剔除方案。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU构造一个低分辨率的Z-Buffer，在其中绘制一些场景中较大的遮挡物（美术设定的一些大物体+地形）；&lt;/li&gt;
&lt;li&gt;在构造好的Z-Buffer上，绘制小物体的包围盒，执行类似Occlusion Query的操作进行剔除；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2023/08/01/%E5%89%94%E9%99%A4%E6%80%BB%E7%BB%93/image-20230814111511843.png&quot; alt=&quot;image-20230814111511843&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="整理" scheme="https://whitetail-o.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/%E6%95%B4%E7%90%86/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="算法" scheme="https://whitetail-o.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="剔除" scheme="https://whitetail-o.github.io/tags/%E5%89%94%E9%99%A4/"/>
    
  </entry>
  
  <entry>
    <title>Games104_02_引擎分层架构</title>
    <link href="https://whitetail-o.github.io/2023/07/01/Games104_02_%E5%BC%95%E6%93%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/"/>
    <id>https://whitetail-o.github.io/2023/07/01/Games104_02_%E5%BC%95%E6%93%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/</id>
    <published>2023-07-01T10:20:10.000Z</published>
    <updated>2023-07-08T14:03:24.450Z</updated>
    
    <content type="html"><![CDATA[<h1 id="a-引擎架构分层简介"><a href="#a-引擎架构分层简介" class="headerlink" title="a). 引擎架构分层简介"></a>a). 引擎架构分层简介</h1><ul><li>Tool Layer<ul><li>打开一个游戏引擎会直接看到各种类型的编辑器。这个直接和开发者进行交互的层称为<strong>工具层(tool layer)</strong>；</li></ul></li><li>Function Layer<ul><li>在工具层下面包含<strong>功能层(function layer)</strong>，用来实现游戏的渲染、动画、交互等不同类型的功能；</li></ul></li><li>Resource Layer<ul><li>在此基础上还需要<strong>资源层(resource layer)</strong>来管理各种各样的场景美术资源；</li></ul></li><li>Core Layer<ul><li>再下一层是<strong>核心层(core layer)</strong>，它包括支持游戏渲染、动画、物理系统、内存管理等不同系统的核心代码；</li></ul></li><li>Platform Layer<ul><li>最底层是<strong>平台层(platform layer)</strong>，一般包括各种图形API、输入设备支持以及不同游戏平台的底层代码；</li></ul></li></ul><p><img src="/2023/07/01/Games104_02_%E5%BC%95%E6%93%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/Total_Layer.png" alt="Total_Layer"></p><span id="more"></span><h1 id="b-Resource-Layer"><a href="#b-Resource-Layer" class="headerlink" title="b). Resource Layer"></a>b). Resource Layer</h1><h2 id="b-1-Asset-and-importing"><a href="#b-1-Asset-and-importing" class="headerlink" title="b.1). Asset and importing"></a>b.1). Asset and importing</h2><p>导入素材，转换为引擎便于使用的高效类型（如PNG、JPG转换为DDS）。素材转换为<strong>Asset</strong>，如几何模型、纹理、声音、动画等。同时，也会有相应的<strong>Composite Asset</strong>定义资产间的引用关系（类似Unity的Prefab）。资产会有相应的<strong>GUID(全局唯一标识符，Globally Unique Identifier)</strong>进行识别和管理。</p><p><img src="/2023/07/01/Games104_02_%E5%BC%95%E6%93%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/RL_Import.png" alt="RL_Import"></p><h2 id="b-2-Runtime-Asset-Manager"><a href="#b-2-Runtime-Asset-Manager" class="headerlink" title="b.2). Runtime Asset Manager"></a>b.2). Runtime Asset Manager</h2><ul><li>资源层需要对各类资产进行<strong>动态实时的管理</strong>，该功能通过<strong>handle</strong>（Link to ？）系统实现。<img src="/2023/07/01/Games104_02_%E5%BC%95%E6%93%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/RL_RAS.png" alt="RL_RAS"></li></ul><ul><li><p><strong>资源层核心：</strong>管理资产<strong>生命周期（Life Cycle）</strong>。</p></li><li><p><strong>策略：</strong></p><ol><li><strong>GC(Garbage Collection)</strong>；</li><li>动态/延迟加载；</li></ol><p><img src="/2023/07/01/Games104_02_%E5%BC%95%E6%93%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/RL_RAS2.png" alt="RL_RAS2"></p></li></ul><h1 id="c-Function-Layer"><a href="#c-Function-Layer" class="headerlink" title="c). Function Layer"></a>c). Function Layer</h1><p><strong>功能层用来实现游戏的核心玩法。</strong>某种意义上讲功能层的作用类似于一个<strong>时钟(tick)</strong>用来控制整个游戏世界的运行，在每个时钟周期内功能层需要完成整个游戏系统的全部运算。</p><p><img src="/2023/07/01/Games104_02_%E5%BC%95%E6%93%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/FL01.png" alt="FL01"></p><p>Tick会依次调用两个函数：<code>tickLogic()</code>以及<code>tickRender()</code>来分别<strong>更新系统的状态</strong>和并把<strong>图像绘制</strong>到屏幕上。这里需要注意逻辑的计算是严格早于渲染的，编程时也要注意不要把它们混到一起。<img src="/2023/07/01/Games104_02_%E5%BC%95%E6%93%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/FL_Tick01.png" alt="FL_Tick01"></p><p>为了提升游戏引擎的计算效率现代游戏引擎往往会通过多核的方式来充分利用CPU计算的资源。未来的游戏引擎架构一定会向多核并行的方向上发展，因此在设计引擎时最好从多核的角度进行思考。当然如何管理计算任务之间的依赖仍然是一个难点。</p><h1 id="d-Core-Layer"><a href="#d-Core-Layer" class="headerlink" title="d). Core Layer"></a>d). Core Layer</h1><p>核心库：包括高效的数学库、数据结构、<strong>内存管理(Memory Management)</strong>等。</p><p><img src="/2023/07/01/Games104_02_%E5%BC%95%E6%93%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/CL03.png" alt="CL03"></p><p>核心层的数学库和通用数学库的一大区别在于游戏引擎对于计算的<strong>实时性要求更高</strong>，有时我们甚至可以牺牲一些计算精度来换取计算效率的提升。同时核心层数学库还大量使用了CPU的<strong>SIMD</strong>指令，这样可以极大地加速矩阵和向量的计算速度。<img src="/2023/07/01/Games104_02_%E5%BC%95%E6%93%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/CL01.png" alt="CL01"></p><p>数学库之外核心层还需要包含各种常用数据结构的实现。</p><p>核心层最重要的功能是实现<strong>内存管理(memory management)</strong>，使得运行时<strong>内存碎片尽量少，访问效率尽量高</strong>，从这个角度看游戏引擎的功能非常类似于操作系统。在游戏运行时往往会直接申请一大片内存空间然后通过引擎而不是操作系统进行管理，这样可以提升系统的运行效率。</p><ul><li>数据尽可能存放在一起（Memory Pool）</li><li>数据尽可能顺序排布，顺序读取（Reduce cache miss）</li><li>数据的读写尽量批量进行（如通过Memory alignment）</li></ul><p><img src="/2023/07/01/Games104_02_%E5%BC%95%E6%93%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/CL02.png" alt="CL02"></p><h1 id="e-Platform-Layer"><a href="#e-Platform-Layer" class="headerlink" title="e). Platform Layer"></a>e). Platform Layer</h1><p>为了克服不同平台对于代码的限制，我们需要平台层来提供对不同操作系统和硬件平台的支持。这样我们就只需要一套代码就可以在不同的平台上运行程序。</p><p>不同的平台往往使用了不同的图形接口，为了统一代码游戏引擎的平台层提供了<strong>RHI(render hardware interface, 如SRP)</strong>作为通用的图形编程API。</p><ul><li><p>RHI包含了统一套程序在不同图形API（Vulkan、DX11、DX12等）上的实现，这样上层的图形应用中就可以使用统一的一套API进行编程。</p><p><img src="/2023/07/01/Games104_02_%E5%BC%95%E6%93%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/PL01.png" alt="PL01"></p></li></ul><h1 id="f-Tool-Layer"><a href="#f-Tool-Layer" class="headerlink" title="f). Tool Layer"></a>f). Tool Layer</h1><p><img src="/2023/07/01/Games104_02_%E5%BC%95%E6%93%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/TL01.png" alt="TL01"></p><p>除了游戏引擎自己的开发工具外一般还需要导入其它软件和开发工具的资产，这就需要<strong>Asset conditioning pipeline(起到如导入导出的作用)</strong>来提供不同资源导入游戏引擎的统一管线。可以说编辑器和asset conditioning pipeline共同构成了游戏引擎的工具层。</p><p><img src="/2023/07/01/Games104_02_%E5%BC%95%E6%93%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/TL02.png" alt="TL02"></p><h1 id="g-Why-Layered-Architecture"><a href="#g-Why-Layered-Architecture" class="headerlink" title="g). Why Layered Architecture?"></a>g). Why Layered Architecture?</h1><p><img src="/2023/07/01/Games104_02_%E5%BC%95%E6%93%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/LA01.png" alt="LA01"></p><ul><li>上层可调动下层，下层无法调动上层；</li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;a-引擎架构分层简介&quot;&gt;&lt;a href=&quot;#a-引擎架构分层简介&quot; class=&quot;headerlink&quot; title=&quot;a). 引擎架构分层简介&quot;&gt;&lt;/a&gt;a). 引擎架构分层简介&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;Tool Layer&lt;ul&gt;
&lt;li&gt;打开一个游戏引擎会直接看到各种类型的编辑器。这个直接和开发者进行交互的层称为&lt;strong&gt;工具层(tool layer)&lt;/strong&gt;；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Function Layer&lt;ul&gt;
&lt;li&gt;在工具层下面包含&lt;strong&gt;功能层(function layer)&lt;/strong&gt;，用来实现游戏的渲染、动画、交互等不同类型的功能；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Resource Layer&lt;ul&gt;
&lt;li&gt;在此基础上还需要&lt;strong&gt;资源层(resource layer)&lt;/strong&gt;来管理各种各样的场景美术资源；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Core Layer&lt;ul&gt;
&lt;li&gt;再下一层是&lt;strong&gt;核心层(core layer)&lt;/strong&gt;，它包括支持游戏渲染、动画、物理系统、内存管理等不同系统的核心代码；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Platform Layer&lt;ul&gt;
&lt;li&gt;最底层是&lt;strong&gt;平台层(platform layer)&lt;/strong&gt;，一般包括各种图形API、输入设备支持以及不同游戏平台的底层代码；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2023/07/01/Games104_02_%E5%BC%95%E6%93%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/Total_Layer.png&quot; alt=&quot;Total_Layer&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Games104" scheme="https://whitetail-o.github.io/categories/Games104/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="Games104" scheme="https://whitetail-o.github.io/tags/Games104/"/>
    
    <category term="Engine architecture" scheme="https://whitetail-o.github.io/tags/Engine-architecture/"/>
    
  </entry>
  
  <entry>
    <title>目录</title>
    <link href="https://whitetail-o.github.io/2023/03/27/%E7%9B%AE%E5%BD%95/"/>
    <id>https://whitetail-o.github.io/2023/03/27/%E7%9B%AE%E5%BD%95/</id>
    <published>2023-03-26T17:17:18.635Z</published>
    <updated>2023-07-08T14:27:52.130Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目前已有"><a href="#目前已有" class="headerlink" title="目前已有"></a>目前已有</h1><p><a href="https://whitetail-o.github.io/categories/Demo/">分类: Demo概述 | WhiteTail’s Blog (whitetail-o.github.io)</a></p><p><a href="https://whitetail-o.github.io/categories/Games101/">分类: Games101 | WhiteTail’s Blog (whitetail-o.github.io)</a></p><p><a href="https://whitetail-o.github.io/categories/Games104/">分类: Games104 | WhiteTail’s Blog (whitetail-o.github.io)(占位，待全部完成后上传)</a></p><p><a href="[WhiteTail-o/SRP_Demo (github.com">分类: SRP | WhiteTail’s Blog (whitetail-o.github.io)</a>](<a href="https://github.com/WhiteTail-o/SRP_Demo/tree/master">https://github.com/WhiteTail-o/SRP_Demo/tree/master</a>))</p><p><a href="https://whitetail-o.github.io/categories/Games202/">分类: Games202 | WhiteTail’s Blog (whitetail-o.github.io)</a></p><p><a href="https://whitetail-o.github.io/categories/百人计划/">分类: 百人计划 | WhiteTail’s Blog (whitetail-o.github.io)</a></p><p><a href="https://whitetail-o.github.io/categories/相机/">分类: 相机概述 | WhiteTail’s Blog (whitetail-o.github.io)</a></p><span id="more"></span><h1 id="已完成未上传"><a href="#已完成未上传" class="headerlink" title="已完成未上传"></a>已完成未上传</h1><ul><li><p>通过Maya实现将平滑法线写入顶点色；</p><ul><li><p>事实上此方案只能完全解决不带顶点形变的物体描边，对于<strong>带形变动画</strong>的物体<strong>硬表面</strong>的描边只能<strong>改善</strong>。原因：</p><ul><li><p>切线空间是根据UV求出T、B向量，再根据顶点法线的方向对T，B向量做正交化，进而得到真正的切线、副切线（副法线）。（是的，切线和副切线方向不一定和uv方向相同）</p></li><li><p>对于不经法线修改的硬表面，其顶点法线方向方向等于面法线（值得一提的是，光滑组改变的是顶点法线的计算方式，而不是直接改变顶点法线）。那经过动画形变，重合顶点各自的切线空间的相对位置很可能发生偏移，进而改变TBN矩阵，造成法线断裂。解决方法想到了几个，但是都太耗了，得不偿失，等补充了参数化方面的知识再看看能不能完善此方案。</p><p><img src="/2023/03/27/%E7%9B%AE%E5%BD%95/Snipaste_2023-03-28_11-09-47.png" alt="Snipaste_2023-03-28_11-09-47" style="zoom: 33%;"></p><p><img src="/2023/03/27/%E7%9B%AE%E5%BD%95/Snipaste_2023-03-28_11-09-13.png" alt="Snipaste_2023-03-28_11-09-13" style="zoom: 25%;"></p></li></ul></li></ul></li></ul><ul><li><p>使用SSSS(Separable SSS)实现SSS的SSSSS(Screen Space SSS)            :D</p></li><li><p>战双帕弥什的角色渲染分析；</p></li></ul><h1 id="待完成"><a href="#待完成" class="headerlink" title="待完成"></a>待完成</h1><ul><li>DX12龙书学习笔记；</li><li>SRP整理；</li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;目前已有&quot;&gt;&lt;a href=&quot;#目前已有&quot; class=&quot;headerlink&quot; title=&quot;目前已有&quot;&gt;&lt;/a&gt;目前已有&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://whitetail-o.github.io/categories/Demo/&quot;&gt;分类: Demo概述 | WhiteTail’s Blog (whitetail-o.github.io)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://whitetail-o.github.io/categories/Games101/&quot;&gt;分类: Games101 | WhiteTail’s Blog (whitetail-o.github.io)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://whitetail-o.github.io/categories/Games104/&quot;&gt;分类: Games104 | WhiteTail’s Blog (whitetail-o.github.io)(占位，待全部完成后上传)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;[WhiteTail-o/SRP_Demo (github.com&quot;&gt;分类: SRP | WhiteTail’s Blog (whitetail-o.github.io)&lt;/a&gt;](&lt;a href=&quot;https://github.com/WhiteTail-o/SRP_Demo/tree/master&quot;&gt;https://github.com/WhiteTail-o/SRP_Demo/tree/master&lt;/a&gt;))&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://whitetail-o.github.io/categories/Games202/&quot;&gt;分类: Games202 | WhiteTail’s Blog (whitetail-o.github.io)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://whitetail-o.github.io/categories/百人计划/&quot;&gt;分类: 百人计划 | WhiteTail’s Blog (whitetail-o.github.io)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://whitetail-o.github.io/categories/相机/&quot;&gt;分类: 相机概述 | WhiteTail’s Blog (whitetail-o.github.io)&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="目录" scheme="https://whitetail-o.github.io/categories/%E7%9B%AE%E5%BD%95/"/>
    
    
  </entry>
  
  <entry>
    <title>【转载】为不同的图形 API 编写着色器（Unity）</title>
    <link href="https://whitetail-o.github.io/2023/03/18/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E4%B8%BA%E4%B8%8D%E5%90%8C%E7%9A%84%E5%9B%BE%E5%BD%A2%20API%20%E7%BC%96%E5%86%99%E7%9D%80%E8%89%B2%E5%99%A8/"/>
    <id>https://whitetail-o.github.io/2023/03/18/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E4%B8%BA%E4%B8%8D%E5%90%8C%E7%9A%84%E5%9B%BE%E5%BD%A2%20API%20%E7%BC%96%E5%86%99%E7%9D%80%E8%89%B2%E5%99%A8/</id>
    <published>2023-03-18T12:24:32.000Z</published>
    <updated>2023-03-19T02:56:32.776Z</updated>
    
    <content type="html"><![CDATA[<p>之前刚想写一篇DX12和OpenGL在Unity Shader中的差异，没想到官网就写了……</p><p>附上链接：<a href="https://docs.unity3d.com/cn/current/Manual/SL-PlatformDifferences.html">为不同的图形 API 编写着色器 - Unity 手册 (unity3d.com)</a> </p><p>以下正文</p><hr><p>在某些情况下，不同图形 API 之间的图形渲染行为方式存在差异。大多数情况下，Unity 编辑器会隐藏这些差异，但在某些情况下，编辑器无法为您执行此操作。下面列出了这些情况以及发生这些情况时需要采取的操作。</p><h2 id="渲染纹理坐标"><a href="#渲染纹理坐标" class="headerlink" title="渲染纹理坐标"></a>渲染纹理坐标</h2><p>垂直纹理坐标约定在两种类型的平台之间有所不同，分别是 Direct3D 类和 OpenGL 类平台。</p><ul><li><strong>Direct3D 类</strong>：顶部坐标为 0 并向下增加。此类型适用于 Direct3D、Metal 和游戏主机。</li><li><strong>OpenGL 类</strong>：底部坐标为 0 并向上增加。此类适用于 OpenGL 和 OpenGL ES。</li></ul><p>除了渲染到<a href="https://docs.unity3d.com/cn/current/Manual/class-RenderTexture.html">渲染纹理</a>的情况下，这种差异不会对您的项目产生任何影响。在 Direct3D 类平台上渲染到纹理时，Unity 会在内部上下翻转渲染。这样就会使坐标约定在平台之间匹配，并以 OpenGL 类平台约定作为标准。</p><p>在着色器中，有两种常见情况需要您采取操作确保不同的坐标约定不会在项目中产生问题，这两种情况就是图像效果和 UV 空间中的渲染。</p><span id="more"></span><h3 id="图像效果"><a href="#图像效果" class="headerlink" title="图像效果"></a>图像效果</h3><p>使用<a href="https://docs.unity3d.com/Packages/com.unity.postprocessing@latest">图像效果</a>和抗锯齿时，系统不会翻转为图像效果生成的源纹理来匹配 OpenGL 类平台约定。在这种情况下，Unity 渲染到屏幕以获得抗锯齿效果，然后将渲染解析为渲染纹理，以便通过图像效果进行进一步处理。</p><p>如果您的图像效果是一次处理一个渲染纹理的简单图像效果，则 <a href="https://docs.unity3d.com/cn/current/ScriptReference/Graphics.Blit.html">Graphics.Blit</a> 会处理不一致的坐标。但是，如果您在<a href="https://docs.unity3d.com/Packages/com.unity.postprocessing@latest">图像效果</a>中一起处理多个<a href="https://docs.unity3d.com/cn/current/Manual/class-RenderTexture.html">渲染纹理</a>，则在 Direct3D 类平台中以及在您使用抗锯齿时，渲染纹理很可能以不同的垂直方向出现。要标准化坐标，必须在顶点着色器中手动上下“翻转”屏幕纹理，使其与 OpenGL 类坐标标准匹配。</p><p>以下代码示例演示了如何执行此操作：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 翻转纹理的采样：</span><br><span class="line">// 主纹理的</span><br><span class="line">// 纹理像素大小将具有负 Y。</span><br><span class="line"></span><br><span class="line"># if UNITY_UV_STARTS_AT_TOP</span><br><span class="line">if (_MainTex_TexelSize.y &lt; 0)</span><br><span class="line">        uv.y = 1-uv.y;</span><br><span class="line"># endif</span><br></pre></td></tr></table></figure><p><a href="https://docs.unity3d.com/cn/current/Manual/SL-GrabPass.html">GrabPass</a> 也出现了类似的情况。生成的渲染纹理实际上可能不会在 Direct3D 类（非 OpenGL 类）平台上进行上下翻转。如果着色器代码对 GrabPass 纹理进行采样，请使用 <a href="https://docs.unity3d.com/cn/current/Manual/SL-BuiltinFunctions.html">UnityCG include</a> 文件中的 <code>ComputeGrabScreenPos</code> 函数。</p><h3 id="在-UV-空间中渲染"><a href="#在-UV-空间中渲染" class="headerlink" title="在 UV 空间中渲染"></a>在 UV 空间中渲染</h3><p>在纹理坐标 (UV) 空间中渲染特殊效果或工具时，您可能需要调整着色器，以便在 Direct3D 类和 OpenGL 类系统之间进行一致渲染。您还可能需要在渲染到屏幕和渲染到纹理之间进行渲染调整。为进行此类调整，应上下翻转 Direct3D 类投影，使其坐标与 OpenGL 类投影坐标相匹配。</p><p><a href="https://docs.unity3d.com/cn/current/Manual/SL-UnityShaderVariables.html">内置变量</a> <code>ProjectionParams.x</code> 包含值 <code>+1</code> 或 <code>–1</code>。<code>-1</code> 表示投影已上下翻转以匹配 OpenGL 类投影坐标，而 <code>+1</code> 表示尚未翻转。 您可以在着色器中检查此值，然后执行不同的操作。下面的示例将检查是否已翻转投影，如果已翻转，则再次进行翻转，然后返回 UV 坐标以便匹配。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">float4 vert(float2 uv : TEXCOORD0) : SV_POSITION</span><br><span class="line">&#123;</span><br><span class="line">    float4 pos;</span><br><span class="line">    pos.xy = uv;</span><br><span class="line">    // 此示例使用上下翻转的投影进行渲染，</span><br><span class="line">    // 因此也翻转垂直 UV 坐标</span><br><span class="line">    if (_ProjectionParams.x &lt; 0)</span><br><span class="line">        pos.y = 1 - pos.y;</span><br><span class="line">    pos.z = 0;</span><br><span class="line">    pos.w = 1;</span><br><span class="line">    return pos;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="裁剪空间坐标"><a href="#裁剪空间坐标" class="headerlink" title="裁剪空间坐标"></a>裁剪空间坐标</h2><p>与纹理坐标类似，裁剪空间坐标（也称为投影后空间坐标）在 Direct3D 类和 OpenGL 类平台之间有所不同：</p><ul><li><strong>Direct3D 类</strong>：裁剪空间深度从近平面的 +1.0 到远平面的 0.0。此类型适用于 Direct3D、Metal 和游戏主机。</li><li><strong>OpenGL 类</strong>：裁剪空间深度从近平面的 –1.0 到远平面的 +1.0。此类适用于 OpenGL 和 OpenGL ES。</li></ul><p>在着色器代码内，可使用<a href="https://docs.unity3d.com/cn/current/Manual/SL-BuiltinMacros.html">内置宏</a> <code>UNITY_NEAR_CLIP_VALUE</code> 来获取基于平台的近平面值。</p><p>在脚本代码内，使用 <a href="https://docs.unity3d.com/cn/current/ScriptReference/GL.GetGPUProjectionMatrix.html">GL.GetGPUProjectionMatrix</a> 将 Unity 的坐标系（遵循 OpenGL 类约定）转换为 Direct3D 类坐标（如果这是平台所期望的）。</p><h2 id="着色器计算的精度"><a href="#着色器计算的精度" class="headerlink" title="着色器计算的精度"></a>着色器计算的精度</h2><p>要避免精度问题，请确保在目标平台上测试着色器。移动设备和 PC 中的 GPU 在处理浮点类型方面有所不同。PC GPU 将所有浮点类型（浮点精度、半精度和固定精度）视为相同；PC GPU 使用完整 32 位精度进行所有计算，而许多移动设备 GPU 并不是这样做。</p><p>有关详细信息，请参阅<a href="https://docs.unity3d.com/cn/current/Manual/SL-DataTypesAndPrecision.html">数据类型和精度</a>的文档。</p><h2 id="着色器中的-const-声明"><a href="#着色器中的-const-声明" class="headerlink" title="着色器中的 const 声明"></a>着色器中的 const 声明</h2><p><code>const</code> 的使用在 Microsoft HSL（请参阅 <a href="http://msdn.microsoft.com/">msdn.microsoft.com</a>）和 OpenGL 的 GLSL（请参阅 <a href="https://en.wikipedia.org/wiki/OpenGL_Shading_Language">Wikipedia</a>）着色器语言之间有所不同。</p><ul><li>Microsoft 的 HLSL <code>const</code> 与 C# 和 C++ 中的含义大致相同：声明的变量在其作用域内是只读的，但可按任何方式初始化。</li><li>OpenGL 的 GLSL <code>const</code> 表示变量实际上是编译时常量，因此必须使用编译时约束（文字值或其他对于 <code>const</code> 的计算）进行初始化。</li></ul><p>最好是遵循 OpenGL 的 GLSL 语义，并且只有当变量真正不变时才将变量声明为 <code>const</code>。避免使用其他一些可变值初始化 <code>const</code> 变量（例如，作为函数中的局部变量）。这一原则也适用于 Microsoft 的 HLSL，因此以这种方式使用 <code>const</code> 可以避免在某些平台上混淆错误。</p><h2 id="着色器使用的语义"><a href="#着色器使用的语义" class="headerlink" title="着色器使用的语义"></a>着色器使用的语义</h2><p>要让着色器在所有平台上运行，一些着色器值应该使用以下语义：</p><ul><li><strong>顶点着色器输出（裁剪空间）位置</strong>：<code>SV_POSITION</code>。有时，着色器使用 POSITION 语义来使着色器在所有平台上运行。请注意，这不适用于 Sony PS4 或有曲面细分的情况。</li><li><strong>片元着色器输出颜色</strong>：<code>SV_Target</code>。有时，着色器使用 <code>COLOR</code> 或 <code>COLOR0</code> 来使着色器在所有平台上运行。请注意，这不适用于 Sony PS4。</li></ul><p>将网格渲染为点时，从顶点着色器输出 <code>PSIZE</code> 语义（例如，将其设置为 1）。某些平台（如 OpenGL ES 或 Metal）在未从着色器写入点大小时会将点大小视为“未定义”。</p><p>有关更多详细信息，请参阅有关<a href="https://docs.unity3d.com/cn/current/Manual/SL-ShaderSemantics.html">着色器语义</a>的文档。</p><h2 id="Direct3D-着色器编译器语法"><a href="#Direct3D-着色器编译器语法" class="headerlink" title="Direct3D 着色器编译器语法"></a>Direct3D 着色器编译器语法</h2><p>Direct3D 平台使用 Microsoft 的 <a href="https://docs.unity3d.com/cn/current/Manual/shader-compilation.html">HLSL 着色器编译器</a>。对于各种细微的着色器错误，HLSL 编译器比其他编译器更严格。例如，它不接受未正确初始化的函数输出值。</p><p>使用此编译器时，您可能遇到的最常见情况是：</p><ul><li>具有 <code>out</code> 参数的<a href="https://docs.unity3d.com/cn/current/Manual/SL-SurfaceShaders.html">表面着色器</a>顶点修改器。按如下方式初始化输出：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">void vert (inout appdata_full v, out Input o) </span><br><span class="line">    &#123;</span><br><span class="line">      **UNITY_INITIALIZE_OUTPUT(Input,o);**</span><br><span class="line">      // ...</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><ul><li>部分初始化的值。例如，函数返回 <code>float4</code>，但代码只设置它的 <code>.xyz</code> 值。如果只需要三个值，请设置所有值或更改为 <code>float3</code>。</li><li>在顶点着色器中使用 <code>tex2D</code>。这是无效的，因为顶点着色器中不存在 UV 导数。这种情况下，您需要采样显式 Mip 级别；例如，使用 <code>tex2Dlod</code> (<code>tex, float4(uv,0,0)</code>)。此外，还需要添加 <code>#pragma target 3.0</code>，因为 <code>tex2Dlod</code> 是着色器模型 3.0 的功能。</li></ul><h2 id="着色器中的-DirectX-11-DX11-HLSL-语法"><a href="#着色器中的-DirectX-11-DX11-HLSL-语法" class="headerlink" title="着色器中的 DirectX 11 (DX11) HLSL 语法"></a>着色器中的 DirectX 11 (DX11) HLSL 语法</h2><p><a href="https://docs.unity3d.com/cn/current/Manual/SL-SurfaceShaders.html">表面着色器</a>编译管线的某些部分不能理解特定于 DirectX 11 的 HLSL（Microsoft 的着色器语言）语法。</p><p>如果您正在使用 HLSL 功能（比如 <code>StructuredBuffers</code>、<code>RWTextures</code> 和其他非 DirectX 9 语法），请将它们包裹在 DirectX X11 专用的预处理器宏中，如下例所示。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># ifdef SHADER_API_D3D11</span><br><span class="line">// DirectX11 专用代码，例如</span><br><span class="line">StructuredBuffer&lt;float4&gt; myColors;</span><br><span class="line">RWTexture2D&lt;float4&gt; myRandomWriteTexture;</span><br><span class="line"># endif</span><br></pre></td></tr></table></figure><h2 id="使用着色器帧缓冲提取"><a href="#使用着色器帧缓冲提取" class="headerlink" title="使用着色器帧缓冲提取"></a>使用着色器帧缓冲提取</h2><p>一些 GPU（最明显的是 iOS 上基于 PowerVR 的 GPU）允许您通过提供当前片元颜色作为片元着色器的输入来进行某种可编程混合（请参阅 <a href="https://www.khronos.org/registry/gles/extensions/EXT/EXT_shader_framebuffer_fetch.txt">khronos.org</a> 上的 <code>EXT_shader_framebuffer_fetch</code>）。</p><p>可在 Unity 中编写使用帧缓冲提取功能的着色器。要执行此操作，请在使用 HLSL（Microsoft 的着色语言，请参阅 <a href="http://msdn.microsoft.com/">msdn.microsoft.com</a>）或 Cg（Nvidia 的着色语言，请参阅 <a href="http://www.nvidia.co.uk/">nvidia.co.uk</a>）编写片元着色器时使用 <code>inout</code> 颜色参数。</p><p>以下示例采用的是 Cg 语言。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">CGPROGRAM</span><br><span class="line">// 只为可能支持该功能的平台（目前是 gles、gles3 和 metal）</span><br><span class="line">// 编译着色器</span><br><span class="line"># pragma only_renderers framebufferfetch</span><br><span class="line"></span><br><span class="line">void frag (v2f i, inout half4 ocol : SV_Target)</span><br><span class="line">&#123;</span><br><span class="line">    // ocol 可以被读取（当前帧缓冲区颜色）</span><br><span class="line">    // 并且可以被写入（将颜色更改为该颜色）</span><br><span class="line">    // ...</span><br><span class="line">&#125;   </span><br><span class="line">ENDCG</span><br></pre></td></tr></table></figure><h2 id="着色器中的深度-Z-方向"><a href="#着色器中的深度-Z-方向" class="headerlink" title="着色器中的深度 (Z) 方向"></a>着色器中的深度 (Z) 方向</h2><p>深度 (Z) 方向在不同的着色器平台上不同。</p><p><strong>DirectX 11, DirectX 12, Metal: Reversed direction</strong></p><ul><li>深度 (Z) 缓冲区在近平面处为 1.0，在远平面处减小到 0.0。</li><li>裁剪空间范围是 [near,0]（表示近平面处的近平面距离，在远平面处减小到 0.0）。</li></ul><p><strong>其他平台：传统方向</strong></p><ul><li>深度 (Z) 缓冲区值在近平面处为 0.0，在远平面处为 1.0。</li><li>裁剪空间取决于具体平台：<ul><li>在 Direct3D 类平台上，范围是 [0,far]（表示在近平面处为 0.0，在远平面处增加到远平面距离）。</li><li>在 OpenGL 类平台上，范围是 [-near,far]（表示在近平面处为负的近平面距离，在远平面处增加到远平面距离）。</li></ul></li></ul><p>请注意，使反转方向深度 (Z) 与浮点深度缓冲区相结合，可显著提高相对于传统方向的深度缓冲区精度。这样做的优点是降低 Z 坐标的冲突并改善阴影，特别是在使用小的近平面和大的远平面时。</p><p>因此，在使用深度 (Z) 发生反转的平台上的着色器时：</p><ul><li>定义了 UNITY_REVERSED_Z。</li><li><code>_CameraDepth</code> 纹理的纹理范围是 1（近平面）到 0（远平面）。</li><li>裁剪空间范围是“near”（近平面）到 0（远平面）。</li></ul><p>但是，以下宏和函数会自动计算出深度 (Z) 方向的任何差异：</p><ul><li><code>Linear01Depth(float z)</code></li><li><code>LinearEyeDepth(float z)</code></li><li>UNITY_CALC_FOG_FACTOR(coord)</li></ul><h3 id="提取深度缓冲区"><a href="#提取深度缓冲区" class="headerlink" title="提取深度缓冲区"></a>提取深度缓冲区</h3><p>如果要手动提取深度 (Z) 缓冲区值，则可能需要检查缓冲区方向。以下是执行此操作的示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">float z = tex2D(_CameraDepthTexture, uv);</span><br><span class="line"># if defined(UNITY_REVERSED_Z)</span><br><span class="line">    z = 1.0f - z;</span><br><span class="line"># endif</span><br></pre></td></tr></table></figure><h3 id="使用裁剪空间"><a href="#使用裁剪空间" class="headerlink" title="使用裁剪空间"></a>使用裁剪空间</h3><p>如果要手动使用裁剪空间 (Z) 深度，则可能还需要使用以下宏来抽象化平台差异：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">float clipSpaceRange01 = UNITY_Z_0_FAR_FROM_CLIPSPACE(rawClipSpace);</span><br></pre></td></tr></table></figure><p><strong>注意</strong>：此宏不会改变 OpenGL 或 OpenGL ES 平台上的裁剪空间，因此在这些平台上，此宏返回“-near”1（近平面）到 far（远平面）之间的值。</p><h3 id="投影矩阵"><a href="#投影矩阵" class="headerlink" title="投影矩阵"></a>投影矩阵</h3><p>如果处于深度 (Z) 发生反转的平台上，则 <a href="https://docs.unity3d.com/cn/current/ScriptReference/GL.GetGPUProjectionMatrix.html">GL.GetGPUProjectionMatrix()</a> 返回一个还原了 z 的矩阵。 但是，如果要手动从投影矩阵中进行合成（例如，对于自定义阴影或深度渲染），您需要通过脚本按需自行还原深度 (Z) 方向。</p><p>以下是执行此操作的示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">var shadowProjection = Matrix4x4.Ortho(...); //阴影摄像机投影矩阵</span><br><span class="line">var shadowViewMat = ...     //阴影摄像机视图矩阵</span><br><span class="line">var shadowSpaceMatrix = ... //从裁剪空间到阴影贴图纹理空间</span><br><span class="line">    </span><br><span class="line">//当引擎通过摄像机投影计算设备投影矩阵时，</span><br><span class="line">//&quot;m_shadowCamera.projectionMatrix&quot;被隐式反转</span><br><span class="line">m_shadowCamera.projectionMatrix = shadowProjection; </span><br><span class="line"></span><br><span class="line">//&quot;shadowProjection&quot;在连接到&quot;m_shadowMatrix&quot;之前被手动翻转，</span><br><span class="line">//因为它被视为着色器的其他矩阵。</span><br><span class="line">if(SystemInfo.usesReversedZBuffer) </span><br><span class="line">&#123;</span><br><span class="line">    shadowProjection[2, 0] = -shadowProjection[2, 0];</span><br><span class="line">    shadowProjection[2, 1] = -shadowProjection[2, 1];</span><br><span class="line">    shadowProjection[2, 2] = -shadowProjection[2, 2];</span><br><span class="line">    shadowProjection[2, 3] = -shadowProjection[2, 3];</span><br><span class="line">&#125;</span><br><span class="line">    m_shadowMatrix = shadowSpaceMatrix * shadowProjection * shadowViewMat;</span><br></pre></td></tr></table></figure><h3 id="深度-Z-偏差"><a href="#深度-Z-偏差" class="headerlink" title="深度 (Z) 偏差"></a>深度 (Z) 偏差</h3><p>Unity 自动处理深度 (Z) 偏差，以确保其与 Unity 的深度 (Z) 方向匹配。但是，如果要使用本机代码渲染插件，则需要在 C 或 C++ 代码中消除（反转）深度 (Z) 偏差。</p><h4 id="深度-Z-方向检查工具"><a href="#深度-Z-方向检查工具" class="headerlink" title="深度 (Z) 方向检查工具"></a>深度 (Z) 方向检查工具</h4><ul><li>使用 <a href="https://docs.unity3d.com/cn/current/ScriptReference/SystemInfo-usesReversedZBuffer.html">SystemInfo.usesReversedZBuffer</a> 可确认所在平台是否使用反转深度 (Z)。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;之前刚想写一篇DX12和OpenGL在Unity Shader中的差异，没想到官网就写了……&lt;/p&gt;
&lt;p&gt;附上链接：&lt;a href=&quot;https://docs.unity3d.com/cn/current/Manual/SL-PlatformDifferences.html&quot;&gt;为不同的图形 API 编写着色器 - Unity 手册 (unity3d.com)&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;以下正文&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;在某些情况下，不同图形 API 之间的图形渲染行为方式存在差异。大多数情况下，Unity 编辑器会隐藏这些差异，但在某些情况下，编辑器无法为您执行此操作。下面列出了这些情况以及发生这些情况时需要采取的操作。&lt;/p&gt;
&lt;h2 id=&quot;渲染纹理坐标&quot;&gt;&lt;a href=&quot;#渲染纹理坐标&quot; class=&quot;headerlink&quot; title=&quot;渲染纹理坐标&quot;&gt;&lt;/a&gt;渲染纹理坐标&lt;/h2&gt;&lt;p&gt;垂直纹理坐标约定在两种类型的平台之间有所不同，分别是 Direct3D 类和 OpenGL 类平台。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Direct3D 类&lt;/strong&gt;：顶部坐标为 0 并向下增加。此类型适用于 Direct3D、Metal 和游戏主机。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenGL 类&lt;/strong&gt;：底部坐标为 0 并向上增加。此类适用于 OpenGL 和 OpenGL ES。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除了渲染到&lt;a href=&quot;https://docs.unity3d.com/cn/current/Manual/class-RenderTexture.html&quot;&gt;渲染纹理&lt;/a&gt;的情况下，这种差异不会对您的项目产生任何影响。在 Direct3D 类平台上渲染到纹理时，Unity 会在内部上下翻转渲染。这样就会使坐标约定在平台之间匹配，并以 OpenGL 类平台约定作为标准。&lt;/p&gt;
&lt;p&gt;在着色器中，有两种常见情况需要您采取操作确保不同的坐标约定不会在项目中产生问题，这两种情况就是图像效果和 UV 空间中的渲染。&lt;/p&gt;</summary>
    
    
    
    <category term="Unity" scheme="https://whitetail-o.github.io/categories/Unity/"/>
    
    
    <category term="图形 API" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2-API/"/>
    
    <category term="Unity" scheme="https://whitetail-o.github.io/tags/Unity/"/>
    
    <category term="转载" scheme="https://whitetail-o.github.io/tags/%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>Games202 作业汇总</title>
    <link href="https://whitetail-o.github.io/2023/02/20/Games202HW/"/>
    <id>https://whitetail-o.github.io/2023/02/20/Games202HW/</id>
    <published>2023-02-20T13:42:10.000Z</published>
    <updated>2023-03-18T14:40:11.607Z</updated>
    
    <content type="html"><![CDATA[<h1 id="阴影PCSS"><a href="#阴影PCSS" class="headerlink" title="阴影PCSS"></a>阴影PCSS</h1><p><img src="/2023/02/20/Games202HW/PCSS.png" alt="PCSS"></p><h1 id="Precomputed-Radiance-Transfer，PRT"><a href="#Precomputed-Radiance-Transfer，PRT" class="headerlink" title="Precomputed Radiance Transfer，PRT"></a>Precomputed Radiance Transfer，PRT</h1><p><img src="/2023/02/20/Games202HW/prt.png" alt="prt"></p><p><img src="/2023/02/20/Games202HW/prt2.png" alt="prt2"></p><h1 id="屏幕空间反射"><a href="#屏幕空间反射" class="headerlink" title="屏幕空间反射"></a>屏幕空间反射</h1><p><img src="/2023/02/20/Games202HW/SSR.png" alt="SSR"></p><h1 id="Kulla-Conty-Approximation"><a href="#Kulla-Conty-Approximation" class="headerlink" title="Kulla-Conty Approximation"></a>Kulla-Conty Approximation</h1><p><img src="/2023/02/20/Games202HW/Kulla.png" alt="Kulla"></p><h1 id="TAA"><a href="#TAA" class="headerlink" title="TAA"></a>TAA</h1><p><img src="/2023/02/20/Games202HW/un.png" alt="un"></p><p><img src="/2023/02/20/Games202HW/1.png" alt="1"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;阴影PCSS&quot;&gt;&lt;a href=&quot;#阴影PCSS&quot; class=&quot;headerlink&quot; title=&quot;阴影PCSS&quot;&gt;&lt;/a&gt;阴影PCSS&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2023/02/20/Games202HW/PCSS.png&quot; alt=&quot;PCSS&quot;&gt;</summary>
      
    
    
    
    <category term="Games202" scheme="https://whitetail-o.github.io/categories/Games202/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="Games202" scheme="https://whitetail-o.github.io/tags/Games202/"/>
    
  </entry>
  
  <entry>
    <title>Games202-7 A Glimpse of Industrial Solution</title>
    <link href="https://whitetail-o.github.io/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/"/>
    <id>https://whitetail-o.github.io/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/</id>
    <published>2023-02-20T13:42:10.000Z</published>
    <updated>2023-03-17T05:34:29.382Z</updated>
    
    <content type="html"><![CDATA[<h1 id="a-Anti-Aliasing"><a href="#a-Anti-Aliasing" class="headerlink" title="a). Anti-Aliasing"></a>a). Anti-Aliasing</h1><h2 id="a-1-Temporal-Anti-Aliasing-TAA"><a href="#a-1-Temporal-Anti-Aliasing-TAA" class="headerlink" title="a.1). Temporal Anti-Aliasing (TAA)"></a>a.1). Temporal Anti-Aliasing (TAA)</h2><ul><li><strong>复用先前帧的样本</strong>，假设画面不动，就可在单个像素内随时间规律移动感知点，进行（加权）平均；<ul><li><strong>为何规律移动感知点：</strong> 随机采样会引入高频噪声；</li></ul></li><li>如画面移动，则和频域降噪相同，使用Motion vector找到对应像素，再规律移动感知点。同时也可引入Clamp和Detection的操作；</li></ul><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/TAA01.png" alt="TAA01"></p><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/TAA02.png" alt="TAA02" style="zoom: 33%;"></p><h2 id="a-2-MSAA-vs-SSAA"><a href="#a-2-MSAA-vs-SSAA" class="headerlink" title="a.2). MSAA vs. SSAA"></a>a.2). MSAA vs. SSAA</h2><p><strong>SSAA：</strong></p><ul><li>相当于用更大分辨率渲染后降采样，做2倍的SSAA，相当于一个像素做4次shading；</li><li>质量最好，但是性能开销大；</li></ul><p><strong>MSAA：</strong></p><ul><li><p>在一个像素内，<strong>同一个图元只着色一次</strong>；(如图，0、2、3为图元A，着色一次(左边的绿点)；1为图元B，着色一次；)</p><ul><li>因此，MSAA会维护一张表，表中记录当前感知点记录的color(albedo?) 和 深度</li></ul><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/MSAA01.png" alt="MSAA01" style="zoom:50%;"></p></li><li><p>在像素间复用样本；</p><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/MSAA02.png" alt="MSAA02" style="zoom:50%;"></p></li></ul><h2 id="a-3-Image-Based-Anti-Aliasing-Solution"><a href="#a-3-Image-Based-Anti-Aliasing-Solution" class="headerlink" title="a.3). Image Based Anti-Aliasing Solution"></a>a.3). Image Based Anti-Aliasing Solution</h2><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/ImageBasedAA.png" alt="ImageBasedAA"></p><h2 id="a-4-Note"><a href="#a-4-Note" class="headerlink" title="a.4). Note"></a>a.4). Note</h2><ul><li><strong><font color="red">G-buffers一定不能做抗锯齿</font></strong></li></ul><span id="more"></span><h1 id="b-Temporal-Super-Resolution"><a href="#b-Temporal-Super-Resolution" class="headerlink" title="b). Temporal Super Resolution"></a>b). Temporal Super Resolution</h1><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/DLSS01.png" alt="DLSS01"></p><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/DLSS02.png" alt="DLSS02"></p><ul><li>通过深度学习告诉管线，<strong>如何使用历史帧的信息</strong>；</li></ul><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/DLSS03.png" alt="DLSS03" style="zoom:50%;"></p><h1 id="c-Deferred-Shading-详见百人计划图形3-4-延迟渲染管线"><a href="#c-Deferred-Shading-详见百人计划图形3-4-延迟渲染管线" class="headerlink" title="c). Deferred Shading(详见百人计划图形3.4 延迟渲染管线)"></a>c). Deferred Shading(详见百人计划图形3.4 延迟渲染管线)</h1><p>主要解决<strong>大量光照渲染</strong>和<strong>overdraw</strong>（传统渲染如果从后往前渲染，那所有fragment都会被shaded一次）的方案。</p><p>可以将延迟渲染(Deferred Rendering)理解为先将所有物体都先绘制到屏幕空间的缓冲（即<strong>G-buffer</strong>，Geometric Buffer，几何缓冲区）中，再逐光源对该缓冲进行着色的过程，从而避免了因计算被深度测试丢弃的片元的着色而产生的不必要的开销。也就是说延迟渲染<strong>基本思想</strong>是，<strong>先执行深度测试（应该也包括其他测试），再进行着色计算</strong>，将本来在物空间（三维空间）进行光照计算放到了<strong>像空间</strong>（二维空间）进行处理。</p><p>对应于正向渲染O(m*n)的 复杂度，经典的延迟渲染复杂度为O(n+m)。</p><h2 id="c-1-流程"><a href="#c-1-流程" class="headerlink" title="c.1). 流程"></a>c.1). 流程</h2><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/Deffer_Workflow.png" alt="Deffer_Workflow" style="zoom:33%;"></p><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/Deffer_Workflow2.jpg" alt="Deffer_Workflow2"></p><p>可以将延迟渲染理解为两个Pass的过程：</p><ol><li><p><strong>几何处理阶段(Geometry Pass)。</strong>这个阶段中，我们获取对象的各种<strong>几何信息</strong>（Position、Normal、Albedo、Specular等），并将第二步所需的各种数据储存（也就是渲染）到多个<strong>G-buffer</strong>中；</p><ul><li>由于有深度测试，所以最终写入G-buffer中的，都是离摄像机最近的片元的集合属性，这就意味着，在G-buffer中的片元必定要进行光照计算。</li></ul></li><li><p><strong>光照处理阶段(Lighting Pass)。</strong>在这个pass中，我们只需渲染出一个屏幕大小的二维矩形，使用第一步在G-buffer中存储的数据对此矩阵的每一个片段<strong>计算场景的光照</strong>；光照计算的过程还是和正向渲染以前一样，只是现在<strong>我们需要从对应的G-buffer而不是顶点着色器(和一些uniform变量)那里获取输入变量了</strong>。</p></li></ol><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/Deffer_Workflow3.jpg" alt="Deffer_Workflow3"></p><h2 id="c-2-延迟渲染的优缺点"><a href="#c-2-延迟渲染的优缺点" class="headerlink" title="c.2). 延迟渲染的优缺点"></a>c.2). 延迟渲染的优缺点</h2><ul><li><p><strong>优点：</strong></p><ol><li>Complexity: O(#fragment <em> #light) -&gt; O(#vis. frag. </em> #light)</li><li>只渲染可见的像素，节省计算量</li><li>用更少的shader</li><li>对后处理支持良好（例如深度信息：直接拿G-buffer中的就行。而前向渲染需要单独Pass再渲染一张深度图）</li><li>在大量光源的场景优势尤其明显；</li></ol></li><li><p><strong>缺点：</strong></p><ol><li>内存开销较大，且占用了大量的显存带宽；<ul><li>需要传递G-Buffer；</li><li>有时需要用到G-Buffer的信息，如深度图做后处理，那将不会进行Clear；</li></ul></li><li>只能用同一套Lighting Pass；</li><li>对透明物体的渲染存在问题。在这点上需要结合正向渲染进行渲染；</li><li>对多重采样抗锯齿（MultiSampling Anti-Aliasing, MSAA）等硬件抗锯齿的支持不友好，主要因为需开启MRT；<ul><li>MSAA是依赖于子像素，而Deffered shading<strong>处在光栅化之后（单个像素内值相等）</strong>，传输数据是通过G-Buffer；</li><li>但可使用TAA</li></ul></li></ol><p><a href="https://www.zhihu.com/question/20236638/answer/44821615">问FXAA、FSAA与MSAA有什么区别？效果和性能上哪个好？ - 文刀秋二的回答 - 知乎</a></p><p><a href="https://catlikecoding.com/unity/tutorials/rendering/part-13/">https://catlikecoding.com/unity/tutorials/rendering/part-13/</a></p></li></ul><h1 id="d-Tiled-Shading"><a href="#d-Tiled-Shading" class="headerlink" title="d). Tiled Shading"></a>d). Tiled Shading</h1><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/Tiled Shading.png" alt="Tiled Shading"></p><ul><li>基于Deferred Shading</li><li>并不是所有光源都会对Tile有贡献</li><li>Complexity: O(#vis. frag. <em> #light) -&gt; O(#vis. frag. </em> avg #light per tile)</li></ul><h1 id="e-Clustered-Shading-群组渲染"><a href="#e-Clustered-Shading-群组渲染" class="headerlink" title="e). Clustered Shading(群组渲染)"></a>e). Clustered Shading(群组渲染)</h1><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/ClusteredShading.png" alt="ClusteredShading"></p><ul><li>在Tiled Shading的基础上再对Depth分段；</li><li>Complexity: O(#vis. frag. <em> avg #light per tile) -&gt; O(#vis. frag. </em> avg #light per cluster)</li></ul><h1 id="f-Level-of-Detail-Solutions"><a href="#f-Level-of-Detail-Solutions" class="headerlink" title="f). Level of Detail Solutions"></a>f). Level of Detail Solutions</h1><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/LoD01.png" alt="LoD01"></p><ul><li>cascaded: 级联</li></ul><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/LoD02.png" alt="LoD02"></p><ul><li>生成时，不同Level之间有一定重叠，用于过渡时Lerp</li></ul><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/LoD03.png" alt="LoD03"></p><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/LoD04.png" alt="LoD04"></p><h1 id="g-Global-Illumination-Solutions"><a href="#g-Global-Illumination-Solutions" class="headerlink" title="g). Global Illumination Solutions"></a>g). Global Illumination Solutions</h1><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/GI01.png" alt="GI01"></p><p><img src="/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/GI02.png" alt="GI02"></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;a-Anti-Aliasing&quot;&gt;&lt;a href=&quot;#a-Anti-Aliasing&quot; class=&quot;headerlink&quot; title=&quot;a). Anti-Aliasing&quot;&gt;&lt;/a&gt;a). Anti-Aliasing&lt;/h1&gt;&lt;h2 id=&quot;a-1-Temporal-Anti-Aliasing-TAA&quot;&gt;&lt;a href=&quot;#a-1-Temporal-Anti-Aliasing-TAA&quot; class=&quot;headerlink&quot; title=&quot;a.1). Temporal Anti-Aliasing (TAA)&quot;&gt;&lt;/a&gt;a.1). Temporal Anti-Aliasing (TAA)&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;复用先前帧的样本&lt;/strong&gt;，假设画面不动，就可在单个像素内随时间规律移动感知点，进行（加权）平均；&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;为何规律移动感知点：&lt;/strong&gt; 随机采样会引入高频噪声；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;如画面移动，则和频域降噪相同，使用Motion vector找到对应像素，再规律移动感知点。同时也可引入Clamp和Detection的操作；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/TAA01.png&quot; alt=&quot;TAA01&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/TAA02.png&quot; alt=&quot;TAA02&quot; style=&quot;zoom: 33%;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;a-2-MSAA-vs-SSAA&quot;&gt;&lt;a href=&quot;#a-2-MSAA-vs-SSAA&quot; class=&quot;headerlink&quot; title=&quot;a.2). MSAA vs. SSAA&quot;&gt;&lt;/a&gt;a.2). MSAA vs. SSAA&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;SSAA：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;相当于用更大分辨率渲染后降采样，做2倍的SSAA，相当于一个像素做4次shading；&lt;/li&gt;
&lt;li&gt;质量最好，但是性能开销大；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;MSAA：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;在一个像素内，&lt;strong&gt;同一个图元只着色一次&lt;/strong&gt;；(如图，0、2、3为图元A，着色一次(左边的绿点)；1为图元B，着色一次；)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;因此，MSAA会维护一张表，表中记录当前感知点记录的color(albedo?) 和 深度&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/MSAA01.png&quot; alt=&quot;MSAA01&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在像素间复用样本；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/MSAA02.png&quot; alt=&quot;MSAA02&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;a-3-Image-Based-Anti-Aliasing-Solution&quot;&gt;&lt;a href=&quot;#a-3-Image-Based-Anti-Aliasing-Solution&quot; class=&quot;headerlink&quot; title=&quot;a.3). Image Based Anti-Aliasing Solution&quot;&gt;&lt;/a&gt;a.3). Image Based Anti-Aliasing Solution&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/ImageBasedAA.png&quot; alt=&quot;ImageBasedAA&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;a-4-Note&quot;&gt;&lt;a href=&quot;#a-4-Note&quot; class=&quot;headerlink&quot; title=&quot;a.4). Note&quot;&gt;&lt;/a&gt;a.4). Note&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;font color=&quot;red&quot;&gt;G-buffers一定不能做抗锯齿&lt;/font&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Games202" scheme="https://whitetail-o.github.io/categories/Games202/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="Games202" scheme="https://whitetail-o.github.io/tags/Games202/"/>
    
  </entry>
  
  <entry>
    <title>Games202-6 Real-time Ray-Tracing</title>
    <link href="https://whitetail-o.github.io/2023/02/19/Games202_06_Real-time%20Ray-Tracing/"/>
    <id>https://whitetail-o.github.io/2023/02/19/Games202_06_Real-time%20Ray-Tracing/</id>
    <published>2023-02-19T12:42:10.000Z</published>
    <updated>2023-03-17T05:34:38.145Z</updated>
    
    <content type="html"><![CDATA[<h1 id="a-Introduction"><a href="#a-Introduction" class="headerlink" title="a). Introduction"></a>a). Introduction</h1><p><strong>Real-time Ray-Tracing vs. Ray-Tracing:</strong></p><ul><li><p>Real-time Ray-Tracing == <strong>1/few sample per pixel(SPP)</strong></p></li><li><p><strong>Key technology:</strong> Denoising(降噪)</p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/RTRT00.png" alt="RTRT00" style="zoom: 50%;"></p></li></ul><p><strong>一个光路样本（1 SPP path tracing）：</strong></p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/RTRT01.png" alt="RTRT01" style="zoom:50%;"></p><ul><li><p><strong>第一步是Rasterization，而不是Ray的原因：</strong> 从摄影机发出经过各个像素的光线，即等同于进行一次光栅化，找到Primary hitpoint</p><ul><li><p>第一步如做光线求交，则为<strong>光线投射（Ray Casting）</strong>。而<strong>光线投射和光栅化没有本质区别</strong>（都是渲染一点的DI，只不过相当于深度测试被光线求交替代了）</p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/光线投射.png" alt="光线投射" style="zoom: 50%;"></p><blockquote id="fn_Ray Casting"><sup>Ray Casting</sup>. 注意和光线追踪的区别，Ray Casting基本只求交一次，而不迭代追踪<a href="#reffn_Ray Casting" title="Jump back to footnote [Ray Casting] in the text."> &#8617;</a></blockquote></li></ul></li></ul><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/RTRT02.png" alt="RTRT02" style="zoom:50%;"></p><ul><li>传统的降噪方式不是效果不好，就是太慢或不靠谱</li></ul><h1 id="b-Temporal-denoising-时域降噪"><a href="#b-Temporal-denoising-时域降噪" class="headerlink" title="b). Temporal denoising(时域降噪)"></a>b). Temporal denoising(时域降噪)</h1><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/Denoising01.png" alt="Denoising01" style="zoom:50%;"></p><p><strong>Key idea:</strong></p><ul><li>复用<strong>前面已经降噪过的一帧</strong>；</li><li>使用<strong>motion vector</strong>来找到先前的位置；</li><li>本质上是提高采样率；</li></ul><h2 id="b-1-G-Buffer"><a href="#b-1-G-Buffer" class="headerlink" title="b.1). G-Buffer"></a>b.1). G-Buffer</h2><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/G-Buffer01.png" alt="G-Buffer01"></p><h2 id="b-2-Back-Projection"><a href="#b-2-Back-Projection" class="headerlink" title="b.2). Back Projection"></a>b.2). Back Projection</h2><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/BackProj01.png" alt="BackProj01" style="zoom:50%;"></p><ul><li><strong>Key idea：</strong>不同帧之间相同的点，意味着有着<strong>相同的世界位置（如不移动）或模型空间位置</strong>；</li></ul><p><strong>How：</strong></p><ul><li>如果世界坐标 $s$ 存在于G-Buffer中，即可直接使用；</li><li>否则，$s = M^{-1}V^{-1}P^{-1}E^{-1}x$ （$E$ 为视口变换，即NDF到Viewport/Screen）</li><li>运动（Motion）情况已知，$s’ = T^{-1} s$，$s’$ 为运动前的位置，$T$ 为运动的矩阵</li><li>在 $i-1$ 帧，$s$ 对应的屏幕空间位置为 $x’=P’V’M’s’$</li></ul><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/BackProj03.png" alt="BackProj03" style="zoom:50%;"></p><span id="more"></span><h2 id="b-3-issues"><a href="#b-3-issues" class="headerlink" title="b.3). issues"></a>b.3). issues</h2><ul><li><p>Failure case 1: 切换场景</p><ul><li><strong>burn-in period</strong>(即需要一定时间积累降噪质量足够好的帧，如UE中的burn-in)</li></ul></li><li><p>Failure case 2: walking backwards in a hallway</p><ul><li><strong>screen space issue</strong>（当前帧出现上一帧屏幕外的信息）</li></ul></li><li><p>Failure case 3: suddenly appearing background</p><ul><li><p><strong>disocclusion</strong>（上一帧被遮挡的物体，当前帧未被遮挡）</p></li><li><p>可能造成<strong>拖尾（lagging）</strong></p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/TemporalFailure01.png" alt="TemporalFailure01" style="zoom: 67%;"></p></li></ul></li></ul><h2 id="b-4-Adjustments-to-Temp-Failure"><a href="#b-4-Adjustments-to-Temp-Failure" class="headerlink" title="b.4). Adjustments to Temp. Failure"></a>b.4). Adjustments to Temp. Failure</h2><script type="math/tex; mode=display">\bar{C}^{(i)}=\alpha \bar{C}^{(i)}+(1-\alpha) C^{(i-1)}</script><ul><li><p>Clamping</p><ul><li>Clamp上一帧的信息，使其接近当前帧。即Clamp $C^{(i-1)}$ </li></ul></li><li><p>Detection(即不符合要求时，不使用Temp. denoising)</p><ul><li>Use e.g. object ID to detect temporal failure（ID通道）</li><li>调整$\alpha$，上一帧不可靠时，调高$\alpha$<ul><li>Problem：重新引入更多噪声；</li></ul></li><li>可能需要增强空域降噪；</li></ul></li></ul><h2 id="b-5-More-Temporal-Failure"><a href="#b-5-More-Temporal-Failure" class="headerlink" title="b.5). More Temporal Failure"></a>b.5). More Temporal Failure</h2><ul><li><p>Detaching/lagging shadows(阴影拖尾)</p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/Failure01.png" alt="Failure01"></p></li><li><p>Temporal failure can also happen in shading</p><ul><li><p>如反射滞后；</p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/Failure02.png" alt="Failure02" style="zoom:67%;"></p></li></ul></li></ul><h1 id="c-Implementation-实现"><a href="#c-Implementation-实现" class="headerlink" title="c). Implementation(实现)"></a>c). Implementation(实现)</h1><p>eg. Gaussian filter</p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/Implementation01.png" alt="Implementation01"></p><ul><li>滤波核可以不归一化，但对于结果需要归一化；</li></ul><h2 id="c-1-Bilateral-filtering-双边滤波"><a href="#c-1-Bilateral-filtering-双边滤波" class="headerlink" title="c.1). Bilateral filtering(双边滤波)"></a>c.1). Bilateral filtering(双边滤波)</h2><p><strong>观察：</strong></p><ul><li>高斯模糊会将边界模糊，但我们需要保留边界；</li><li>边界 = 颜色差异大</li></ul><p><strong>目的：</strong></p><ul><li><p>模糊同时保留边界；</p></li><li><p>当像素$j$ 和像素$i$ 颜色差异大时，$j$贡献变少（权重变小）</p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/BilateralFiltering01.png" alt="BilateralFiltering01"></p><ul><li>像素$a$ 位置为$(i,j)$，像素$b$ 位置为$(k,l)$；</li><li>$I(i,j)$ 表示$(i,j)$位置的像素值；</li><li>$\sigma$ 控制对应项的作用范围，其值越大，对应项的局部影响<strong>范围</strong>就越大，分子变化影响越小</li><li>类似于两个不同形式的高斯核<strong>相乘</strong>（指数相加），即两个标准（距离，颜色），2 metrics</li><li>可以根据需求调整，如较为看重color dist. 对weight的影响，就可以将第二项的2 调为 1；</li></ul></li></ul><h2 id="c-2-Joint-Bilateral-filtering-联合双边滤波"><a href="#c-2-Joint-Bilateral-filtering-联合双边滤波" class="headerlink" title="c.2). Joint Bilateral filtering(联合双边滤波)"></a>c.2). Joint Bilateral filtering(联合双边滤波)</h2><p><strong>观察：</strong></p><ul><li>Gaussian filtering: 1 metric (distance)</li><li>Bilateral filtering: 2 metrics (position dist. &amp; color dist.)</li><li>因此，我们可以<strong>考虑更多的标准（metric），丰富滤波核，进行滤波（Key idea）</strong></li></ul><p><strong>定义：</strong>Joint Bilateral filtering是一系列考虑更多标准的滤波方法。</p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/JointBilateralFiltering01.png" alt="JointBilateralFiltering01"></p><p><strong>Note:</strong></p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/JointBilateralFiltering02.png" alt="JointBilateralFiltering02"></p><hr><h3 id="c-2-1-Example"><a href="#c-2-1-Example" class="headerlink" title="c.2.1). Example"></a>c.2.1). Example</h3><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/JointBilateralFiltering_Example01.png" alt="JointBilateralFiltering_Example01"></p><h2 id="c-2-Large-Filters"><a href="#c-2-Large-Filters" class="headerlink" title="c.2). Large Filters"></a>c.2). Large Filters</h2><p>对于大的滤波核，性能开销会非常大(e.g. 64x64)</p><h3 id="Solution-1-Separate-Passes"><a href="#Solution-1-Separate-Passes" class="headerlink" title="Solution 1: Separate Passes"></a>Solution 1: Separate Passes</h3><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/Large_Solution01.png" alt="Large_Solution01"></p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/Large_Solution02.png" alt="Large_Solution02"></p><ul><li>将NxN大小的2D高斯核，拆分为 1xN 和 Nx1 的1D高斯核。通过两个Pass进行滤波；（<strong>注意：</strong> 并不是所有滤波核都可拆分）</li></ul><hr><p><strong>原因：</strong></p><script type="math/tex; mode=display">w(i, j, k, l)=\exp \left(-\frac{(i-k)^{2}+(j-l)^{2}}{2 \sigma_{d}^{2}}\right)</script><p>2D高斯核的形式是可拆分的，如下：</p><script type="math/tex; mode=display">G_{2D}(x, y) = G_{1D}(x) \cdot G_{1D}(y)</script><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/Large_Solution03.png" alt="Large_Solution03"></p><ul><li><strong><font color="red">理论上</font>，双边滤波/联合双边滤波是不可拆分的</strong>（实现上，只要滤波核不特别大，如超过32x32，就可采用拆分方法）</li></ul><hr><h3 id="Solution-2-Progressively-Growing-Sizes-逐步增加尺寸"><a href="#Solution-2-Progressively-Growing-Sizes-逐步增加尺寸" class="headerlink" title="Solution 2: Progressively Growing Sizes(逐步增加尺寸)"></a>Solution 2: Progressively Growing Sizes(逐步增加尺寸)</h3><p><strong>介绍：</strong> 逐Pass增加filter (间隙的)size，类似空洞卷积。第一次间隙为0，第二次间隙为1……</p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/ATW01.png" alt="ATW01"></p><hr><p><strong>原因：</strong></p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/ATW02.png" alt="ATW02"></p><ul><li><p><strong>逐步增加尺寸：</strong> 逐步减小信号的最高频率；</p></li><li><p><strong>增加采样间隙：</strong> 降低采样频率，频谱搬移距离逐渐减小；</p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/频谱搬移.png" alt="频谱搬移" style="zoom: 67%;"></p></li></ul><ul><li><strong>逻辑：</strong> 减少信号高频部分，并增大采样间隙（频谱搬移，将信号左边界搬移到有边界），使得不会产生信号混叠；</li></ul><hr><h1 id="d-Outlier-Removal-and-temporal-clamping"><a href="#d-Outlier-Removal-and-temporal-clamping" class="headerlink" title="d). Outlier Removal(and temporal clamping)"></a>d). Outlier Removal(and temporal clamping)</h1><h2 id="d-1-Introduction"><a href="#d-1-Introduction" class="headerlink" title="d.1). Introduction"></a>d.1). Introduction</h2><p><strong>Outlier:</strong> 场景中一些特别亮的噪声，即萤火虫噪声；</p><ul><li><strong>出现原因：</strong> 蒙特卡洛积分时，由于采样率不足，会出现特别亮和特别暗的点；</li><li><p>无法用滤波解决，滤波后仍会存在，甚至从一点变为亮的色块（<strong>blocky</strong>）</p></li><li><p><strong>解决方法：</strong> Outlier removal(clamp)</p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/OutlierRemoval01.png" alt="OutlierRemoval01"></p></li></ul><p><strong>Outlier removal:</strong></p><ul><li><strong>应用时间：</strong> 滤波<strong>之前</strong>（但会打破能量守恒，如不想打破就得提高采样率）</li></ul><h2 id="d-2-实现"><a href="#d-2-实现" class="headerlink" title="d.2). 实现"></a>d.2). 实现</h2><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/OutlierRemoval02.png" alt="OutlierRemoval02"></p><ul><li>$\mu$: 均值</li><li>$\sigma$: 标准差</li><li>即将各个点Clamp到一定范围内（如担心光源被clamp掉，可以先不Render光源。Outlier removal之后再加上光源）</li></ul><p><strong>之前提到的Temporal Clamping同理：</strong></p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/OutlierRemoval03.png" alt="OutlierRemoval03"></p><ul><li>将上一帧Clamp向（经过空域降噪）这一帧</li></ul><h1 id="e-SVGF-Spatiotemporal-Variance-Guided-Filtering"><a href="#e-SVGF-Spatiotemporal-Variance-Guided-Filtering" class="headerlink" title="e). SVGF(Spatiotemporal Variance-Guided Filtering)"></a>e). SVGF(Spatiotemporal Variance-Guided Filtering)</h1><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/SVGF01.png" alt="SVGF01"></p><ul><li>降噪效果好，但仍然有拖影、反射滞后等问题；</li><li>在Overblue和更多的noise之间，选择了Overblur</li></ul><h2 id="e-1-SVGF-—-Joint-Bilateral-Filtering"><a href="#e-1-SVGF-—-Joint-Bilateral-Filtering" class="headerlink" title="e.1). SVGF — Joint Bilateral Filtering"></a>e.1). SVGF — Joint Bilateral Filtering</h2><h3 id="e-1-1-Depth"><a href="#e-1-1-Depth" class="headerlink" title="e.1.1). Depth"></a>e.1.1). Depth</h3><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/SVGF_Depth.png" alt="SVGF_Depth"></p><ul><li>A、B在同平面深度却差异很大，使得互相之间贡献少。因此，在分母中引入梯度$\nabla z(p)$ ，该梯度为<strong>深度在对应点法线方向的变化率</strong>（注意：梯度为向量，其方向为法线方向；）。<ul><li>当平面几乎垂直于屏幕时，$\nabla z(p)$ 变大，使得深度差异对权重的影响变小；</li></ul></li></ul><h3 id="e-1-2-Normal"><a href="#e-1-2-Normal" class="headerlink" title="e.1.2). Normal"></a>e.1.2). Normal</h3><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/SVGF_Normal.png" alt="SVGF_Normal"></p><ul><li>应使用几何法线，而不使用经过法线扰动的Normal</li></ul><h3 id="e-1-3-Luminance-grayscale-color-value"><a href="#e-1-3-Luminance-grayscale-color-value" class="headerlink" title="e.1.3). Luminance(grayscale color value)"></a>e.1.3). Luminance(grayscale color value)</h3><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/SVGF_Color.png" alt="SVGF_Color"></p><ul><li><p>使用亮度值；</p></li><li><p><strong>Variance:</strong></p><ul><li><p><strong>Step1:</strong> 计算<strong>空域</strong>中<strong>7x7的方差</strong>；</p></li><li><p><strong>Step2:</strong> 通过<strong>motion vectors</strong>在<strong>时域</strong>上<strong>平均</strong>（类似时域降噪）；</p></li><li><strong>Step3:</strong> 对平均后的结果再在<strong>空域</strong>上<strong>3x3的范围内平均</strong>；</li><li>即，<strong>spatial filter —&gt; temporal filter —&gt; spatial filter</strong></li></ul></li></ul><h1 id="f-RAE-Recurrent-AutoEncoder"><a href="#f-RAE-Recurrent-AutoEncoder" class="headerlink" title="f). RAE(Recurrent AutoEncoder)"></a>f). RAE(Recurrent AutoEncoder)</h1><ul><li>一种结构，对Monte carlo路径追踪得到的结果进行reconstruction-对RTRT做滤波。</li><li>后期处理，把noise的图变clean。</li><li>使用G-buffers</li><li>神经网络会自动将temporal的结果累积起来</li></ul><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/RAE.png" alt="RAE"></p><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/RAE02.png" alt="RAE02"></p><h1 id="g-Comparison"><a href="#g-Comparison" class="headerlink" title="g). Comparison"></a>g). Comparison</h1><p><img src="/2023/02/19/Games202_06_Real-time%20Ray-Tracing/Comparison.png" alt="Comparison"></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;a-Introduction&quot;&gt;&lt;a href=&quot;#a-Introduction&quot; class=&quot;headerlink&quot; title=&quot;a). Introduction&quot;&gt;&lt;/a&gt;a). Introduction&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;Real-time Ray-Tracing vs. Ray-Tracing:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Real-time Ray-Tracing == &lt;strong&gt;1/few sample per pixel(SPP)&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Key technology:&lt;/strong&gt; Denoising(降噪)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/19/Games202_06_Real-time%20Ray-Tracing/RTRT00.png&quot; alt=&quot;RTRT00&quot; style=&quot;zoom: 50%;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;一个光路样本（1 SPP path tracing）：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/19/Games202_06_Real-time%20Ray-Tracing/RTRT01.png&quot; alt=&quot;RTRT01&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;第一步是Rasterization，而不是Ray的原因：&lt;/strong&gt; 从摄影机发出经过各个像素的光线，即等同于进行一次光栅化，找到Primary hitpoint&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;第一步如做光线求交，则为&lt;strong&gt;光线投射（Ray Casting）&lt;/strong&gt;。而&lt;strong&gt;光线投射和光栅化没有本质区别&lt;/strong&gt;（都是渲染一点的DI，只不过相当于深度测试被光线求交替代了）&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/19/Games202_06_Real-time%20Ray-Tracing/光线投射.png&quot; alt=&quot;光线投射&quot; style=&quot;zoom: 50%;&quot;&gt;&lt;/p&gt;
&lt;blockquote id=&quot;fn_Ray Casting&quot;&gt;
&lt;sup&gt;Ray Casting&lt;/sup&gt;. 注意和光线追踪的区别，Ray Casting基本只求交一次，而不迭代追踪&lt;a href=&quot;#reffn_Ray Casting&quot; title=&quot;Jump back to footnote [Ray Casting] in the text.&quot;&gt; &amp;#8617;&lt;/a&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/19/Games202_06_Real-time%20Ray-Tracing/RTRT02.png&quot; alt=&quot;RTRT02&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;传统的降噪方式不是效果不好，就是太慢或不靠谱&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;b-Temporal-denoising-时域降噪&quot;&gt;&lt;a href=&quot;#b-Temporal-denoising-时域降噪&quot; class=&quot;headerlink&quot; title=&quot;b). Temporal denoising(时域降噪)&quot;&gt;&lt;/a&gt;b). Temporal denoising(时域降噪)&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2023/02/19/Games202_06_Real-time%20Ray-Tracing/Denoising01.png&quot; alt=&quot;Denoising01&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Key idea:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;复用&lt;strong&gt;前面已经降噪过的一帧&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;使用&lt;strong&gt;motion vector&lt;/strong&gt;来找到先前的位置；&lt;/li&gt;
&lt;li&gt;本质上是提高采样率；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;b-1-G-Buffer&quot;&gt;&lt;a href=&quot;#b-1-G-Buffer&quot; class=&quot;headerlink&quot; title=&quot;b.1). G-Buffer&quot;&gt;&lt;/a&gt;b.1). G-Buffer&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/2023/02/19/Games202_06_Real-time%20Ray-Tracing/G-Buffer01.png&quot; alt=&quot;G-Buffer01&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;b-2-Back-Projection&quot;&gt;&lt;a href=&quot;#b-2-Back-Projection&quot; class=&quot;headerlink&quot; title=&quot;b.2). Back Projection&quot;&gt;&lt;/a&gt;b.2). Back Projection&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/2023/02/19/Games202_06_Real-time%20Ray-Tracing/BackProj01.png&quot; alt=&quot;BackProj01&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Key idea：&lt;/strong&gt;不同帧之间相同的点，意味着有着&lt;strong&gt;相同的世界位置（如不移动）或模型空间位置&lt;/strong&gt;；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;How：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果世界坐标 $s$ 存在于G-Buffer中，即可直接使用；&lt;/li&gt;
&lt;li&gt;否则，$s = M^{-1}V^{-1}P^{-1}E^{-1}x$ （$E$ 为视口变换，即NDF到Viewport/Screen）&lt;/li&gt;
&lt;li&gt;运动（Motion）情况已知，$s’ = T^{-1} s$，$s’$ 为运动前的位置，$T$ 为运动的矩阵&lt;/li&gt;
&lt;li&gt;在 $i-1$ 帧，$s$ 对应的屏幕空间位置为 $x’=P’V’M’s’$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/19/Games202_06_Real-time%20Ray-Tracing/BackProj03.png&quot; alt=&quot;BackProj03&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Games202" scheme="https://whitetail-o.github.io/categories/Games202/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="Ray-Tracing" scheme="https://whitetail-o.github.io/tags/Ray-Tracing/"/>
    
    <category term="Games202" scheme="https://whitetail-o.github.io/tags/Games202/"/>
    
    <category term="Denoise" scheme="https://whitetail-o.github.io/tags/Denoise/"/>
    
  </entry>
  
  <entry>
    <title>Games202-5 Real-time Physically-based Materials</title>
    <link href="https://whitetail-o.github.io/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/"/>
    <id>https://whitetail-o.github.io/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/</id>
    <published>2023-02-18T10:42:10.000Z</published>
    <updated>2023-03-17T05:34:50.468Z</updated>
    
    <content type="html"><![CDATA[<p>Q1：在金属或高光工作流中，对于非导体材质（电介质）默认其零度菲涅尔值$R_0$ 为4%，那么按PBR来，他怎么会有颜色呢；还是说非导体的albedo就是$R_0$ ? 按作业中来好像albedo就是 $R_0$ ，后续还得深挖一下；</p><p>Q2：Jacobian 项，方向导数需要去了解更多</p><h1 id="a-Introduction"><a href="#a-Introduction" class="headerlink" title="a). Introduction"></a>a). Introduction</h1><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/PBR_Intro00.png" alt="PBR_Intro00"></p><ul><li>尽管实时渲染中的PBR，不一定完全基于物理。如Disney principled BRDFs (artist friendly but still not PBR)</li></ul><h1 id="b-Microfacet-BRDF"><a href="#b-Microfacet-BRDF" class="headerlink" title="b). Microfacet BRDF"></a>b). Microfacet BRDF</h1><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/MicrofacetBRDF.png" alt="MicrofacetBRDF"></p><ul><li>菲涅尔项；</li><li>Shadowing-masking term<ul><li>考虑微表面之间的遮挡和阴影；</li><li>当光线几乎平行与表面入射时(Grazing angle)，微表面之间遮挡变多</li></ul></li><li>Disterbution of normals(法线分布)</li></ul><span id="more"></span><h2 id="b-1-The-Fresnel-Term"><a href="#b-1-The-Fresnel-Term" class="headerlink" title="b.1). The Fresnel Term"></a>b.1). The Fresnel Term</h2><ul><li><strong>本质上是考虑能量的吸收和反射</strong>（即考虑BRDF就会有因为颜色的合理的能量损失）</li></ul><table frame="void">    <tr>    <td><center><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/绝缘体_Fresnel.png" alt="绝缘体_Fresnel" height="250"></center></td>    <td><center><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/导体(金属)_Fresnel.png" alt="导体(金属)_Fresnel" height="250"></center></td>    </tr></table><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/FresnelTerm.png" alt="FresnelTerm"></p><hr><h2 id="b-2-Normal-Distribution-Function-NDF"><a href="#b-2-Normal-Distribution-Function-NDF" class="headerlink" title="b.2). Normal Distribution Function(NDF)"></a>b.2). Normal Distribution Function(NDF)</h2><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/NormalDistribution.png" alt="NormalDistribution"></p><ul><li>NDF从简单（如Gloosy）变为复杂（如Diffuse），就类似于把微表面高度场拉大；</li></ul><ul><li><p><strong>类型：</strong></p><ul><li>Beckmann, GGX, etc.</li><li>Detailed models [Yan 2014, 2016, 2018, …]</li></ul><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/NDF01.png" alt="NDF01"></p></li></ul><h3 id="b-2-1-Beckmann-NDF"><a href="#b-2-1-Beckmann-NDF" class="headerlink" title="b.2.1). Beckmann NDF"></a>b.2.1). Beckmann NDF</h3><p><strong>Beckmann NDF:</strong></p><ul><li><p>和高斯函数相似</p></li><li><p>Project Solid angel上积分为1</p></li><li><p>定义在Slope space（坡度空间）</p><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/NDF_Beckmann_01.png" alt="NDF_Beckmann_01" style="zoom:50%;"></p><ul><li><strong>原因：</strong> 在Slope space（法线交点处切线平面）中Support无限大，任意位置对应的夹角不会超过90°，<strong>保证微表面不会朝下</strong></li></ul></li></ul><script type="math/tex; mode=display">D(h)=\frac{e^{-\frac{\tan ^{2} \theta_{h}}{\alpha^{2}}}}{\pi \alpha^{2} \cos ^{4} \theta_{h}}</script><ul><li><strong>$\alpha$ ：Roughness的平方</strong></li><li><strong>$\theta_{h}$ ：半角向量和（宏观）法线的夹角</strong></li></ul><h3 id="b-2-2-GGX-or-Trowbridge-Reitz-TR"><a href="#b-2-2-GGX-or-Trowbridge-Reitz-TR" class="headerlink" title="b.2.2). GGX (or Trowbridge-Reitz, TR)"></a>b.2.2). GGX (or Trowbridge-Reitz, TR)</h3><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/NDF_GGX01.png" alt="NDF_GGX01"></p><ul><li><p><strong>Long tail:</strong> 使得光线过度更为自然，如高光过渡柔和</p><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/NDF_GGX02.png" alt="NDF_GGX02"></p></li></ul><h3 id="b-2-3-GGGX-GTR"><a href="#b-2-3-GGGX-GTR" class="headerlink" title="b.2.3). GGGX(GTR)"></a>b.2.3). GGGX(GTR)</h3><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/NDF_GTR.png" alt="NDF_GTR"></p><hr><h2 id="b-3-Shadowing-Masking-Term"><a href="#b-3-Shadowing-Masking-Term" class="headerlink" title="b.3). Shadowing-Masking Term"></a>b.3). Shadowing-Masking Term</h2><p> <strong>Why is it important?</strong></p><ul><li><p>如没$G$ 项，在grazing angle时，物体表面会发亮；</p><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/MicrofacetBRDF_G01.png" alt="MicrofacetBRDF_G01"></p></li></ul><h3 id="b-3-1-The-Smith-shadowing-masking-term"><a href="#b-3-1-The-Smith-shadowing-masking-term" class="headerlink" title="b.3.1). The Smith shadowing-masking term"></a>b.3.1). The Smith shadowing-masking term</h3><ul><li><p><strong>假设：</strong> Shadow和Masking无关，即</p><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/Smith_01.png" alt="Smith_01"></p></li></ul><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/Smith_02.png" alt="Smith_02"></p><h3 id="b-3-2-Issues-Missing-energy"><a href="#b-3-2-Issues-Missing-energy" class="headerlink" title="b.3.2). Issues(Missing energy)"></a>b.3.2). Issues(Missing energy)</h3><ul><li><p><strong>原因：</strong>由于Shadowing-masking只考虑了一次弹射，对于<strong>多次弹射</strong>的能量直接舍去，造成能量损失；</p><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/WhiteFurnaceTest.png" alt="WhiteFurnaceTest"></p></li></ul><p>  <img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/ShadowMasking01.png" alt="ShadowMasking01"></p><ul><li><strong>做法：</strong><ul><li>Accurate methods exist [Heitz et al. 2016]<ul><li>主要用于离线渲染，对于RTR过慢；</li></ul></li><li><strong>The Kulla-Conty Approximation</strong><ul><li>Being occluded == next bounce happening</li><li>构造函数去补偿损失的能量；</li><li>求得的BRDF+原BRDF，即可；</li></ul></li></ul></li></ul><h3 id="b-3-3-Kulla-Conty-Approximation"><a href="#b-3-3-Kulla-Conty-Approximation" class="headerlink" title="b.3.3). Kulla-Conty Approximation"></a>b.3.3). Kulla-Conty Approximation</h3><script type="math/tex; mode=display">{L}_{o}(\omega_{o})=\int_{\Omega^{+}}{L}_{i}(\omega_{i})f_{r}(\omega_{i},\omega_{o})cos\theta_i\,\mathrm{d}\omega_{i}</script><ul><li><p>通过对$\mathrm{d}\omega_{i}$ 换元（即立体角）</p><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/SolidAngle_D02.png" alt="SolidAngle_D02" style="zoom: 25%;"></p><p><strong>得到：</strong></p><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/Kulla-Conty.png" alt="Kulla-Conty"></p><ul><li>此处假设各处<strong>入射Radiance（$L_i$） 均匀为1</strong>，因此出射的Radiance也应均匀为1；</li><li>此处假设BRDF的菲涅尔项为1，即无颜色，能量不损失。后续再考虑颜色（<em>？待验证</em>）</li><li>该函数是关于出射角的俯仰角$\theta_o$ 的函数（和方位角无关是因为假设为各项同性）</li></ul></li></ul><h4 id="Key-idea"><a href="#Key-idea" class="headerlink" title="Key idea:"></a>Key idea:</h4><ul><li><p>通过积分可得<strong>需要补偿的能量为 $1 - E(\mu_{o})$；</strong></p></li><li><blockquote><p>该函数是关于出射角的俯仰角$\theta_o$ 的函数（和方位角无关是因为假设为各项同性）</p></blockquote></li><li><p>考虑到对称性质（reciprocity），即入射方向和出射方向互换，Radiance不变，<strong>补偿项的BRDF</strong>形式为$c(1 - E(\mu_{i}))(1 - E(\mu_{o}))$，其中 $c$ 为常数；</p></li></ul><h4 id="补偿项的BRDF（带cos）-c-1-E-mu-i-1-E-mu-o"><a href="#补偿项的BRDF（带cos）-c-1-E-mu-i-1-E-mu-o" class="headerlink" title="补偿项的BRDF（带cos） - $c(1 - E(\mu_{i}))(1 - E(\mu_{o}))$"></a>补偿项的BRDF（带cos） - $c(1 - E(\mu_{i}))(1 - E(\mu_{o}))$</h4><ul><li><p>常数 $c = \frac{1}{\pi(1-E_{avg})}, E_{avg}=2\int_0^1E(\mu)\mu\, \mathrm{d}\mu$ </p></li><li><p><strong>补偿项即为：</strong>  </p><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/Kulla-Conty02.png" alt="Kulla-Conty02"></p><ul><li>$c$ 推导：即让补偿项的BRDF$f_{ms}(\mu_{o},\mu_{i})$ 的积分结果为 $1 - E(\mu_{o})$</li></ul></li></ul><h4 id="预计算"><a href="#预计算" class="headerlink" title="预计算"></a>预计算</h4><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/Kulla-Conty03.png" alt="Kulla-Conty03"></p><ul><li>对于$E_{avg}=2\int_0^1E(\mu)\mu\, \mathrm{d}\mu$ ，只需要得知其Roughness就可求出对应的结果，储存在1D table中；<ul><li>NDF等使用的模型已知；</li></ul></li><li>对于$E(\mu)$ 得知其roughness(确定函数) 和 $\mu$ (确定函数自变量)，即可求出对应结果，储存在2D table中；</li></ul><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/Kulla-Conty_Result.png" alt="Kulla-Conty_Result"></p><blockquote id="fn_Result"><sup>Result</sup>. 原BRDF+(uncolored)补偿项BRDF<a href="#reffn_Result" title="Jump back to footnote [Result] in the text."> &#8617;</a></blockquote><h4 id="Color-energy-loss"><a href="#Color-energy-loss" class="headerlink" title="Color(energy loss)"></a>Color(energy loss)</h4><ul><li>有颜色( vec3的$R_0$项 )，意味着能量被吸收，也是能量合理的损失；</li><li>之前我们做了，不损失能量，无颜色的情况。之后，我们需要计算由于颜色的能量损失；</li></ul><hr><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/Kulla-Conty04.png" alt="Kulla-Conty04"></p><ul><li>定义平均菲涅尔 $F_{avg}$ ，表示<strong>能量参与弹射后，平均反射出多少</strong>；（剩下的被吸收）</li><li>之前定义了 $E_{avg}$ ，表示每次弹射后，<strong>平均有多少能量被看见（即<font color="red">不参与</font>之后的弹射）</strong></li><li>$F_{avg}$ 、$E_{avg}$ 都是三维的向量；</li></ul><ul><li><p><strong>由此可得，</strong></p><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/Kulla-Conty05.png" alt="Kulla-Conty05"></p><ul><li>$(1-E_{avg})$ 表示上一次弹射后，被遮挡未出射的能量；</li><li>等比数列求和；</li><li>求得的color term直接乘上uncolored additional BRDF即可；</li></ul><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/Kulla-Conty_Result02.png" alt="Kulla-Conty_Result02"></p><blockquote id="fn_Result with color"><sup>Result with color</sup>. 原BRDF + colored补偿项BRDF(color term * uncolor补偿项BRDF)<a href="#reffn_Result with color" title="Jump back to footnote [Result with color] in the text."> &#8617;</a></blockquote></li></ul><h1 id="c-Linearly-Transformed-Cosines-LTC-线性变换余弦"><a href="#c-Linearly-Transformed-Cosines-LTC-线性变换余弦" class="headerlink" title="c). Linearly Transformed Cosines(LTC, 线性变换余弦)"></a>c). Linearly Transformed Cosines(LTC, 线性变换余弦)</h1><h2 id="c-1-Introduction"><a href="#c-1-Introduction" class="headerlink" title="c.1). Introduction"></a>c.1). Introduction</h2><p><strong>作用：</strong> Solves the <strong>shading</strong> of <strong>microfacet models</strong> </p><ul><li>主要用于GGX，当然其他NDF也适用；</li><li>No shadows</li><li><strong>Under polygon shaped lighting</strong>(多边形光源)，解决多边形光源的光照积分问题；</li></ul><p><strong>Key idea:</strong></p><ul><li><p>对于<strong>任意一个球面分布函数</strong>，一定可以通过<strong>一个线性变换矩阵</strong>将其变化到<strong>另外一个球面分布函数</strong>(对于任意2D(二维，出射方位角和俯仰角) BRDF lobe can be transformed to a cosine)</p></li><li><p>光源的形状也可以被变换，且积分结果相同；</p></li><li>变换后的积分有<strong>解析解</strong>；</li></ul><p><strong>Ref:</strong></p><p>[1] <a href="pic\LTC.pdf">Real-Time Polygonal-Light Shading with Linearly Transformed Cosines</a> </p><p>[2] <a href="https://zhuanlan.zhihu.com/p/84714602">Real-Time Polygonal-Light with LTC-zhihu</a></p><p>[3] <a href="https://blog.csdn.net/JMXIN422/article/details/124586534?ops_request_misc=%7B%22request%5Fid%22%3A%22167578550616800192233591%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=167578550616800192233591&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-124586534-null-null.142">物理光源：Linearly Transformed Cosines</a></p><p>[4] <a href="https://eheitzresearch.wordpress.com/415-2/">Eric Heitz’s Research Page</a></p><p>[5] <a href="https://blog.csdn.net/qq_35312463/article/details/122514827?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_utm_term~default-0-122514827-blog-77370524.pc_relevant_default&amp;spm=1001.2101.3001.4242.1&amp;utm_relevant_index=3">Global Illumination_Linearly Transformed Cosines (LTC)</a></p><p>[6] <a href="https://blog.csdn.net/qjh5606/article/details/119682254?spm=1001.2101.3001.6650.2&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2-119682254-blog-77370524.pc_relevant_default&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2-119682254-blog-77370524.pc_relevant_default&amp;utm_relevant_index=5">图形学基础|基于LTC的面光源渲染</a></p><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/LTC01.png" alt="LTC01"></p><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/LTC00.png" alt="LTC00"></p><ul><li>$J$ 是雅可比行列式，更进一步的可见Ref，后续论文复现后再进一步补充此处笔记；</li></ul><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/LTC03.png" alt="LTC03"></p><blockquote id="fn_LTC介绍"><sup>LTC介绍</sup>. 来源Ref[3]<a href="#reffn_LTC介绍" title="Jump back to footnote [LTC介绍] in the text."> &#8617;</a></blockquote><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/LTC04.png" alt="LTC04"></p><blockquote id="fn_LTC拟合BRDF"><sup>LTC拟合BRDF</sup>. 来源Ref[6]<a href="#reffn_LTC拟合BRDF" title="Jump back to footnote [LTC拟合BRDF] in the text."> &#8617;</a></blockquote><h1 id="d-Disney’s-Principled-BRDF"><a href="#d-Disney’s-Principled-BRDF" class="headerlink" title="d). Disney’s Principled BRDF"></a>d). Disney’s Principled BRDF</h1><h2 id="d-1-Introduction"><a href="#d-1-Introduction" class="headerlink" title="d.1). Introduction"></a>d.1). Introduction</h2><p><strong>微表面BRDF的缺点</strong></p><ul><li>微表面模型不擅长表示真实（基于物理）的材质；<ul><li>如：Diffuse的情况不好表示，多层材质也难以表示；</li></ul></li><li>微表面模型“are not artist friendly”<ul><li>如： <strong>复折射率（complex index of refraction）</strong>,$n-ik$（详见PBR-White-Paper）</li></ul></li></ul><p><strong>需求：</strong></p><ul><li>Artist friendly，但一定程度上physically-based</li></ul><p><strong>设计原则：</strong></p><ul><li>应该使用直观的而不是物理的参数；</li><li>使用的参数尽可能少；</li><li>参数应该在0~1；</li><li>参数在必要时允许超出0~1的范围；</li><li>参数的所有组合的外观都应该是合理、稳定的；</li></ul><p><img src="/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/Disney00.png" alt="Disney00"></p><blockquote id="fn_Disney’s Principled BRDF"><sup>Disney’s Principled BRDF</sup>. A table showing the effects of individual parameters<a href="#reffn_Disney’s Principled BRDF" title="Jump back to footnote [Disney’s Principled BRDF] in the text."> &#8617;</a></blockquote><ul><li>sheen: 类似天鹅绒，材质表面有一层绒毛，使得其在grazing angle有雾化的效果</li><li>sheenTint: 绒毛的颜色</li><li>clearcoat: 类似清漆（当时做雨滴就用的是clearcoat）</li></ul><h2 id="d-2-Pros-and-Cons"><a href="#d-2-Pros-and-Cons" class="headerlink" title="d.2). Pros and Cons"></a>d.2). Pros and Cons</h2><ul><li>易于理解/控制</li><li>可表现大量材质；</li><li>实现复杂，基本是去拟合PBR材质；</li><li>不基于物理，但视觉上大部分是符合的；</li><li>参数空间巨大；</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;Q1：在金属或高光工作流中，对于非导体材质（电介质）默认其零度菲涅尔值$R_0$ 为4%，那么按PBR来，他怎么会有颜色呢；还是说非导体的albedo就是$R_0$ ? 按作业中来好像albedo就是 $R_0$ ，后续还得深挖一下；&lt;/p&gt;
&lt;p&gt;Q2：Jacobian 项，方向导数需要去了解更多&lt;/p&gt;
&lt;h1 id=&quot;a-Introduction&quot;&gt;&lt;a href=&quot;#a-Introduction&quot; class=&quot;headerlink&quot; title=&quot;a). Introduction&quot;&gt;&lt;/a&gt;a). Introduction&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/PBR_Intro00.png&quot; alt=&quot;PBR_Intro00&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;尽管实时渲染中的PBR，不一定完全基于物理。如Disney principled BRDFs (artist friendly but still not PBR)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;b-Microfacet-BRDF&quot;&gt;&lt;a href=&quot;#b-Microfacet-BRDF&quot; class=&quot;headerlink&quot; title=&quot;b). Microfacet BRDF&quot;&gt;&lt;/a&gt;b). Microfacet BRDF&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/MicrofacetBRDF.png&quot; alt=&quot;MicrofacetBRDF&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;菲涅尔项；&lt;/li&gt;
&lt;li&gt;Shadowing-masking term&lt;ul&gt;
&lt;li&gt;考虑微表面之间的遮挡和阴影；&lt;/li&gt;
&lt;li&gt;当光线几乎平行与表面入射时(Grazing angle)，微表面之间遮挡变多&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Disterbution of normals(法线分布)&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Games202" scheme="https://whitetail-o.github.io/categories/Games202/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="Materials" scheme="https://whitetail-o.github.io/tags/Materials/"/>
    
    <category term="Games202" scheme="https://whitetail-o.github.io/tags/Games202/"/>
    
    <category term="PBR" scheme="https://whitetail-o.github.io/tags/PBR/"/>
    
  </entry>
  
  <entry>
    <title>HPP_Graphics_5.1 PBR基础 BRDF介绍</title>
    <link href="https://whitetail-o.github.io/2023/02/15/HPP_Graphics_5.1_PBR%E5%9F%BA%E7%A1%80/"/>
    <id>https://whitetail-o.github.io/2023/02/15/HPP_Graphics_5.1_PBR%E5%9F%BA%E7%A1%80/</id>
    <published>2023-02-15T12:24:32.000Z</published>
    <updated>2023-03-27T04:20:57.958Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2023/02/15/HPP_Graphics_5.1_PBR%E5%9F%BA%E7%A1%80/Cook-Torrance.png" alt="Cook-Torrance"></p><ul><li>引擎为了提高性能，并且artist friendly，用漫反射项补偿微表面BRDF（打破能量守恒，如想在RTR中实现较为准确的能量补充，应使用Kulla-Conty Approximation）。使得其方便控制，如对于非金属4%的 $F_0$ 也可呈现颜色。并且把BRDF分母的 $\pi$ ,写为4。<ul><li>因此，引擎中PBR的Shading常有以下几项，并通过系数控制其不过与打破能量守恒：<ol><li>直接光照漫反射；</li><li>直接光照镜面反射；</li><li>间接光照漫反射；</li><li>间接光照镜面反射；<ul><li><strong>这样做的结果是容易打破能量守恒，但是artist friendly，而且可表现更多外观。</strong></li></ul></li></ol></li></ul></li><li>更多请看<em>Games202 Real-time Physically-based Materials</em>，或以下Reference</li><li><strong>Ref:</strong><ol><li><a href="https://learnopengl-cn.github.io/07%20PBR/01%20Theory/#pbr">LearnOpenGL CN</a></li><li><a href="https://aras-p.info/texts/files/201403-GDC_UnityPhysicallyBasedShading_notes.pdf">201403-GDC_UnityPhysicallyBasedShading</a></li><li><a href="https://www.zhihu.com/column/game-programming">基于物理的渲染（PBR）白皮书</a></li><li><a href="https://blog.uwa4d.com/archives/1582.html">基于物理的渲染—更精确的微表面分布函数GGX</a></li><li><a href="https://zhuanlan.zhihu.com/p/68025039">如何在Unity中造一个PBR Shader轮子</a></li><li><a href="https://bruop.github.io/ibl/">Image Based Lighting with Multiple Scattering</a></li></ol></li></ul><h1 id="a-Unity中的PBR（Disney‘s-Principled-BRDF）"><a href="#a-Unity中的PBR（Disney‘s-Principled-BRDF）" class="headerlink" title="a). Unity中的PBR（Disney‘s Principled BRDF）"></a>a). Unity中的PBR（Disney‘s Principled BRDF）</h1><p>Unity中Standard Shader基本采用Disney’s Principled BRDF，但有些许不同。Disney’s Principled BRDF可具体看其他文章，如毛星云大佬的PBR白皮书，以下就写一些实现上的不同处和细节。</p><span id="more"></span><h2 id="a-1-直接光照漫反射BRDF"><a href="#a-1-直接光照漫反射BRDF" class="headerlink" title="a.1). 直接光照漫反射BRDF"></a>a.1). 直接光照漫反射BRDF</h2><p>Unity中采用的漫反射BRDF不是Lambertian漫反射，而是Disney开发了的一种用于漫反射的新的经验模型。</p><blockquote><p>Disney表示，Lambert漫反射模型在边缘上通常太暗，而通过尝试添加菲涅尔因子以使其在物理上更合理，但会导致其更暗。</p><p>思路方面，Disney使用了Schlick Fresnel近似，并修改掠射逆反射（grazing retroreflection response）以达到其特定值由粗糙度值确定，而不是简单为0。</p></blockquote><p><img src="/2023/02/15/HPP_Graphics_5.1_PBR%E5%9F%BA%E7%A1%80/5bedec7e9fd8594bb6ffcbff3aaeb9ad.png" alt="5bedec7e9fd8594bb6ffcbff3aaeb9ad"></p><blockquote id="fn_Diffuse BRDF"><sup>Diffuse BRDF</sup>. 上图为Diffuse BRDF<a href="#reffn_Diffuse BRDF" title="Jump back to footnote [Diffuse BRDF] in the text."> &#8617;</a></blockquote><p>为保证shader看起来和Legacy版本差不多亮 ，并且避免在ibl部分对非重要光源做特殊处理，Unity会把分母中的 $\pi$ 拿掉。同时也会在直接光照的镜面反射项上多乘上一个 $\pi$</p><h2 id="a-2-直接光照镜面反射BRDF"><a href="#a-2-直接光照镜面反射BRDF" class="headerlink" title="a.2). 直接光照镜面反射BRDF"></a>a.2). 直接光照镜面反射BRDF</h2><p>镜面反射即采用微表面BRDF，即</p><p><img src="/2023/02/15/HPP_Graphics_5.1_PBR%E5%9F%BA%E7%A1%80/c1b2fc1ec5d1e5c6380ffacfb31cff28.png" alt="c1b2fc1ec5d1e5c6380ffacfb31cff28"></p><ul><li><p>D为微平面分布函数，主要负责镜面反射波峰（specular peak）的形状。</p></li><li><p>F为菲涅尔反射系数（Fresnel reflection coefficient）</p></li><li><p>G为几何衰减（geometric attenuation）/ 阴影项（shadowing factor）</p></li></ul><h3 id="a-2-1-法线分布项（Specular-D）：GTR"><a href="#a-2-1-法线分布项（Specular-D）：GTR" class="headerlink" title="a.2.1). 法线分布项（Specular D）：GTR"></a>a.2.1). 法线分布项（Specular D）：GTR</h3><p>Unity中采用法线分布项为GGX，这里采用GTR模型。</p><p><img src="/2023/02/15/HPP_Graphics_5.1_PBR%E5%9F%BA%E7%A1%80/6fb3430619d35fecc4267b24f0edf6cd.png" alt="6fb3430619d35fecc4267b24f0edf6cd"></p><p>其中，γ取2，即GGX</p><p>另外，在Disney Principled BRDF中，实际上有两个镜面反射波瓣（Specular lobe），并且都用GTR模型。其中γ=2的GRT代表基础底层材质，而γ=1的GRT则代表清漆层的反射。</p><h3 id="a-2-2-菲涅尔项（Specular-F）：Schlick-Fresnel"><a href="#a-2-2-菲涅尔项（Specular-F）：Schlick-Fresnel" class="headerlink" title="a.2.2). 菲涅尔项（Specular F）：Schlick Fresnel"></a>a.2.2). 菲涅尔项（Specular F）：Schlick Fresnel</h3><p><img src="/2023/02/15/HPP_Graphics_5.1_PBR%E5%9F%BA%E7%A1%80/071dcb665386a2a56f1cb84352dc60ce.png" alt="071dcb665386a2a56f1cb84352dc60ce"></p><p>由于原始的菲涅尔项表示过于复杂，人们会常用其他数值近似的方法。其中，应用地较为广泛的为Schlick Fresnel。<strong><font color="red">本质上是考虑能量的反射和折射</font></strong>（即考虑菲涅尔就会有因为颜色的合理的能量损失，这也是为什么Kulla-Conty Approximation再为考虑颜色时，不乘上菲涅尔项的原因）</p><p>这里需要注意的有两点。</p><ol><li><p>$\theta_d$ 为半角向量h和视线v之间的夹角，而不是宏观法线n和视线v的夹角。<strong>$(i, h)$和$(i, n)$的区别其实就是宏观和微观。在微表面BRDF中，$D(h)$筛选出了沿$h$方向的normal。那此时菲涅尔项中应该使用的normal即为$h$</strong></p></li><li><p>电介质（绝缘体）的$F_0$ 为float，金属的 $F_0$ 为float3。而最终用于菲涅尔项的 $F_0$ 常常会根据金属度在0.04(引擎中电介质默认的$F_0$)和albedo之间根据金属度Metallic插值。</p></li></ol><h3 id="a-2-3-几何项-Shadowing-Masking（Specular-G）：Smith-GGX"><a href="#a-2-3-几何项-Shadowing-Masking（Specular-G）：Smith-GGX" class="headerlink" title="a.2.3). 几何项/Shadowing-Masking（Specular G）：Smith-GGX"></a>a.2.3). 几何项/Shadowing-Masking（Specular G）：Smith-GGX</h3><p>几何项（Specular G）方面，对于主镜面波瓣（primary specular lobe），Disney参考了 Walter的近似方法，使用Smith GGX导出的G项，并将粗糙度参数进行重映射以减少光泽表面的极端增益，即将α 从[0, 1]重映射到[0.5, 1]，α的值为(0.5 + roughness/2)^2。从而使几何项的粗糙度变化更加平滑，更便于美术人员的使用。</p><p>以下为Smith GGX的几何项的表达式：</p><p><img src="/2023/02/15/HPP_Graphics_5.1_PBR%E5%9F%BA%E7%A1%80/0138e3d33d920148a6a652f2f47158d3.png" alt></p><p><img src="/2023/02/15/HPP_Graphics_5.1_PBR%E5%9F%BA%E7%A1%80/cab428cf33e54a71d70cc9fc05c856c3.png" alt></p><p><img src="/2023/02/15/HPP_Graphics_5.1_PBR%E5%9F%BA%E7%A1%80/5336bcb848115d87c783424111bcf204.png" alt></p><p>另外，对于对清漆层进行处理的次级波瓣（secondary lobe），Disney没有使用Smith G推导，而是直接使用固定粗糙度为0.25的GGX的 G项，便可以得到合理且很好的视觉效果。</p><h2 id="a-3-间接光照漫反射"><a href="#a-3-间接光照漫反射" class="headerlink" title="a.3). 间接光照漫反射"></a>a.3). 间接光照漫反射</h2><p>间接光照漫反射频率基本集中的低频，因此采用球谐函数取近似（Unity中采用前三阶）。</p><p><em>详见Games202 Real-time Environment Mapping</em></p><h2 id="a-4-间接光照镜面反射"><a href="#a-4-间接光照镜面反射" class="headerlink" title="a.4). 间接光照镜面反射"></a>a.4). 间接光照镜面反射</h2><p>间接光照镜面反射采用IBL，并通过prefiltering后采用模拟对Lighting的积分，通过Split sum对BRDF积分。（<em>详见Games202 Real-time Environment Mapping</em>）其中，mip和roughness之间的关系为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">float m = roughness*roughness;</span><br><span class="line">const float fEps = 1.192092896e-07F;</span><br><span class="line">float n =  (2.0 / max(fEps, m * m)) - 2.0;</span><br><span class="line">n /= 4;</span><br><span class="line">roughness = pow( 2 / (n + 2), 0.25);</span><br></pre></td></tr></table></figure><p>Unity中，则通过 $mip = r(1.7 - 0.7r)$ 来拟合。</p><p><a href="http://jbit.net/~sparky/academic/mm_brdf.pdf">http://jbit.net/~sparky/academic/mm_brdf.pdf</a></p><h2 id="a-5-各项比例"><a href="#a-5-各项比例" class="headerlink" title="a.5). 各项比例"></a>a.5). 各项比例</h2><p>至此，我们已经可以把各项的表达式都写出来了。那么最后需要解决的就是各项之间的比例。</p><h3 id="a-5-1-直接光照"><a href="#a-5-1-直接光照" class="headerlink" title="a.5.1). 直接光照"></a>a.5.1). 直接光照</h3><p>首先，我们考虑直接光照。直接光照中，漫反射和镜面反射的关键在于菲涅尔项。菲涅尔项本质上是考虑能量的反射和折射，而光线折射后会发生吸收和散射。而散射的尺度要是足够小，就变成了漫反射（尺度大，如大于一个像素区域时，散射变现为次表面散射，即SSS）。</p><p>镜面反射的比例已经在微表面BRDF中的F项中计算过了，因此漫反射的比例即为1 - F。同时，因为我们采用的Disney principled BRDF需要根据金属度在漫反射和镜面反射之间插值，因此漫反射项的比例为$(1 - F) \cdot (1-Metallic) $ 。</p><h3 id="a-5-2-间接光照"><a href="#a-5-2-间接光照" class="headerlink" title="a.5.2). 间接光照"></a>a.5.2). 间接光照</h3><p>在间接光照中，与直接光照不同的地方在于在求间接光照的镜面反射时，我们对BRDF求了积分（Split sum）。因此，我们菲涅尔的不再是微表面的菲涅尔，而是使用宏观法线的菲涅尔。即，<strong>$\theta_d$ 为法线$n$和视线$v$之间的夹角</strong>。</p><p><img src="/2023/02/15/HPP_Graphics_5.1_PBR%E5%9F%BA%E7%A1%80/071dcb665386a2a56f1cb84352dc60ce.png" alt="071dcb665386a2a56f1cb84352dc60ce"></p><p>这里$F_0$ 与albedo之间lerp使用Roughness，而不是Metallic。（一种经验化的做法，方法来自：<a href="https://seblagarde.wordpress.com/2011/08/17/hello-world/）">https://seblagarde.wordpress.com/2011/08/17/hello-world/）</a></p><p>附上最终Shader</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br></pre></td><td class="code"><pre><span class="line">Shader &quot;PBR/DisneyPBR&quot;</span><br><span class="line">&#123;</span><br><span class="line">    Properties</span><br><span class="line">    &#123;</span><br><span class="line">        _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; &#123;&#125;</span><br><span class="line">        _Roughness (&quot;Roughness&quot;, Range(0, 1.0)) = 0.3</span><br><span class="line">        _Metallic (&quot;Metallic&quot;, Range(0.0, 1.0)) = 0.2</span><br><span class="line">        _IBLlut (&quot;IBL Lut&quot;, 2D) = &quot;while&quot; &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    SubShader</span><br><span class="line">    &#123;</span><br><span class="line">        Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125;</span><br><span class="line"></span><br><span class="line">        CGINCLUDE</span><br><span class="line">        #include &quot;UnityCG.cginc&quot;</span><br><span class="line">        #include &quot;UnityStandardBRDF.cginc&quot;</span><br><span class="line">        #include &quot;UnityStandardUtils.cginc&quot;</span><br><span class="line"></span><br><span class="line">        half DI_DisneyDiffuse(half NdotV, half NdotL, half NdotH, half perceptualRoughness) &#123;</span><br><span class="line">            half F90 = 0.5 + 2 * perceptualRoughness * NdotH * NdotH;</span><br><span class="line">            half lightScatter = 1 + (F90 - 1) * Pow5(1 - NdotL);</span><br><span class="line">            half viewScatter = 1 + (F90 - 1) * Pow5(1 - NdotV);</span><br><span class="line"></span><br><span class="line">            return lightScatter * viewScatter;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        half SmithJointGGX(half NdotV, half NdotL, half perceptualRoughness) &#123;</span><br><span class="line">            half a = 0.5 + perceptualRoughness/2;</span><br><span class="line">            a *= a;</span><br><span class="line">            half a2 = a * a;</span><br><span class="line"></span><br><span class="line">            half lightGGX = 2 * NdotL / (NdotL + sqrt(a2 + (NdotL - a2 * NdotL) * NdotL));</span><br><span class="line">            half viewGGX = 2 * NdotV / (NdotV + sqrt(a2 + (NdotV - a2 * NdotV) * NdotV));</span><br><span class="line"></span><br><span class="line">            return lightGGX * viewGGX;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        half GTR2(half NdotH, half perceptualRoughness) &#123;</span><br><span class="line">            half a2 = perceptualRoughness * perceptualRoughness;</span><br><span class="line">            half cos2 = NdotH * NdotH;</span><br><span class="line">            half denom = (1 + (a2 - 1) * cos2);</span><br><span class="line"></span><br><span class="line">            return a2 * UNITY_INV_PI / (denom * denom);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        half3 F_schlick(half3 F0, half HdotV) &#123;</span><br><span class="line">            return F0 + (1 - F0) * Pow5(1 - HdotV);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        half3 IBL_LightSample(float3 dir, half perceptualRoughness) &#123;</span><br><span class="line">            float mip_roughness = perceptualRoughness * (1.7 - 0.7 * perceptualRoughness);</span><br><span class="line">            half mip = mip_roughness * UNITY_SPECCUBE_LOD_STEPS;</span><br><span class="line"></span><br><span class="line">            half4 hdr_col = UNITY_SAMPLE_TEXCUBE_LOD(unity_SpecCube0, dir, mip);</span><br><span class="line">            float3 ldr_col = DecodeHDR(hdr_col, unity_SpecCube0_HDR);</span><br><span class="line"></span><br><span class="line">            return ldr_col;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        float3 fresnelSchlickRoughness(float cosTheta, float3 F0, float roughness)</span><br><span class="line">        &#123;</span><br><span class="line">            return F0 + (max(float3(1.0 - roughness, 1.0 - roughness, 1.0 - roughness), F0) - F0) * Pow5(1.0 - cosTheta);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        struct a2v</span><br><span class="line">        &#123;</span><br><span class="line">            float4 vertex : POSITION;</span><br><span class="line">            float3 normal : NORMAL;</span><br><span class="line">            float2 uv : TEXCOORD0;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        struct v2f</span><br><span class="line">        &#123;</span><br><span class="line">            float2 uv : TEXCOORD0;</span><br><span class="line">            float3 worldNormal : TEXCOORD1;</span><br><span class="line">            float3 worldPos : TEXCOORD2;</span><br><span class="line">            float4 vertex : SV_POSITION;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        sampler2D _MainTex;</span><br><span class="line">        sampler2D _IBLlut;</span><br><span class="line">        float4 _MainTex_ST;</span><br><span class="line">        float _Roughness;</span><br><span class="line">        float _Metallic;</span><br><span class="line"></span><br><span class="line">        v2f vert (a2v v)</span><br><span class="line">        &#123;</span><br><span class="line">            v2f o;</span><br><span class="line">            o.vertex = UnityObjectToClipPos(v.vertex);</span><br><span class="line">            o.uv = TRANSFORM_TEX(v.uv, _MainTex);</span><br><span class="line">            o.worldNormal = UnityObjectToWorldNormal(v.normal);</span><br><span class="line">            o.worldPos = mul(unity_ObjectToWorld, v.vertex);</span><br><span class="line">            return o;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        fixed4 frag (v2f i) : SV_Target</span><br><span class="line">        &#123;</span><br><span class="line">            float3 worldNormal = normalize(i.worldNormal);</span><br><span class="line">            float3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos));</span><br><span class="line">            float3 worldViewDir = normalize(UnityWorldSpaceViewDir(i.worldPos));</span><br><span class="line">            float3 worldHalfDir = normalize(worldLightDir + worldViewDir);</span><br><span class="line"></span><br><span class="line">            float NdotV = max(dot(worldNormal, worldViewDir), 0.0001);</span><br><span class="line">            float NdotL = max(dot(worldNormal, worldLightDir), 0.0001);</span><br><span class="line">            float NdotH = max(dot(worldNormal, worldHalfDir), 0.0001);</span><br><span class="line">            float HdotV = max(dot(worldHalfDir, worldViewDir), 0.0001);</span><br><span class="line"></span><br><span class="line">            fixed4 albedo = tex2D(_MainTex, i.uv);</span><br><span class="line"></span><br><span class="line">            float roughness = lerp(0.004, 0.9, _Roughness);</span><br><span class="line"></span><br><span class="line">            //DI</span><br><span class="line">            // DisneyDiffuse没有乘上Pi</span><br><span class="line">            fixed3 DisneyDiffuse = albedo.rgb * DI_DisneyDiffuse(NdotV, NdotL, NdotH, roughness); //  * UNITY_INV_PI</span><br><span class="line"></span><br><span class="line">            fixed3 F0 = lerp(unity_ColorSpaceDielectricSpec.rgb, albedo, _Metallic);</span><br><span class="line"></span><br><span class="line">            float D = GTR2(NdotH, roughness);</span><br><span class="line">            float3 F = F_schlick(F0, HdotV);</span><br><span class="line">            float G = SmithJointGGX(NdotV, NdotL, roughness);</span><br><span class="line"></span><br><span class="line">            half3 SpeBRDF = F * D * G / (4 * NdotL * NdotV);</span><br><span class="line"></span><br><span class="line">            fixed3 LightColor = _LightColor0;</span><br><span class="line"></span><br><span class="line">            half kd = OneMinusReflectivityFromMetallic(_Metallic);</span><br><span class="line"></span><br><span class="line">            fixed3 Ambient = albedo * UNITY_LIGHTMODEL_AMBIENT.rgb;</span><br><span class="line">            fixed3 Diffuse = (1-F) * kd * LightColor * DisneyDiffuse * NdotL;</span><br><span class="line">            fixed3 Specular = LightColor * SpeBRDF * NdotL * UNITY_PI; // 乘上Pi和Diffuse等比例变化；</span><br><span class="line"></span><br><span class="line">            // Environment Map</span><br><span class="line"></span><br><span class="line">            half3 ambient_contrib = ShadeSH9(half4(worldNormal, 1));</span><br><span class="line"></span><br><span class="line">            float3 iblLight = IBL_LightSample(reflect(-worldViewDir, worldNormal), roughness);</span><br><span class="line"></span><br><span class="line">            float2 envLut = tex2D(_IBLlut, float2(lerp(0, 0.99, NdotV), roughness)).rg;</span><br><span class="line"></span><br><span class="line">            float3 F0_Roughness = lerp(unity_ColorSpaceDielectricSpec.rgb, albedo, roughness);</span><br><span class="line">            float3 Flast = fresnelSchlickRoughness(max(NdotV, 0.001), F0, roughness);</span><br><span class="line">            float kdLast = (1 - Flast) * (1 - _Metallic);</span><br><span class="line"></span><br><span class="line">            float3 iblDiffuse = (ambient_contrib + Ambient) * albedo * kdLast;</span><br><span class="line">            float3 iblSpec = (iblLight * (Flast * envLut.r + envLut.g));</span><br><span class="line"></span><br><span class="line">            return fixed4(Diffuse + Specular + iblDiffuse + iblSpec, 1);</span><br><span class="line">            // return fixed4(iblDiffuse, 1);</span><br><span class="line">        &#125;</span><br><span class="line">        ENDCG</span><br><span class="line">        Pass</span><br><span class="line">        &#123;</span><br><span class="line">            Tags &#123;</span><br><span class="line">&quot;LightMode&quot; = &quot;ForwardBase&quot;</span><br><span class="line">&#125;</span><br><span class="line">            CGPROGRAM</span><br><span class="line">            #pragma vertex vert</span><br><span class="line">            #pragma fragment frag</span><br><span class="line">            ENDCG</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="a-6-结果"><a href="#a-6-结果" class="headerlink" title="a.6). 结果"></a>a.6). 结果</h2><p><img src="/2023/02/15/HPP_Graphics_5.1_PBR%E5%9F%BA%E7%A1%80/DisneyBRDF.jpg" alt="DisneyBRDF"></p><blockquote id="fn_Custom PBR"><sup>Custom PBR</sup>. 同参数下，与Standard Shader的对比（左侧为Custom PBR）<a href="#reffn_Custom PBR" title="Jump back to footnote [Custom PBR] in the text."> &#8617;</a></blockquote><p>为获得更长的拖尾，将GTR的γ取3以区别Standard。</p><p>可以看到，实现的Shader基本与Unity的Standard Shader一致。但因为法线分布使用了GTR，高光拖尾更长，更柔和。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_5.1_PBR%E5%9F%BA%E7%A1%80/Cook-Torrance.png&quot; alt=&quot;Cook-Torrance&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;引擎为了提高性能，并且artist friendly，用漫反射项补偿微表面BRDF（打破能量守恒，如想在RTR中实现较为准确的能量补充，应使用Kulla-Conty Approximation）。使得其方便控制，如对于非金属4%的 $F_0$ 也可呈现颜色。并且把BRDF分母的 $\pi$ ,写为4。&lt;ul&gt;
&lt;li&gt;因此，引擎中PBR的Shading常有以下几项，并通过系数控制其不过与打破能量守恒：&lt;ol&gt;
&lt;li&gt;直接光照漫反射；&lt;/li&gt;
&lt;li&gt;直接光照镜面反射；&lt;/li&gt;
&lt;li&gt;间接光照漫反射；&lt;/li&gt;
&lt;li&gt;间接光照镜面反射；&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;这样做的结果是容易打破能量守恒，但是artist friendly，而且可表现更多外观。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;更多请看&lt;em&gt;Games202 Real-time Physically-based Materials&lt;/em&gt;，或以下Reference&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ref:&lt;/strong&gt;&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://learnopengl-cn.github.io/07%20PBR/01%20Theory/#pbr&quot;&gt;LearnOpenGL CN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://aras-p.info/texts/files/201403-GDC_UnityPhysicallyBasedShading_notes.pdf&quot;&gt;201403-GDC_UnityPhysicallyBasedShading&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/column/game-programming&quot;&gt;基于物理的渲染（PBR）白皮书&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.uwa4d.com/archives/1582.html&quot;&gt;基于物理的渲染—更精确的微表面分布函数GGX&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/68025039&quot;&gt;如何在Unity中造一个PBR Shader轮子&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://bruop.github.io/ibl/&quot;&gt;Image Based Lighting with Multiple Scattering&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;a-Unity中的PBR（Disney‘s-Principled-BRDF）&quot;&gt;&lt;a href=&quot;#a-Unity中的PBR（Disney‘s-Principled-BRDF）&quot; class=&quot;headerlink&quot; title=&quot;a). Unity中的PBR（Disney‘s Principled BRDF）&quot;&gt;&lt;/a&gt;a). Unity中的PBR（Disney‘s Principled BRDF）&lt;/h1&gt;&lt;p&gt;Unity中Standard Shader基本采用Disney’s Principled BRDF，但有些许不同。Disney’s Principled BRDF可具体看其他文章，如毛星云大佬的PBR白皮书，以下就写一些实现上的不同处和细节。&lt;/p&gt;</summary>
    
    
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="PBR" scheme="https://whitetail-o.github.io/tags/PBR/"/>
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>HPP_Graphics_4.5 DOF景深基础</title>
    <link href="https://whitetail-o.github.io/2023/02/15/HPP_Graphics_4.5_DOF%E6%99%AF%E6%B7%B1%E5%9F%BA%E7%A1%80/"/>
    <id>https://whitetail-o.github.io/2023/02/15/HPP_Graphics_4.5_DOF%E6%99%AF%E6%B7%B1%E5%9F%BA%E7%A1%80/</id>
    <published>2023-02-15T11:26:32.000Z</published>
    <updated>2023-03-17T05:20:51.100Z</updated>
    
    <content type="html"><![CDATA[<p>这两篇已经写得挺好的了，后续再补充。</p><p><a href="https://blog.csdn.net/weixin_45776473/article/details/126912037?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167646563416800182743755%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=167646563416800182743755&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-126912037-null-null.142">用Unity实现景深效果</a></p><p><a href="https://blog.csdn.net/qjh5606/article/details/118960868?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E6%95%A3%E6%99%AF%E6%99%AF%E6%B7%B1&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-118960868.142">图形学基础|景深效果（Depth of Field/DOF）</a></p><h1 id="HW"><a href="#HW" class="headerlink" title="HW"></a>HW</h1><p><img src="/2023/02/15/HPP_Graphics_4.5_DOF%E6%99%AF%E6%B7%B1%E5%9F%BA%E7%A1%80/HW_DOF.gif" alt="HW_DOF"></p><p>Step1: 计算CoC(弥散圆)</p><p>Step2: Bokeh Filter</p><p>Step3: Tent Filter</p><p>Step4: Composition</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这两篇已经写得挺好的了，后续再补充。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/weixin_45776473/article/details/126912037?ops_request_misc=%257B%2522request%255</summary>
      
    
    
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    <category term="效果" scheme="https://whitetail-o.github.io/tags/%E6%95%88%E6%9E%9C/"/>
    
    <category term="算法" scheme="https://whitetail-o.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>HPP_Graphics_4.1 Bloom算法</title>
    <link href="https://whitetail-o.github.io/2023/02/15/HPP_Graphics_4.1_Bloom%E7%AE%97%E6%B3%95/"/>
    <id>https://whitetail-o.github.io/2023/02/15/HPP_Graphics_4.1_Bloom%E7%AE%97%E6%B3%95/</id>
    <published>2023-02-15T11:24:32.000Z</published>
    <updated>2023-03-17T05:18:01.920Z</updated>
    
    <content type="html"><![CDATA[<h1 id="a-Bloom算法介绍"><a href="#a-Bloom算法介绍" class="headerlink" title="a). Bloom算法介绍"></a>a). Bloom算法介绍</h1><p>模拟光辉效果的算法<br>简单思路：提取较亮的部分进行模糊，然后与原图叠加后输出<br>HDR：使用HDR可以使提取到亮度大于1的区域<br>高斯模糊：使用高斯函数得到的高斯核去卷积图像<br>二维高斯核：将运算的复杂度从 N x N x W x H 减少到了 2 x N x W x H (对称性使N可减少到N/2+1)</p><p><img src="/2023/02/15/HPP_Graphics_4.1_Bloom%E7%AE%97%E6%B3%95/Bloom思路.png" alt="Bloom思路"></p><h1 id="b-Bloom算法实现（Unity）"><a href="#b-Bloom算法实现（Unity）" class="headerlink" title="b). Bloom算法实现（Unity）"></a>b). Bloom算法实现（Unity）</h1><h2 id="C-部分"><a href="#C-部分" class="headerlink" title="C#部分"></a>C#部分</h2><p>调用OnRenderImage函数获取纹理和传输参数给Shader：</p><h2 id="Shader部分"><a href="#Shader部分" class="headerlink" title="Shader部分"></a>Shader部分</h2><p>使用4个Pass计算Bloom效果：</p><p>第一个Pass提取较亮区域<br>第二个、第三个Pass分别在竖直和水平方向上计算高斯模糊<br>最后一个Pass将计算的结果与原图像进行混合</p><h1 id="c-Bloom算法应用"><a href="#c-Bloom算法应用" class="headerlink" title="c). Bloom算法应用"></a>c). Bloom算法应用</h1><p>配合自发光贴图使用<br>配合特效（如烟花）<br>GodRay（基于径向的后处理）<br>使用HDR时，配合Tonemapping（配合色调映射的bloom效果更加柔和）</p><span id="more"></span><h1 id="Homework"><a href="#Homework" class="headerlink" title="Homework"></a>Homework</h1><h2 id="带Mask的Bloom效果"><a href="#带Mask的Bloom效果" class="headerlink" title="带Mask的Bloom效果"></a>带Mask的Bloom效果</h2><p><img src="/2023/02/15/HPP_Graphics_4.1_Bloom%E7%AE%97%E6%B3%95/noBloom_HW.png" alt="noBloom_HW" style="zoom: 33%;"></p><p><img src="/2023/02/15/HPP_Graphics_4.1_Bloom%E7%AE%97%E6%B3%95/Bloom_HW.png" alt="Bloom_HW" style="zoom: 33%;"></p><p><img src="/2023/02/15/HPP_Graphics_4.1_Bloom%E7%AE%97%E6%B3%95/Bloom_Mask.png" alt="Bloom_Mask" style="zoom:25%;"></p><ul><li><p><strong>实现思路：</strong></p><ul><li><p>修改对应物体fragment返回的Alpha值作为Bloom遮罩</p><p><img src="/2023/02/15/HPP_Graphics_4.1_Bloom%E7%AE%97%E6%B3%95/Debug.png" alt="Debug" style="zoom: 33%;"></p></li><li><p>黑为Bloom效果最强，白为无Bloom（因为点光源会使得后处理中Alpha通道比FS返回的大，因此采用黑色Bloom效果最强，<em>待验证</em>）</p></li><li></li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;a-Bloom算法介绍&quot;&gt;&lt;a href=&quot;#a-Bloom算法介绍&quot; class=&quot;headerlink&quot; title=&quot;a). Bloom算法介绍&quot;&gt;&lt;/a&gt;a). Bloom算法介绍&lt;/h1&gt;&lt;p&gt;模拟光辉效果的算法&lt;br&gt;简单思路：提取较亮的部分进行模糊，然后与原图叠加后输出&lt;br&gt;HDR：使用HDR可以使提取到亮度大于1的区域&lt;br&gt;高斯模糊：使用高斯函数得到的高斯核去卷积图像&lt;br&gt;二维高斯核：将运算的复杂度从 N x N x W x H 减少到了 2 x N x W x H (对称性使N可减少到N/2+1)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_4.1_Bloom%E7%AE%97%E6%B3%95/Bloom思路.png&quot; alt=&quot;Bloom思路&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;b-Bloom算法实现（Unity）&quot;&gt;&lt;a href=&quot;#b-Bloom算法实现（Unity）&quot; class=&quot;headerlink&quot; title=&quot;b). Bloom算法实现（Unity）&quot;&gt;&lt;/a&gt;b). Bloom算法实现（Unity）&lt;/h1&gt;&lt;h2 id=&quot;C-部分&quot;&gt;&lt;a href=&quot;#C-部分&quot; class=&quot;headerlink&quot; title=&quot;C#部分&quot;&gt;&lt;/a&gt;C#部分&lt;/h2&gt;&lt;p&gt;调用OnRenderImage函数获取纹理和传输参数给Shader：&lt;/p&gt;
&lt;h2 id=&quot;Shader部分&quot;&gt;&lt;a href=&quot;#Shader部分&quot; class=&quot;headerlink&quot; title=&quot;Shader部分&quot;&gt;&lt;/a&gt;Shader部分&lt;/h2&gt;&lt;p&gt;使用4个Pass计算Bloom效果：&lt;/p&gt;
&lt;p&gt;第一个Pass提取较亮区域&lt;br&gt;第二个、第三个Pass分别在竖直和水平方向上计算高斯模糊&lt;br&gt;最后一个Pass将计算的结果与原图像进行混合&lt;/p&gt;
&lt;h1 id=&quot;c-Bloom算法应用&quot;&gt;&lt;a href=&quot;#c-Bloom算法应用&quot; class=&quot;headerlink&quot; title=&quot;c). Bloom算法应用&quot;&gt;&lt;/a&gt;c). Bloom算法应用&lt;/h1&gt;&lt;p&gt;配合自发光贴图使用&lt;br&gt;配合特效（如烟花）&lt;br&gt;GodRay（基于径向的后处理）&lt;br&gt;使用HDR时，配合Tonemapping（配合色调映射的bloom效果更加柔和）&lt;/p&gt;</summary>
    
    
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    <category term="效果" scheme="https://whitetail-o.github.io/tags/%E6%95%88%E6%9E%9C/"/>
    
    <category term="算法" scheme="https://whitetail-o.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>HPP_Graphics_4.2 SSAO</title>
    <link href="https://whitetail-o.github.io/2023/02/15/HPP_Graphics_4.2_SSAO/"/>
    <id>https://whitetail-o.github.io/2023/02/15/HPP_Graphics_4.2_SSAO/</id>
    <published>2023-02-15T11:24:32.000Z</published>
    <updated>2023-03-17T05:18:32.679Z</updated>
    
    <content type="html"><![CDATA[<h1 id="a-AO-Ambient-Occlusion"><a href="#a-AO-Ambient-Occlusion" class="headerlink" title="a). AO(Ambient Occlusion)"></a>a). AO(Ambient Occlusion)</h1><p>环境光遮蔽，全称Ambient Occlusion，是计算机图形学中的一种着色和渲染技术,模拟光线达到物体的能力的粗略的全局方法，描述光线到达物体表面的能力。</p><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/AO00.png" alt="AO00"></p><h1 id="b-SSAO-Screen-Space-Ambient-Occlusion"><a href="#b-SSAO-Screen-Space-Ambient-Occlusion" class="headerlink" title="b). SSAO(Screen Space Ambient Occlusion)"></a>b). SSAO(Screen Space Ambient Occlusion)</h1><p>屏幕空间环境光遮蔽，全称Screen Space Ambient Occlusion，一种用于计算机图形中实时实现近似环境光遮蔽效果的渲染技术。通过获取像素的<strong>深度缓冲</strong>、<strong>法线缓冲</strong>以及<strong>像素坐标</strong>来计算实现，来近似的表现物体在间接光下产生的阴影。</p><h2 id="b-1-SSAO原理"><a href="#b-1-SSAO原理" class="headerlink" title="b.1). SSAO原理"></a>b.1). SSAO原理</h2><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/SSAO原理.png" alt="SSAO原理"></p><ol><li><p>获取深度、法线（View Space）缓冲；</p><ul><li><p>Normal Buffer：</p><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/NormalBuffer.png" alt="NormalBuffer"></p></li></ul></li><li><p>重构像素相机空间中的坐标；</p><ul><li><p>通过深度缓冲的depth值重构（近似）该视角下的三维场景；</p><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/DepthBuffer.png" alt="DepthBuffer" style="zoom:25%;"></p><ul><li>为什么是近似：Depth Buffer中深度值为0~1，并不能反应无穷远（天空等）。常用的办法是把1映射到View Space的远平面。</li></ul></li></ul></li><li><p>法向半球随机采样，计算掩蔽因子，进而得到AO强度（For循环）；</p><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/法向半球.png" alt="法向半球"></p><ul><li>每一次for循环都会在法线半球中获取一个随机向量，根据这个向量我们会求出它对应的深度值，然后跟深度缓冲中对应采样像素位置的深度值做比较，如果大于（灰色点），则认为有遮蔽，算进加权中，最后我们合成AO，然后再加上一些后期处理优化效果。</li></ul></li></ol><span id="more"></span><h2 id="b-2-Unity实现部分"><a href="#b-2-Unity实现部分" class="headerlink" title="b.2). Unity实现部分"></a>b.2). Unity实现部分</h2><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/AO_Flow.png" alt="AO_Flow"></p><p>SSAO的shader中共有三个Pass：</p><ol><li>计算生成AO；</li><li>模糊 / 滤波</li><li>AO与Color buffer混合；</li></ol><h3 id="b-2-1-计算AO"><a href="#b-2-1-计算AO" class="headerlink" title="b.2.1). 计算AO"></a>b.2.1). 计算AO</h3><p>在基于法线方向，建立法线空间中法向半球的采样块。</p><p>在采样块中循环生成采样点，判断是否被遮蔽</p><p>因为实时渲染的性能问题，所以采样点数量不会很多，导致出现“油漆”般的画面</p><p>引入噪声, 将每个采样点以原点法线方向为旋转轴旋转随机的角度。这样的新采样点会变得极其不规则, 更加离散化。将低频的条纹转化成高频的噪声；</p><ol><li><p>计算相机到像素点的坐标（<a href="https://zhuanlan.zhihu.com/p/145400372">Unity Shader中的ComputeScreenPos函数</a>）对应的远平面的向量（屏幕空间转换到裁剪空间后乘以远平面距离，再转换到观察空间）；</p><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/vertAO.png" alt="vertAO"></p></li></ol><ol><li><p>获得着色点的01线性深度值、观察空间下的法线向量；</p><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/GetDepthAndNormal.png" alt="GetDepthAndNormal"></p></li><li><p>然后在法向半球采样块中随机随机采样一个向量，得到<strong>法向半球向量</strong>。并由此构建经过旋转的法线空间的正交基。</p><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/Noise01a.png" alt="Noise01a"></p><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/TBN.png" alt="TBN"></p></li><li><p>将此前生成的随机向量转换到法线空间中。</p><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/Noise02a.png" alt="Noise02a"></p><p>循环操作，将每一个向量转换为采样点，坐标基于切线空间，再计算随机法向半球后的向量，然后进行空间转换，切线空间到裁剪空间到屏幕空间。（裁剪空间到屏幕空间进行01映射）</p><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/scrRandomVec.png" alt="scrRandomVec"></p><p>获得<strong>采样点</strong>的法线深度信息，计算遮蔽，最后得到AO图通过rscreenPos来采样_CameraDepthNormalsTexture，转化成屏幕空间对应的深度值，然后对比linear01Depth（着色点深度，更准确的情况下应该使用viewRandomPos对应的01线性深度），只要大于linear01Depth，则在加权计算AO</p><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/For02a.png" alt="For02a"></p></li></ol><h4 id="AO核心代码"><a href="#AO核心代码" class="headerlink" title="AO核心代码"></a>AO核心代码</h4><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/fragAO.png" alt="fragAO"></p><h4 id="延迟渲染-ssao"><a href="#延迟渲染-ssao" class="headerlink" title="延迟渲染+ssao"></a>延迟渲染+ssao</h4><p>因为在前向渲染的ssao实现过程中，需要获取到相机的法线深度图进行采样得到相应的信息，进行后续的操作。而因为延迟渲染正好需要先生成一个GBuffer，即已包含了ssao执行所需要的法线深度等信息。所以在shader代码编写中有所不同</p><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/Defer01.png" alt="Defer01"></p><p>在c#脚本中需要加入渲染路径的判断</p><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/Defer02.png" alt="Defer02"></p><h3 id="b-2-2-基于法线的双边滤波（Bilateral-Filter）"><a href="#b-2-2-基于法线的双边滤波（Bilateral-Filter）" class="headerlink" title="b.2.2). 基于法线的双边滤波（Bilateral Filter）"></a>b.2.2). 基于法线的双边滤波（Bilateral Filter）</h3><p><a href="https://blog.csdn.net/puppet_master/article/details/83066572">https://blog.csdn.net/puppet_master/article/details/83066572</a></p><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/Blur.png" alt="Blur"></p><h1 id="Homework"><a href="#Homework" class="headerlink" title="Homework"></a>Homework</h1><h2 id="场景1"><a href="#场景1" class="headerlink" title="场景1"></a>场景1</h2><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/HomeworkAO.png" alt="HomeworkAO"></p><table frame="void">    <tr>    <td><center><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/Homework01.png" alt="Homework01" width="600"></center></td>    <td><center><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/Homework02.png" alt="Homework02" width="600"></center></td>    </tr></table><hr><p>这场景好像不太明显，只有在大图里看的清楚，</p><h2 id="场景2"><a href="#场景2" class="headerlink" title="场景2"></a>场景2</h2><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/HomeworkAO_b.png" alt="HomeworkAO_b"></p><table frame="void">    <tr>    <td><center><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/Homework01b.png" alt="Homework01b" width="600"></center></td>    <td><center><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/Homework02b.png" alt="Homework02b" width="600"></center></td>    </tr></table><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/Homework02b.png" alt="Homework02b"></p><p><img src="/2023/02/15/HPP_Graphics_4.2_SSAO/Homework01b.png" alt="Homework01b"></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;a-AO-Ambient-Occlusion&quot;&gt;&lt;a href=&quot;#a-AO-Ambient-Occlusion&quot; class=&quot;headerlink&quot; title=&quot;a). AO(Ambient Occlusion)&quot;&gt;&lt;/a&gt;a). AO(Ambient Occlusion)&lt;/h1&gt;&lt;p&gt;环境光遮蔽，全称Ambient Occlusion，是计算机图形学中的一种着色和渲染技术,模拟光线达到物体的能力的粗略的全局方法，描述光线到达物体表面的能力。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_4.2_SSAO/AO00.png&quot; alt=&quot;AO00&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;b-SSAO-Screen-Space-Ambient-Occlusion&quot;&gt;&lt;a href=&quot;#b-SSAO-Screen-Space-Ambient-Occlusion&quot; class=&quot;headerlink&quot; title=&quot;b). SSAO(Screen Space Ambient Occlusion)&quot;&gt;&lt;/a&gt;b). SSAO(Screen Space Ambient Occlusion)&lt;/h1&gt;&lt;p&gt;屏幕空间环境光遮蔽，全称Screen Space Ambient Occlusion，一种用于计算机图形中实时实现近似环境光遮蔽效果的渲染技术。通过获取像素的&lt;strong&gt;深度缓冲&lt;/strong&gt;、&lt;strong&gt;法线缓冲&lt;/strong&gt;以及&lt;strong&gt;像素坐标&lt;/strong&gt;来计算实现，来近似的表现物体在间接光下产生的阴影。&lt;/p&gt;
&lt;h2 id=&quot;b-1-SSAO原理&quot;&gt;&lt;a href=&quot;#b-1-SSAO原理&quot; class=&quot;headerlink&quot; title=&quot;b.1). SSAO原理&quot;&gt;&lt;/a&gt;b.1). SSAO原理&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_4.2_SSAO/SSAO原理.png&quot; alt=&quot;SSAO原理&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;获取深度、法线（View Space）缓冲；&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Normal Buffer：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_4.2_SSAO/NormalBuffer.png&quot; alt=&quot;NormalBuffer&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;重构像素相机空间中的坐标；&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;通过深度缓冲的depth值重构（近似）该视角下的三维场景；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_4.2_SSAO/DepthBuffer.png&quot; alt=&quot;DepthBuffer&quot; style=&quot;zoom:25%;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;为什么是近似：Depth Buffer中深度值为0~1，并不能反应无穷远（天空等）。常用的办法是把1映射到View Space的远平面。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;法向半球随机采样，计算掩蔽因子，进而得到AO强度（For循环）；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_4.2_SSAO/法向半球.png&quot; alt=&quot;法向半球&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每一次for循环都会在法线半球中获取一个随机向量，根据这个向量我们会求出它对应的深度值，然后跟深度缓冲中对应采样像素位置的深度值做比较，如果大于（灰色点），则认为有遮蔽，算进加权中，最后我们合成AO，然后再加上一些后期处理优化效果。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    <category term="效果" scheme="https://whitetail-o.github.io/tags/%E6%95%88%E6%9E%9C/"/>
    
    <category term="算法" scheme="https://whitetail-o.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>HPP_Graphics_4.3 实时阴影介绍</title>
    <link href="https://whitetail-o.github.io/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/"/>
    <id>https://whitetail-o.github.io/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/</id>
    <published>2023-02-15T11:24:32.000Z</published>
    <updated>2023-03-17T05:20:53.338Z</updated>
    
    <content type="html"><![CDATA[<h1 id="图形-4-3-实时阴影介绍"><a href="#图形-4-3-实时阴影介绍" class="headerlink" title="图形 4.3 实时阴影介绍"></a>图形 4.3 实时阴影介绍</h1><p>更深的可看笔记Games202 Real-time Shadow</p><h1 id="a-基于图片实时阴影技术"><a href="#a-基于图片实时阴影技术" class="headerlink" title="a). 基于图片实时阴影技术"></a>a). 基于图片实时阴影技术</h1><h2 id="a-1-Shadow-Map"><a href="#a-1-Shadow-Map" class="headerlink" title="a.1). Shadow Map"></a>a.1). Shadow Map</h2><ul><li><p><strong>关键思想：</strong>一个点在相机视角中可见，但在光源视角中不可见，那该点就处于阴影中。</p></li><li><p><strong>做法：</strong> 在光源视角下渲染深度图。对于着色点$A$，将其转换到光源视角（其他空间也行，只要两者在同一坐标空间）后，与Shadow Map中对应点进行深度比较，判断一点是否在阴影中；</p><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/深度比较.png" alt="深度比较" style="zoom:50%;"></p></li></ul><blockquote><p>A <strong>2-Pass</strong> Algorithm</p><ol><li>Light pass: Generate the SM(Shadow Map)</li><li>Camera pass: uses the SM</li></ol></blockquote><h3 id="Pass-1-Render-from-Light"><a href="#Pass-1-Render-from-Light" class="headerlink" title="Pass 1: Render from Light"></a>Pass 1: Render from Light</h3><ul><li>输出一张<strong>光源视角</strong>的<strong>深度图（Depth Buffer）</strong></li></ul><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/SM_Pass01.png" alt="SM_Pass01"></p><h3 id="Pass-2-Render-from-Eye-Camera"><a href="#Pass-2-Render-from-Eye-Camera" class="headerlink" title="Pass 2: Render from Eye(Camera)"></a>Pass 2: Render from Eye(Camera)</h3><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/SM_Pass02.png" alt="SM_Pass02"></p><ul><li><p>将光源视角对应的深度转换到View Space, 与Camera视角的深度进行深度比较；</p><ul><li>如$Depth_{cam} &gt; Depth_{light}$ ，那说明该点<strong>在阴影中</strong>（相机可见，光源不可见）</li><li>如$Depth_{cam} &lt; Depth_{light}$ ，那说明该点在<strong>不在阴影中</strong>（相机可见，光源可见）</li></ul></li></ul><span id="more"></span><h2 id="a-2-Unity中的屏幕空间阴影映射"><a href="#a-2-Unity中的屏幕空间阴影映射" class="headerlink" title="a.2). Unity中的屏幕空间阴影映射"></a>a.2). Unity中的屏幕空间阴影映射</h2><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/SM00.png" alt="SM00" style="zoom:50%;"></p><p>Unity的阴影映射是<strong>屏幕空间阴影映射</strong>，即<strong>逐像素</strong>生成屏幕空间的阴影贴图后，再在Shading中采样，进而着色。</p><p><strong>Step1:</strong> 渲染屏幕空间的<strong>深度贴图</strong>；</p><p><strong>Step2:</strong> 调用每个物体的Shadow Cast Pass，从光源方向<strong>生成Shadow Map</strong>；</p><p><strong>Step3:</strong> 屏幕空间进行<strong>阴影收集（Shadow Collector）</strong>，即进行深度比较后，得到屏幕空间的阴影贴图；</p><ul><li>Unity采用了<strong>屏幕空间</strong>的阴影映射，在进行阴影收集时，是逐Pixel进行的。</li></ul><p><strong>Step4:</strong> Shading时，用屏幕空间的uv，采样Step3中得到的屏幕空间阴影贴图；</p><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/SM01.png" alt="SM01" style="zoom: 33%;"></p><h1 id="b-阴影映射优化"><a href="#b-阴影映射优化" class="headerlink" title="b). 阴影映射优化"></a>b). 阴影映射优化</h1><h2 id="b-1-Self-occlusion-自遮挡"><a href="#b-1-Self-occlusion-自遮挡" class="headerlink" title="b.1). Self occlusion(自遮挡)"></a>b.1). Self occlusion(自遮挡)</h2><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/SelfOcclusion.png" alt="SelfOcclusion"></p><ul><li><strong>Self occlusion：</strong> 也被称作Z-Fighting，阴影自遮挡，造成阴影毛刺的现象；</li><li><strong>原因：</strong> 如上图，<ul><li>Shadow Map分辨率有限，一个像素内记录的深度值相同。如图中红色和橙色斜线表示Shadow Map中深度相同的位置（$Depth_A = Depth_{A’}$）；</li><li>当计算平面中$B$点是否在阴影中时，$Depth_{light} = z1 = Depth_A$，而相机视角下的点$B$转换到光源视角下对应的深度为 $z2$ ，即$Depth_{cam} = z2 = Depth_B$</li><li>因此，$Depth_{cam} &gt; Depth_{light}$ ，说明该点<strong>在阴影中</strong>，因此造成Self occlusion</li></ul></li></ul><ul><li><p><strong>解决方法：</strong> 引入<strong>Bias</strong>；</p><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/SelfOcclusion_Bias.png" alt="SelfOcclusion_Bias" style="zoom:50%;"></p><ul><li>认为对于$B$点，如$Depth_{cam} &gt; Depth_{light}$，但$Depth_{light}$ 处于橙色中，那该点仍然不在阴影中；</li><li>即：<ul><li>$Depth_{cam} &gt; Depth_{light}+bias$，才使得该点<strong>在阴影中</strong>；</li><li>$Depth_{cam} &lt; Depth_{light}+bias$，该点<strong>不在阴影中</strong>；</li></ul></li><li>易得，当光源方向垂直于平面时，所需的Bias最小，因此可引入光源与平面法线的夹角 $cos\alpha$ ，来调整Bias大小；</li></ul></li></ul><ul><li>引入bias会造成的问题：Detached shadow(不接触阴影，Peter Panning)</li></ul><h3 id="b-1-1-偏移优化（Depth-Bias）"><a href="#b-1-1-偏移优化（Depth-Bias）" class="headerlink" title="b.1.1). 偏移优化（Depth Bias）"></a>b.1.1). 偏移优化（Depth Bias）</h3><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/DepthBias01.png" alt="DepthBias01"></p><ul><li>深度偏移：简单添加Bias，使得该像素深度（Shading Point的深度，而不是SM中的深度）朝光源靠近；</li><li>法线偏移：沿表面法线法线向外偏移；</li><li>偏移单位是阴影纹理映射的纹素大小；</li></ul><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/NormalBias01.png" alt="NormalBias01" style="zoom: 50%;"></p><h3 id="b-1-2-Unity中的偏移优化"><a href="#b-1-2-Unity中的偏移优化" class="headerlink" title="b.1.2). Unity中的偏移优化"></a>b.1.2). Unity中的偏移优化</h3><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/Unity_Bias.png" alt="Unity_Bias"></p><hr><h2 id="b-2-走样"><a href="#b-2-走样" class="headerlink" title="b.2). 走样"></a>b.2). 走样</h2><p>以信号重建的过程来审视阴影映射：</p><ul><li>初始采样：渲染Shadow Map;</li><li>重采样：从摄影机视角对Shadow Map重采样；</li></ul><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/ShadowMap_AA01.png" alt="ShadowMap_AA01"></p><h3 id="b-2-1-初始采样-透视走样"><a href="#b-2-1-初始采样-透视走样" class="headerlink" title="b.2.1). 初始采样 - 透视走样"></a>b.2.1). 初始采样 - 透视走样</h3><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/透视走样.png" alt="透视走样"></p><ul><li><strong>原因：</strong> 由于Shadow Map初始采样是在摄影机进行透视投影之前（左图），使得<strong>经过透视投影后，近景大量pixel与Shadow Map中的同一个texel对应</strong>造成走样。</li><li><strong>解决方法：</strong> <ol><li>在光源位置采样获得Shadow Map之前，我们先做一次透视投影。即采样经过透视投影后的场景；</li><li><strong>级联阴影映射（Cascaded Shadow Map）</strong>，减小近景和远景对应到屏幕空间中像素大小的差异；</li></ol></li></ul><h2 id="b-3-级联阴影映射（Cascaded-Shadow-Map）"><a href="#b-3-级联阴影映射（Cascaded-Shadow-Map）" class="headerlink" title="b.3). 级联阴影映射（Cascaded Shadow Map）"></a>b.3). 级联阴影映射（Cascaded Shadow Map）</h2><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/CSM.png" alt="CSM"></p><p><strong>实现：</strong>通过平行于视图方向的切片将视锥体截成多个子视锥体，每一个子视锥体都对应一张Shadow Map，每张Shadow Map独立计算但<strong>分辨率相同</strong>。</p><ul><li>如果在View Space也就是视锥体划分级联，一旦镜头转动会产生很严重的闪烁，所以<strong>一般划分级联是在光源空间中划分</strong>。(<a href="https://zhuanlan.zhihu.com/p/92017307">https://zhuanlan.zhihu.com/p/92017307</a>)</li></ul><h1 id="c-PCSS-Percentage-Closer-Soft-Shadow"><a href="#c-PCSS-Percentage-Closer-Soft-Shadow" class="headerlink" title="c). PCSS(Percentage-Closer Soft Shadow)"></a>c). PCSS(Percentage-Closer Soft Shadow)</h1><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/PCSS.png" alt="PCSS"></p><h2 id="c-1-PCF-Percentage-Closer-Filtering"><a href="#c-1-PCF-Percentage-Closer-Filtering" class="headerlink" title="c.1). PCF(Percentage Closer Filtering)"></a>c.1). PCF(Percentage Closer Filtering)</h2><ul><li>PCF用于抗锯齿，而不用于软阴影（用于软阴影的叫PCSS，两者实质是一个东西，但应用不同叫法不同）</li><li>在<strong>生成Shadow Map后，阴影比较时（即对阴影比较的结果）</strong>，进行Filtering<ul><li>面光源生成Shadow Map：以面光源的中心点(放置相机)生成shadow map</li></ul></li></ul><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/PCF.png" alt="PCF"></p><ul><li><p><strong>做法：</strong> 不止对着色点与其在Shadow Map中的对应点进行深度比较，而是<strong>着色点深度</strong>与其<strong>在Shadow Map中对应点及其周围点深度</strong>进行比较，最后<strong>对各个Visibility的结果取平均值</strong>（或加权平均）</p><ul><li><strong>eg1</strong>. $P$点在Cam视角下深度为$Depth_p$，转换到光源视角下深度为$Depth_{p’}$，$Depth_{p’}$ 与其在Shadow Map中对应点周围3x3（<strong>Filter size</strong>）像素进行比较，得到结果<script type="math/tex; mode=display">\begin{array}{l}1,0,1 \\1,0,1 \\1,1,0\end{array}</script>取平均得到Visibility为 0.667</li></ul></li></ul><ul><li><strong>Filter size</strong><ul><li>Small -&gt; sharper</li><li>Large -&gt; softer</li><li>为选取合适的Filter size，产生了PCSS</li></ul></li></ul><h2 id="c-2-PCSS-Percentage-Closer-Soft-Shadow"><a href="#c-2-PCSS-Percentage-Closer-Soft-Shadow" class="headerlink" title="c.2). PCSS(Percentage-Closer Soft Shadow)"></a>c.2). PCSS(Percentage-Closer Soft Shadow)</h2><h3 id="c-2-1-什么是PCSS？"><a href="#c-2-1-什么是PCSS？" class="headerlink" title="c.2.1). 什么是PCSS？"></a>c.2.1). 什么是PCSS？</h3><ul><li><strong>关键：</strong> 自适应Filter size</li></ul><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/PCSS01.png" alt="PCSS01"></p><ul><li>观察可得：<ul><li>钢笔（Blocker）与接收平面（Receiver）的距离越小（笔尖），阴影越硬</li><li>钢笔（Blocker）与接收平面（Receiver）的距离越大（笔尖），阴影越软</li></ul></li><li>即阴影的软硬程度，一部分取决于Blocker和Receiver的距离</li></ul><hr><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/PCSS_Key.png" alt="PCSS_Key"></p><ul><li><p>阴影的软硬取决于</p><ul><li>$w_{Light}$ （光源的宽度）</li><li>$d_{Blocker}$ 与 $d_{BtoR}$ 的比值；</li></ul></li><li><p><strong>Blocker定义：</strong></p><p>Shading point变换到Light视角，对应深度为$Depth_{scene}$ 。<strong>查询区域内</strong>，深度值$z &lt; Depth_{scene}$ 的texel即为Blocker；</p></li><li><p>$d_{Blocker}$ 为 <strong>Average blocker distance</strong></p><ul><li><p><strong>Average blocker distance：</strong> Shadow Map一定范围内的Blocker的深度平均值</p></li><li><p>类似eg1</p><blockquote><p><strong>eg1</strong>. $P$点在Cam视角下深度为$Depth_p$，转换到光源视角下深度为$Depth_{p’}$，$Depth_{p’}$ 与其在Shadow Map中对应点周围3x3（<strong>Filter size</strong>）像素进行比较，得到结果</p><script type="math/tex; mode=display">\begin{array}{l}1,0,1 \\1,0,1 \\1,1,0\end{array}</script><p>取平均得到Visibility为 0.667</p></blockquote><p>其中，Visibility为0的点，即 处于阴影中，$Depth_{cam} &gt; Depth_{light}+bias$ 的点即为Blocker，对Blocker在Shadow Map中的深度值取平均值，即得到Average blocker distance</p></li></ul></li></ul><h3 id="c-2-2-做法"><a href="#c-2-2-做法" class="headerlink" title="c.2.2). 做法"></a>c.2.2). 做法</h3><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/PCSS_How.png" alt="PCSS_How"></p><p>首先将shading point点$x$投应到shadow map上,找到其对应的像素点$P$。PCSS算法的实现流程如下：</p><p>第一步：Blocker search，即获取<strong>某个区域</strong>的平均遮挡物深度（在点p附近取一个范围(这个范围是自己定义或动态计算的),将范围内各像素的最小深度与x的实际深度比较,从而判断哪些像素是遮挡物，把所有遮挡物的深度记下来取个平均值作为blocker distance。）</p><p>第二步：Penumbra estimation，使用平均遮挡物深度计算滤波核尺寸（用取得的遮挡物深度距离来算在PCF中filtering的范围。）</p><script type="math/tex; mode=display">w_{\text {Penumbra }}=\left(d_{\text {Receiver }}-d_{\text {Blocker }}\right) \cdot w_{\text {Light }} / d_{\text {Blocker }}</script><p>第三步：Percentage Closer Filtering，对应该滤波核尺寸应用PCF算法。</p><ul><li>如何动态计算Blocker search的<strong>“某个范围”</strong><ul><li><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/PCSS_Region.png" alt="PCSS_Region"></li><li>Light越远，Region越小；Light越近，Region越大；（好像和图不太对应，如非要对应，就类似与Shadow Map位置不变，Light距离变大/小）</li></ul></li></ul><h4 id="那么PCSS中那些步骤会导致速度变慢？"><a href="#那么PCSS中那些步骤会导致速度变慢？" class="headerlink" title="那么PCSS中那些步骤会导致速度变慢？"></a>那么PCSS中那些步骤会导致速度变慢？</h4><ul><li><p>第一步：Blocker search，需要多次采样查询深度信息并比较，计算Blocker的平均深度$d_{Blocker}$</p></li><li><p>第三步：PCF，阴影越软→滤波核尺寸越大→采样查询次数变多→速度变慢</p><ul><li>由此可见，主要是多次采样并比较的方法使得速度变慢；</li></ul></li><li><p><strong>加速方法：</strong></p><ul><li>随机采样，后降噪；</li></ul><blockquote><p>如果觉得区域过大不想对每一个texels都进行比较,就可以通过随机采样其中的texels，而不是全部采样，会得到一个近似的结果,近似的结果就可能会导致出现噪声。工业的处理的方式就是先稀疏采样得到一个有噪声的visibility的图,接着再在图像空间进行降噪。</p></blockquote><ul><li><strong>Variance Soft Shadow Mapping(VSSM)</strong></li></ul></li></ul><hr><h3 id="c-2-3-Math"><a href="#c-2-3-Math" class="headerlink" title="c.2.3). Math"></a>c.2.3). Math</h3><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/PCF_02.png" alt="PCF_02"></p><script type="math/tex; mode=display">V(x)=\sum_{q \in \mathcal{N}(p)} w(p, q) \cdot \chi^{+}\left[D_{\mathrm{SM}}(q)-D_{\text {scene }}(x)\right]</script><ul><li>其中$\chi^{+}$ 类似于$step()$ 函数<ul><li>$D_{\mathrm{SM}}(q)-D_{\text {scene }}(x) \geq 0$， 即$Depth_{ShadowMap} \geq Depth_{cam}$，$\chi^{+}\left[D_{\mathrm{SM}}(q)-D_{\text {scene }}(x)\right] = 1$</li><li>$D_{\mathrm{SM}}(q)-D_{\text {scene }}(x) &lt; 0$， 即$Depth_{ShadowMap} &lt; Depth_{cam}$，$\chi^{+}\left[D_{\mathrm{SM}}(q)-D_{\text {scene }}(x)\right] = 0$</li></ul></li></ul><h1 id="Homework-屏幕空间PCSS软阴影"><a href="#Homework-屏幕空间PCSS软阴影" class="headerlink" title="Homework - 屏幕空间PCSS软阴影"></a>Homework - 屏幕空间PCSS软阴影</h1><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/HW_PCSS.png" alt="HW_PCSS" style="zoom:50%;"></p><p>本次实现了屏幕空间的软阴影。其主要步骤如下：</p><ol><li><p>渲染屏幕空间的<strong>深度贴图</strong>；</p></li><li><p>从光源方向<strong>生成Shadow Map</strong>；（下图深度经过EncodeFloatRGBA()，提高精度）</p><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/HW_PCSS01.png" alt="HW_PCSS01" style="zoom:25%;"></p></li><li><p>屏幕空间进行<strong>阴影收集（Shadow Collector）</strong>，即进行深度比较后，得到屏幕空间的阴影贴图；</p><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/HW_PCSS02.png" alt="HW_PCSS02" style="zoom: 25%;"></p></li><li><p>Shading时，用屏幕空间的uv，采样Step3中得到的屏幕空间阴影贴图；</p><p><img src="/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/HW_PCSS03.png" alt="HW_PCSS03" style="zoom:25%;"></p></li></ol><p>至于为什么要使用屏幕空间的软阴影，而不是直接在Shader中实现阴影主要有以下考虑：</p><ol><li>屏幕空间的阴影可在一个Pass内完成，管理和调整方便，更贴近实际的应用；</li><li>屏幕空间的阴影性能开销小；</li><li>方便阴影的后处理；</li><li>此方案主要考虑场景阴影，而不考虑角色阴影。</li></ol><p>此方案主要有2个C#脚本，3个Shader实现。</p><ul><li>C#：<ol><li>DepthTextureCamera.cs: 实现从光源方向<strong>生成Shadow Map</strong>；</li><li>ShadowCollector.cs: 屏幕空间进行<strong>阴影收集（Shadow Collector）</strong></li></ol></li><li>Shader:<ol><li>CustomCaster.shader: 用于渲染深度图；</li><li>ShadowCollector.shader: 用于逐像素比较深度，并实现具体的PCSS算法；</li><li>CustromReciver.shader: 用于应用ShadowCollector得到的阴影图片，并通过屏幕空间的坐标进行采样，得到Visibility项；</li></ol></li></ul><p>以下，给出PCSS的主要代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">float findBlocker(float2 UVfromLight, float ZReciver) &#123;// 返回Blocker的平均深度</span><br><span class="line">    float num_occ = 0.0f;</span><br><span class="line">    float Z_avg = 0.0f;</span><br><span class="line">    float filterSize = 30.0f / _cusShadowMap_TexelSize.z;</span><br><span class="line"></span><br><span class="line">    for (int i = 0; i&lt;BLOCKER_SEARCH_NUM_SAMPLES; i++) &#123;</span><br><span class="line">        float Z_SM = DecodeFloatRGBA(tex2D(_cusShadowMap, poissonDisk[i]*filterSize + UVfromLight));</span><br><span class="line">        if (Z_SM &lt; ZReciver) &#123;</span><br><span class="line">            num_occ++;</span><br><span class="line">            Z_avg += Z_SM;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    if (num_occ == 0) &#123;</span><br><span class="line">        return 1.0;</span><br><span class="line">    &#125;</span><br><span class="line">    return Z_avg / num_occ;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">float PCSS(float4 coord) &#123;</span><br><span class="line">    float zReceiver = coord.z / coord.w;</span><br><span class="line">    float2 uv = coord.xy / coord.w;</span><br><span class="line">    uv = uv * 0.5 + 0.5;</span><br><span class="line">#if defined (SHADER_TARGET_GLSL)    //(-1, 1) -&gt; (0, 1)</span><br><span class="line">    zReceiver = zReceiver * 0.5 + 0.5;</span><br><span class="line"></span><br><span class="line">#elif defined (UNITY_REVERSED_Z)</span><br><span class="line">    zReceiver = 1 - zReceiver;</span><br><span class="line">#endif</span><br><span class="line">    poissonDiskSamples(uv);// 泊松圆盘采样</span><br><span class="line">    float visibility = 0.0f;</span><br><span class="line"></span><br><span class="line">    float zBlocker = findBlocker(uv, zReceiver);</span><br><span class="line">    // 计算半影宽度</span><br><span class="line">    float wPenumbra = (zReceiver - zBlocker) * LIGHT_WIDTH / zBlocker;</span><br><span class="line"></span><br><span class="line">    float scale = 1.0f;</span><br><span class="line">    float filterSize = scale * wPenumbra / _cusShadowMap_TexelSize.z + 1.0f / _cusShadowMap_TexelSize.z;;</span><br><span class="line"></span><br><span class="line">    // PCF</span><br><span class="line">    for (int i = 0; i &lt; PCF_NUM_SAMPLES; i++) &#123;</span><br><span class="line">        float zNear = DecodeFloatRGBA(tex2D(_cusShadowMap, poissonDisk[i]*filterSize + uv));</span><br><span class="line">        if (zNear &gt; zReceiver) &#123;</span><br><span class="line">            visibility += 1;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return visibility / PCF_NUM_SAMPLES;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;图形-4-3-实时阴影介绍&quot;&gt;&lt;a href=&quot;#图形-4-3-实时阴影介绍&quot; class=&quot;headerlink&quot; title=&quot;图形 4.3 实时阴影介绍&quot;&gt;&lt;/a&gt;图形 4.3 实时阴影介绍&lt;/h1&gt;&lt;p&gt;更深的可看笔记Games202 Real-time Shadow&lt;/p&gt;
&lt;h1 id=&quot;a-基于图片实时阴影技术&quot;&gt;&lt;a href=&quot;#a-基于图片实时阴影技术&quot; class=&quot;headerlink&quot; title=&quot;a). 基于图片实时阴影技术&quot;&gt;&lt;/a&gt;a). 基于图片实时阴影技术&lt;/h1&gt;&lt;h2 id=&quot;a-1-Shadow-Map&quot;&gt;&lt;a href=&quot;#a-1-Shadow-Map&quot; class=&quot;headerlink&quot; title=&quot;a.1). Shadow Map&quot;&gt;&lt;/a&gt;a.1). Shadow Map&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键思想：&lt;/strong&gt;一个点在相机视角中可见，但在光源视角中不可见，那该点就处于阴影中。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;做法：&lt;/strong&gt; 在光源视角下渲染深度图。对于着色点$A$，将其转换到光源视角（其他空间也行，只要两者在同一坐标空间）后，与Shadow Map中对应点进行深度比较，判断一点是否在阴影中；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/深度比较.png&quot; alt=&quot;深度比较&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;A &lt;strong&gt;2-Pass&lt;/strong&gt; Algorithm&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Light pass: Generate the SM(Shadow Map)&lt;/li&gt;
&lt;li&gt;Camera pass: uses the SM&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;Pass-1-Render-from-Light&quot;&gt;&lt;a href=&quot;#Pass-1-Render-from-Light&quot; class=&quot;headerlink&quot; title=&quot;Pass 1: Render from Light&quot;&gt;&lt;/a&gt;Pass 1: Render from Light&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;输出一张&lt;strong&gt;光源视角&lt;/strong&gt;的&lt;strong&gt;深度图（Depth Buffer）&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/SM_Pass01.png&quot; alt=&quot;SM_Pass01&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;Pass-2-Render-from-Eye-Camera&quot;&gt;&lt;a href=&quot;#Pass-2-Render-from-Eye-Camera&quot; class=&quot;headerlink&quot; title=&quot;Pass 2: Render from Eye(Camera)&quot;&gt;&lt;/a&gt;Pass 2: Render from Eye(Camera)&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/SM_Pass02.png&quot; alt=&quot;SM_Pass02&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;将光源视角对应的深度转换到View Space, 与Camera视角的深度进行深度比较；&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如$Depth_{cam} &amp;gt; Depth_{light}$ ，那说明该点&lt;strong&gt;在阴影中&lt;/strong&gt;（相机可见，光源不可见）&lt;/li&gt;
&lt;li&gt;如$Depth_{cam} &amp;lt; Depth_{light}$ ，那说明该点在&lt;strong&gt;不在阴影中&lt;/strong&gt;（相机可见，光源可见）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    <category term="算法" scheme="https://whitetail-o.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="阴影" scheme="https://whitetail-o.github.io/tags/%E9%98%B4%E5%BD%B1/"/>
    
  </entry>
  
  <entry>
    <title>HPP_Graphics_3.7 移动端TB(D)R架构基础</title>
    <link href="https://whitetail-o.github.io/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/"/>
    <id>https://whitetail-o.github.io/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/</id>
    <published>2023-02-15T10:44:32.000Z</published>
    <updated>2023-03-17T05:13:36.127Z</updated>
    
    <content type="html"><![CDATA[<h1 id="a-名词解释"><a href="#a-名词解释" class="headerlink" title="a). 名词解释"></a>a). 名词解释</h1><h2 id="System-on-Chip-Soc"><a href="#System-on-Chip-Soc" class="headerlink" title="System on Chip(Soc)"></a>System on Chip(Soc)</h2><ul><li>Soc是把CPU、GPU、内存、通信基带、GPS模块等整合在一起的芯片的称呼。常见有A系Soc（苹果），骁龙Soc（高通），麒麟Soc（华为），联发科Soc，猎户座Soc（三星），去年苹果推出的M系Soc，暂用于Mac，但这说明手机、笔记本和PC的通用芯片已经出现了</li></ul><h2 id="物理内存"><a href="#物理内存" class="headerlink" title="物理内存"></a>物理内存</h2><ul><li>也就是我们常说的手机内存，也叫<strong>System Memory</strong>。Soc中CPU和GPU共用一块片内LPDDR物理内存。此外CPU和GPU还分别有自己的告诉SRAM的Cache缓存，也叫<strong>On-chip Memory</strong>。读取System Memory的时间消耗大概是On-chip Memory的几倍到几十倍</li></ul><h2 id="On-Chip-Buffer"><a href="#On-Chip-Buffer" class="headerlink" title="On-Chip Buffer"></a>On-Chip Buffer</h2><p>在TB(D)R架构下会存储Tile的颜色、深度和模板缓冲，读写修改都非常快。如果Load/Store指令中缓冲需要被Preserve，将会被写入一份到System Memory中。</p><h2 id="Stall"><a href="#Stall" class="headerlink" title="Stall"></a>Stall</h2><p>当GPU两次计算结果之间有依赖关系而必须串行时，等待的过程便是Stall</p><h2 id="FillRate"><a href="#FillRate" class="headerlink" title="FillRate"></a>FillRate</h2><p>像素填充率 = ROP运行的时钟频率 x ROP的个数 x 每个时钟ROP可以处理的像素个数</p><h2 id="TBR（Tile-Based-Deferred-Rendering）"><a href="#TBR（Tile-Based-Deferred-Rendering）" class="headerlink" title="TBR（Tile-Based (Deferred) Rendering）"></a>TBR（Tile-Based (Deferred) Rendering）</h2><p>TBR（Tile-Based (Deferred) Rendering）是目前主流的移动GPU渲染架构，对应一般PC上的GPU渲染架构则是IMR（Immediate Mode Rendering ）。</p><ul><li>TBR流水线：顶点着色器 - Defer - 光栅化 - 片元着色器</li><li>TBDR流水线：顶点着色器 - Defer - 光栅化 - Defer - 片元着色器</li></ul><h2 id="Deffer"><a href="#Deffer" class="headerlink" title="Deffer"></a>Deffer</h2><p> 延迟，从渲染数据的角度来看，就是 ”阻塞+批处理“ GPU ”一帧“ 的多个数据，然后一起处理</p><hr><h1 id="b-立即渲染（IMR，Immediate-Mode-Rendering-）"><a href="#b-立即渲染（IMR，Immediate-Mode-Rendering-）" class="headerlink" title="b). 立即渲染（IMR，Immediate Mode Rendering ）"></a>b). 立即渲染（IMR，Immediate Mode Rendering ）</h1><ul><li><p>IMR是PC上GPU采用的架构</p><p><img src="/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/IMR.png" alt="IMR"></p><p><img src="/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/IMR_Pipeline.png" alt="IMR_Pipeline"></p><p><img src="/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/IMR_Pipeline2.png" alt="IMR_Pipeline2" style="zoom:33%;"></p></li></ul><h1 id="c-基于块元渲染的TB-D-R"><a href="#c-基于块元渲染的TB-D-R" class="headerlink" title="c). 基于块元渲染的TB(D)R"></a>c). 基于块元渲染的TB(D)R</h1><p>TB(D)R宏观上总共分为两个阶段：</p><ol><li><strong>分图元：</strong> 第一阶段执行所有几何相关的处理，并生成Primitive List（图元列表），并且<strong>确定每个Tile上面有哪些Primitive</strong></li><li>第二阶段逐Tile执行 光栅化后 写入Tile Buffer（片上内存），并在完成后将 Frame BUffer 从 Tile Buffer 写回到 System Memory中；</li></ol><p><img src="/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/TBR_TBDR_Flow.png" alt="TBR_TBDR_Flow"></p><span id="more"></span><h2 id="c-1-TBDR-Pipeline"><a href="#c-1-TBDR-Pipeline" class="headerlink" title="c.1). TBDR Pipeline"></a>c.1). TBDR Pipeline</h2><p>下图为PowerVR的TBDR：</p><p><img src="/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/TBDR_Pipeline.png" alt="TBDR_Pipeline"></p><ul><li>Tilling后将图元列表和顶点数据传到System Memory，待需要光栅化时从System Memory取出。光栅化后进行HSR（因为是PowerVR的流程图所以是HSR）或Depth Test会将结果写入On-chip Buffer。同样，在逐片元操作后，会将Tile的结果写入Tile Buffer，并在完成Frame Buffer后从Tile Buffer写回到System Memory中</li></ul><p>下图为三星提出的流程图：</p><p><img src="/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/TBDR_Pipeline2.png" alt="TBDR_Pipeline2"></p><h2 id="c-2-TBR和IMR对比"><a href="#c-2-TBR和IMR对比" class="headerlink" title="c.2). TBR和IMR对比"></a>c.2). TBR和IMR对比</h2><p>(a)为TBR，(b)为IMR</p><p><img src="/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/TBR_IMR.png" alt="TBR_IMR"></p><ul><li><p><strong>TBR</strong>的核心目的是<strong><font color="red">降低带宽，减少功耗</font></strong>，但渲染帧率上并不比<strong>IMR</strong>快</p></li><li><p>图（a）TBR架构</p><ul><li><p>几何处理数据形成了FrameData（放在System Memory上）</p></li><li><p>这些Frame Data经过片段处理，结果放在了Tile Buffer上（片的内存上）</p></li><li><p>最后的结果会刷到FrameBuffer中（System Memory上）</p></li></ul></li><li><p>图（b）IMR架构</p><ul><li>对比TBR有以下两种区别<ul><li>几何处理数据直接到片段处理，没有中间数据（Frame Data）</li><li>直接刷到System Memory上了，没有经过片内存（On-Chip Memory）</li></ul></li></ul></li></ul><h3 id="TBR优点："><a href="#TBR优点：" class="headerlink" title="TBR优点："></a>TBR优点：</h3><ol><li>TBR大大<strong>减少了Overdraw</strong>，PowerVR使用了<strong>HSR</strong>技术，Mali使用了<strong>Forward Pixel Killing</strong>技术，目的是为了最大限度减少被遮挡Pixel的Texturing和shading；</li><li>TBR是Cache friendly，在cache里读写的速度比全局内存的速度要快得多，以降低帧率为代价，降低带宽，省电；</li></ol><h3 id="TBR缺点："><a href="#TBR缺点：" class="headerlink" title="TBR缺点："></a>TBR缺点：</h3><ol><li>Binning过程在Vertex阶段之后，将输出的集合数据写入到System Memory，然后才被FS读取，<strong>集合数据过多的管线，容易在Binning过程产生性能瓶颈；</strong></li><li>如一个三角形同时在多个Tile上，需要多次绘制（和Games101RayTracing中空间划分容易造成同一个Object存在多个叶子节点的原因类似）。这意味着总渲染时间高于IMR；</li></ol><h1 id="d-第一个Defer：Binning"><a href="#d-第一个Defer：Binning" class="headerlink" title="d). 第一个Defer：Binning"></a>d). 第一个Defer：Binning</h1><ul><li><p><strong>概念：将图元分配到块元的过程</strong></p></li><li><p><strong>过程：</strong> </p><p><img src="/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/Binning.png" alt="Binning"></p></li><li><p>注释：</p><ul><li>第二幅图里的红色三角形，只用一个块元就能渲染，所以它只会被分配到一个块元中</li><li>第四幅图里的棕色三角形，需要多个块元才能渲染，所以它需要分配到9个块元中一起渲染</li></ul></li><li><p><em>如果你的项目中binning过程相比其他耗时长的话，就要考虑一下是不是几何数据过多了</em></p></li></ul><h1 id="e-第二个Defer：不同GPU-的-Early-Depth-Test"><a href="#e-第二个Defer：不同GPU-的-Early-Depth-Test" class="headerlink" title="e). 第二个Defer：不同GPU 的 Early-Depth-Test"></a>e). 第二个Defer：不同GPU 的 Early-Depth-Test</h1><h2 id="Forward-Pixel-Kill"><a href="#Forward-Pixel-Kill" class="headerlink" title="Forward Pixel Kill"></a>Forward Pixel Kill</h2><p><img src="/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/Forward Pixel Kill.png" alt="Forward Pixel Kill"></p><ul><li><strong>Arm Mali</strong><ul><li>采用Forward Pixel Kill技术</li></ul></li></ul><ul><li><p><strong>位于管线的位置：</strong></p><ul><li>发生在Early-z之后</li></ul></li><li><p><strong>数据结构：</strong></p><ul><li>先进先出的队列</li></ul></li><li><p><strong>简单概括一下：</strong></p><ul><li><p>队列中有4个Quad（可以理解为2×2像素的平面），每个Quad有屏幕上位置的数据和Z数据</p></li><li><p>Z越大代表离摄像机越远</p></li><li><p>根据屏幕上相同位置（pos）的不同z，对不透明的像素进行替换（有近的就不渲染远的），这个过程叫作killed</p></li></ul></li></ul><h2 id="HSR"><a href="#HSR" class="headerlink" title="HSR"></a>HSR</h2><p><img src="/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/HSR.png" alt="HSR"></p><ul><li><p>PowerVR的<strong>HSR</strong></p><ul><li>HSR = Hide Surface Removal隐形面剔除</li></ul></li><li><p>大体实现原理：</p><ul><li>虚拟出一个射线，当它遇到第一个不透明的物体时就会停下来，这样就会打断后面三角形的后续ps处理</li></ul></li></ul><h1 id="f-优化建议"><a href="#f-优化建议" class="headerlink" title="f). 优化建议"></a>f). 优化建议</h1><ol><li><p><strong>记得在不使用FrameBuffer的时候clear或discard</strong></p><ul><li><p>这样做主要是为了清空积存在tile buffer上的中间数据（前边提到的Frame Data），</p></li><li><p>所以对Unity里的rt（render texture）的使用也特别说明一下：</p></li><li><p>当我们不再使用这个rt的时候，尽量调用一次Discard</p></li><li><p>在OpenGl ES上，要善用glclear，glInvalidateFrameBuffer，避免不必要的Resolve（tile buff刷新到system memory）行为</p></li></ul></li><li><p><strong>不要在一帧里频繁的切换FrameBuffer的绑定</strong></p><ul><li>本质：减少tile buffer和system memory之间的stall（同步）操作</li></ul></li></ol><ol><li><strong>对于移动平台，建议使用Alpha混合，而非Alpha测试。</strong><ul><li>是一个经验性的结论</li><li>在实际使用的过程中应该使用比较两者的表现</li><li>通常情况下，移动端应该避免使用Alpha混合来实现透明，如果确实要用，尝试缩小混合区域的覆盖范围</li></ul></li></ol><ol><li><strong>手机上必须用Alpha Test时，先做一遍Depth Prepass（参考Alpha Test 的双pass优化思路）</strong></li><li><strong>图片尽量压缩</strong><ul><li>例如ASTC 、ETC2</li></ul></li></ol><ol><li><p><strong>图片尽量走mipmap</strong></p></li><li><p><strong>尽量使用从vertex shader传来的Varying变量uv值采样贴图（连续的），不要在Fragment shader里动态计算贴图的uv值（非连续的），否则CacheMiss</strong></p></li><li><p><strong>在延迟渲染中，尽量利用Tile Buffer（参考传统延迟渲染和TBDR）</strong></p></li><li><p><strong>如果在Unity中调整ProjectSetting—-Quality—-Rendering—-Texture Quality的不同设置，或者不同分辨率下，帧率有很大的变化，大概率是带宽出问题了</strong></p></li><li><p><strong>MASS在TBDR下反而是非常快速的</strong></p><ul><li><p>MSAA是硬件上的，发生在片上的</p><p><img src="/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/TBDR_Pipeline.png" alt="TBDR_Pipeline"></p><ul><li>可以看到Tilling后的几何数据存到System Memory后，在Texture and Shade时仍然可以调用，这也为MSAA提供了便利</li></ul></li><li><p>相比FSAA，MSAA在手机上是非常快的</p></li></ul></li></ol><ol><li><p><strong>少在Fragment shader中使用discard函数，调用gl_FragDepth从而打断Early-DT的过程</strong></p><ul><li>（hlsl中为Clip，glsl中为discard）</li></ul></li><li><p><strong>在shader使用浮点数精度值时，有目的的区分使用float，half</strong></p><ul><li>优点<ul><li>带宽减少</li><li>GPU中用的周期数减少，因为着色器编译器可以优化你的代码来提高并行化程度</li><li>要求的统一变量寄存器的数量减少，这样反而又降低了寄存器数量溢出风险。</li><li>具体参考：熊大的优化建议、shader数学计算优化技巧</li></ul></li></ul></li><li><p><strong>在移动端的TBDR架构中，顶点处理部分（Binning过程）容易成为瓶颈</strong></p><ul><li>避免使用曲面细分shader，置换贴图等负操作</li><li><p>提倡使用模型LOD，（本质上减少Frame Data的压力）</p></li><li><p>Unity中尽早的在应用阶段做umbra（Unity内置）遮挡剔除、gpu的occlusion cull</p></li></ul></li></ol><hr><h1 id="【补充链接】"><a href="#【补充链接】" class="headerlink" title="【补充链接】"></a>【补充链接】</h1><p><a href="https://www.gpuinsight.com/gpu_performance/">GPU性能指标 </a>_</p><p><a href="https://developer.samsung.com/galaxy-gamedev/resources/articles/gpu-framebuffer.html">三星的GPU-FrameBuff指导</a></p><p><a href="https://www.techpowerup.com/231129/on-nvidias-tile-based-rendering">英伟达的TBR教学文章</a></p><p><a href="https://developer.arm.com/solutions/graphics-and-gaming/developer-guides/learn-the-basics/tile-based-rendering/single-page">ARM的TBR教学文章</a></p><p><a href="https://developer.apple.com/library/archive/documentation/3DDrawing/Conceptual/OpenGLES_ProgrammingGuide/Performance/Performance.html">苹果OpenGL程序开发指南</a></p><p><a href="https://www.seas.upenn.edu/~pcozzi/OpenGLInsights/OpenGLInsights-TileBasedArchitectures.pdf">OpenGL Insights</a></p><p><a href="https://www.zhihu.com/question/49141824">知乎文章：Tile-based 和 Full-screen 方式的 Rasterization 相比有什么优劣</a></p><p><a href="https://www.evolife.cn/html/2016/87847_5.html">移动图形芯片的故事</a></p><p><a href="https://zhuanlan.zhihu.com/p/112120206">移动设备GPU架构知识汇总</a></p><p><a href="https://zhuanlan.zhihu.com/p/33127345">再议移动平台的AlphaTest效率问题</a></p><p><a href="https://zhuanlan.zhihu.com/p/347001411">移动平台GPU硬件学习与理解</a></p><p><a href="http://cdn.imgtec.com/sdk-documentation/Introduction_to_PowerVR_for_Developers.pdf">PowerVR开发者指南</a></p><p><a href="https://www.cnblogs.com/gameknife/p/3515714.html">Performance Tunning for Tile-Based Architecture Tile-Based架构下的性能调校</a></p><p><a href="https://www.zhihu.com/question/29904258">TBDR的HSR流程细节和使用AlphaBlend的效率提升程度</a></p><p><a href="https://zhuanlan.zhihu.com/p/68158277">当我们谈优化时，我们谈些什么</a></p><p><a href="https://edu.uwa4d.com/course-intro/1/179">https://edu.uwa4d.com/course-intro/1/179</a> 虽然是收费的 但是很值得买，推荐</p><p><a href="https://zhuanlan.zhihu.com/p/58017068">Alpha Test的双pass 优化思路</a></p><p><a href="https://github.com/killop/anything_about_game#gpu-architecture">个人收藏</a></p><p><a href="https://www.youtube.com/watch?v=SeySx0TkluE&amp;pbjreload=101">Adreno Hardware Tutorial 3: Tile Based Rendering</a></p><p><a href="https://www.cnblogs.com/hamwj1991/p/12404551.html">Mali GPU的独有特性</a></p><p><a href="http://grmanet.sogang.ac.kr/ihm/cs170/20/HC27.25.531-Mali-T880-Bratt-ARM-2015_08_23.pdf">Mali-T880</a></p><p><a href="http://www.xionggf.com/post/my_books/u3d_shader_annotation">《Unity3D内建着色器源码剖析》</a></p><p><a href="http://www.xionggf.com/post/unity3d/shader/u3d_shader_optimization/">作者熊大的优化建议</a></p><p><a href="https://zhuanlan.zhihu.com/p/22232448">GPU画像素的顺序是什么</a></p><p><a href="https://www.youtube.com/watch?v=Nc6R1hwXhL8&amp;t=973s&amp;pbjreload=101">Tile-based Rasterization in Nvidia GPUs with David Kanter of Real World Tech</a></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;a-名词解释&quot;&gt;&lt;a href=&quot;#a-名词解释&quot; class=&quot;headerlink&quot; title=&quot;a). 名词解释&quot;&gt;&lt;/a&gt;a). 名词解释&lt;/h1&gt;&lt;h2 id=&quot;System-on-Chip-Soc&quot;&gt;&lt;a href=&quot;#System-on-Chip-Soc&quot; class=&quot;headerlink&quot; title=&quot;System on Chip(Soc)&quot;&gt;&lt;/a&gt;System on Chip(Soc)&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Soc是把CPU、GPU、内存、通信基带、GPS模块等整合在一起的芯片的称呼。常见有A系Soc（苹果），骁龙Soc（高通），麒麟Soc（华为），联发科Soc，猎户座Soc（三星），去年苹果推出的M系Soc，暂用于Mac，但这说明手机、笔记本和PC的通用芯片已经出现了&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;物理内存&quot;&gt;&lt;a href=&quot;#物理内存&quot; class=&quot;headerlink&quot; title=&quot;物理内存&quot;&gt;&lt;/a&gt;物理内存&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;也就是我们常说的手机内存，也叫&lt;strong&gt;System Memory&lt;/strong&gt;。Soc中CPU和GPU共用一块片内LPDDR物理内存。此外CPU和GPU还分别有自己的告诉SRAM的Cache缓存，也叫&lt;strong&gt;On-chip Memory&lt;/strong&gt;。读取System Memory的时间消耗大概是On-chip Memory的几倍到几十倍&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;On-Chip-Buffer&quot;&gt;&lt;a href=&quot;#On-Chip-Buffer&quot; class=&quot;headerlink&quot; title=&quot;On-Chip Buffer&quot;&gt;&lt;/a&gt;On-Chip Buffer&lt;/h2&gt;&lt;p&gt;在TB(D)R架构下会存储Tile的颜色、深度和模板缓冲，读写修改都非常快。如果Load/Store指令中缓冲需要被Preserve，将会被写入一份到System Memory中。&lt;/p&gt;
&lt;h2 id=&quot;Stall&quot;&gt;&lt;a href=&quot;#Stall&quot; class=&quot;headerlink&quot; title=&quot;Stall&quot;&gt;&lt;/a&gt;Stall&lt;/h2&gt;&lt;p&gt;当GPU两次计算结果之间有依赖关系而必须串行时，等待的过程便是Stall&lt;/p&gt;
&lt;h2 id=&quot;FillRate&quot;&gt;&lt;a href=&quot;#FillRate&quot; class=&quot;headerlink&quot; title=&quot;FillRate&quot;&gt;&lt;/a&gt;FillRate&lt;/h2&gt;&lt;p&gt;像素填充率 = ROP运行的时钟频率 x ROP的个数 x 每个时钟ROP可以处理的像素个数&lt;/p&gt;
&lt;h2 id=&quot;TBR（Tile-Based-Deferred-Rendering）&quot;&gt;&lt;a href=&quot;#TBR（Tile-Based-Deferred-Rendering）&quot; class=&quot;headerlink&quot; title=&quot;TBR（Tile-Based (Deferred) Rendering）&quot;&gt;&lt;/a&gt;TBR（Tile-Based (Deferred) Rendering）&lt;/h2&gt;&lt;p&gt;TBR（Tile-Based (Deferred) Rendering）是目前主流的移动GPU渲染架构，对应一般PC上的GPU渲染架构则是IMR（Immediate Mode Rendering ）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TBR流水线：顶点着色器 - Defer - 光栅化 - 片元着色器&lt;/li&gt;
&lt;li&gt;TBDR流水线：顶点着色器 - Defer - 光栅化 - Defer - 片元着色器&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Deffer&quot;&gt;&lt;a href=&quot;#Deffer&quot; class=&quot;headerlink&quot; title=&quot;Deffer&quot;&gt;&lt;/a&gt;Deffer&lt;/h2&gt;&lt;p&gt; 延迟，从渲染数据的角度来看，就是 ”阻塞+批处理“ GPU ”一帧“ 的多个数据，然后一起处理&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&quot;b-立即渲染（IMR，Immediate-Mode-Rendering-）&quot;&gt;&lt;a href=&quot;#b-立即渲染（IMR，Immediate-Mode-Rendering-）&quot; class=&quot;headerlink&quot; title=&quot;b). 立即渲染（IMR，Immediate Mode Rendering ）&quot;&gt;&lt;/a&gt;b). 立即渲染（IMR，Immediate Mode Rendering ）&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;IMR是PC上GPU采用的架构&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/IMR.png&quot; alt=&quot;IMR&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/IMR_Pipeline.png&quot; alt=&quot;IMR_Pipeline&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/IMR_Pipeline2.png&quot; alt=&quot;IMR_Pipeline2&quot; style=&quot;zoom:33%;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;c-基于块元渲染的TB-D-R&quot;&gt;&lt;a href=&quot;#c-基于块元渲染的TB-D-R&quot; class=&quot;headerlink&quot; title=&quot;c). 基于块元渲染的TB(D)R&quot;&gt;&lt;/a&gt;c). 基于块元渲染的TB(D)R&lt;/h1&gt;&lt;p&gt;TB(D)R宏观上总共分为两个阶段：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;分图元：&lt;/strong&gt; 第一阶段执行所有几何相关的处理，并生成Primitive List（图元列表），并且&lt;strong&gt;确定每个Tile上面有哪些Primitive&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;第二阶段逐Tile执行 光栅化后 写入Tile Buffer（片上内存），并在完成后将 Frame BUffer 从 Tile Buffer 写回到 System Memory中；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/TBR_TBDR_Flow.png&quot; alt=&quot;TBR_TBDR_Flow&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    <category term="硬件" scheme="https://whitetail-o.github.io/tags/%E7%A1%AC%E4%BB%B6/"/>
    
    <category term="移动端" scheme="https://whitetail-o.github.io/tags/%E7%A7%BB%E5%8A%A8%E7%AB%AF/"/>
    
    <category term="架构" scheme="https://whitetail-o.github.io/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>HPP_Graphics_3.6 纹理压缩</title>
    <link href="https://whitetail-o.github.io/2023/02/15/HPP_Graphics_3.6_%E7%BA%B9%E7%90%86%E5%8E%8B%E7%BC%A9/"/>
    <id>https://whitetail-o.github.io/2023/02/15/HPP_Graphics_3.6_%E7%BA%B9%E7%90%86%E5%8E%8B%E7%BC%A9/</id>
    <published>2023-02-15T10:42:32.000Z</published>
    <updated>2023-03-17T05:12:06.555Z</updated>
    
    <content type="html"><![CDATA[<h1 id="a-纹理压缩简介"><a href="#a-纹理压缩简介" class="headerlink" title="a). 纹理压缩简介"></a>a). 纹理压缩简介</h1><ul><li>纹理压缩是为了解决<strong>内存</strong>、<strong>带宽</strong>问题，专为在计算机图形渲染系统中存储<strong>纹理</strong>而使用的图像压缩技术；</li></ul><h2 id="a-1-图片压缩-vs-纹理压缩（为什么要纹理压缩）"><a href="#a-1-图片压缩-vs-纹理压缩（为什么要纹理压缩）" class="headerlink" title="a.1). 图片压缩 vs. 纹理压缩（为什么要纹理压缩）"></a>a.1). 图片压缩 vs. 纹理压缩（为什么要纹理压缩）</h2><ul><li>图片格式：JPG、PNG、GIF、BMP等；</li><li><strong>纹理压缩格式：</strong> ETC、DXT、ASTC等</li></ul><p>图片压缩格式大部分都是整体依赖，即不支持像素随机访问（基于整张图片进行压缩，无法直接实现单个像素的解析），且图片压缩格式无法被GPU识别，还需要经CPU解压缩成非压缩纹理格式才能被识别。<strong>因此采用基于块压缩的纹理压缩，能够更快读取像素所属字节进行解压缩以支持<font color="red">随机访问</font>。</strong></p><ul><li><p><strong>纹理管线：</strong></p><p><img src="/2023/02/15/HPP_Graphics_3.6_%E7%BA%B9%E7%90%86%E5%8E%8B%E7%BC%A9/TexturePipeline.png" alt="TexturePipeline"></p></li></ul><h1 id="b-常见纹理压缩格式"><a href="#b-常见纹理压缩格式" class="headerlink" title="b). 常见纹理压缩格式"></a>b). 常见纹理压缩格式</h1><p><img src="/2023/02/15/HPP_Graphics_3.6_%E7%BA%B9%E7%90%86%E5%8E%8B%E7%BC%A9/常见纹理压缩格式.png" alt="常见纹理压缩格式"></p><span id="more"></span><h2 id="b-1-DXTC"><a href="#b-1-DXTC" class="headerlink" title="b.1). DXTC"></a>b.1). DXTC</h2><p>DCTC纹理压缩格式来源于S3公司提出的S3TC算法，基本思想是把4×4的像素块压缩成一个64或128位的数据块，优点为创建了一个固定大小且独立的编码片段，没有共享查找表或其他依赖关系，简化了解码过程；</p><p><img src="/2023/02/15/HPP_Graphics_3.6_%E7%BA%B9%E7%90%86%E5%8E%8B%E7%BC%A9/DXT00.jpg" alt="DXT00"></p><h3 id="b-1-1-DXT1-BC1"><a href="#b-1-1-DXT1-BC1" class="headerlink" title="b.1.1). DXT1(BC1)"></a>b.1.1). DXT1(BC1)</h3><p>适用于：不包含透明信息RGB、只包含1位透明信息的贴图（即透明或完全不透明）</p><ul><li><p><strong>对与不包含透明信息的RGB</strong></p><ul><li><p>每一块具有两个16位RGB颜色值（<strong>RGB5<font color="red">6</font>5</strong>）$color_a、color_b$，代表了此4x4像素块中颜色极端值，然后通过线性插值计算出两个中间颜色值，16个2位索引值则表示每一个像素的颜色值索引。</p></li><li><p>所以，对与4x4的像素块：</p><ul><li><p>2x16 RGB颜色值（RGB565）</p></li><li><p>16x2 颜色索引值（索引2个颜色极端值+2个插值得到的中间值）</p></li></ul></li></ul></li></ul><p><img src="/2023/02/15/HPP_Graphics_3.6_%E7%BA%B9%E7%90%86%E5%8E%8B%E7%BC%A9/DXT1.png" alt="DXT1"></p><ul><li>对与包含1位透明信息的纹理<ul><li>通过$color_a、color_b$ 插值出一个颜色中间值 $color_c$ ，并用 $color_d$ 表示透明/不透明，其每个像素通过2位索引这四个颜色</li></ul></li><li><strong>压缩率：6:1</strong></li></ul><h3 id="b-1-2-DXT2-DXT3-BC2"><a href="#b-1-2-DXT2-DXT3-BC2" class="headerlink" title="b.1.2). DXT2/DXT3 (BC2)"></a>b.1.2). DXT2/DXT3 (BC2)</h3><p>DXT2/3与DXT1类似，表示颜色信息的64位数据块不变，另外附加了64位数据来表示每个像素的Alpha信息，整个数据块变为了128位；；</p><p>每个像素占用8位，0-3表示透明信息，4-7表示颜色信息；</p><h3 id="b-1-3-DXT4-DXT5-BC3"><a href="#b-1-3-DXT4-DXT5-BC3" class="headerlink" title="b.1.3). DXT4/DXT5 (BC3)"></a>b.1.3). DXT4/DXT5 (BC3)</h3><p>DXT4/5与DXT2/3的差异在于其Alpha信息是通过线性插值所得的，表示颜色信息的64位数据块依然不变，而Alpha信息则由2个8位Alpha极端值和16个3位索引值组成；</p><p>DXT5和DXT3分别计算RGB和A再混合，而DXT4和DXT2先混合RGBA，若A改变也不再重新混合而是直接改变整体颜色</p><h3 id="b-1-4-DXTnm"><a href="#b-1-4-DXTnm" class="headerlink" title="b.1.4). DXTnm"></a>b.1.4). DXTnm</h3><p>Unity内贴图类型选为法线后会采用DXTnm压缩格式，该格式会把法线贴图R通道存入A通道，然后RB通道清除为1，这样可以将法线XY信息分别存入到RGB/A中分别压缩，以获得更高的精度，然后再根据XY构建出Z通道数据；</p><p>即将法线贴图RGBA变为AG通道；</p><p><img src="/2023/02/15/HPP_Graphics_3.6_%E7%BA%B9%E7%90%86%E5%8E%8B%E7%BC%A9/AG.png" alt="AG" style="zoom:25%;"></p><h2 id="b-2-ATI1-2"><a href="#b-2-ATI1-2" class="headerlink" title="b.2). ATI1/2"></a>b.2). ATI1/2</h2><h3 id="b-2-1-ATI1-BC4-4x4-4位"><a href="#b-2-1-ATI1-BC4-4x4-4位" class="headerlink" title="b.2.1). ATI1(BC4, 4x4 4位)"></a>b.2.1). ATI1(BC4, 4x4 4位)</h3><p>ATI1为ATI公司开发的纹理压缩格式，也被称为BC4，其每个数据块存储<strong>单个颜色的数据通道</strong>，以与DXT5中的Alpha数据相同的方式进行编码，常用于存储高度图、光滑度贴图，效果与原始图像基本无差异；</p><ul><li>压缩比：2:1</li></ul><h3 id="b-2-2-ATI2-BC5-4x4-8位"><a href="#b-2-2-ATI2-BC5-4x4-8位" class="headerlink" title="b.2.2). ATI2(BC5, 4x4 8位)"></a>b.2.2). ATI2(BC5, 4x4 8位)</h3><p>每一个块中存储<strong>两个颜色通道的数据</strong>，同上以与DXT5中Alpha数据相同的方式进行编码，相当于存储了两个BC4块；</p><ul><li>压缩比：2:1</li></ul><p>如果是在将法线存储在XY双通道中采用BC5格式压缩，由于每个通道都有自己的索引，因此法线贴图XY信息可以比在BC1中保留更多的保真度，缺点是需要使用两倍内存，也需要更多的带宽才能将纹理传递到着色器中；</p><h2 id="b-3-BC6-7"><a href="#b-3-BC6-7" class="headerlink" title="b.3). BC6/7"></a>b.3). BC6/7</h2><p>BC6和BC7仅在D3D11级图形硬件中受支持，他们每个块占用16字节，BC7针对8位RGB或RGBA数据，而BC6针对RGB半精度浮点数据，因此BC6是唯一一个可以原生存储HDR的BC格式；</p><p><strong>BC6</strong>是专门针对<strong>HDR</strong>（高动态范围）图像设计的压缩算法，压缩比为6：1；</p><p><strong>BC7</strong>是专门针对LDR（低动态范围）图像设计的压缩算法，压缩比为3：1，该格式用于<strong>高质量</strong>的RGBA压缩，可以显著减少由于压缩法线带来的错误效果，但这也意味着解码所带来更多的消耗；</p><h2 id="b-4-ETC"><a href="#b-4-ETC" class="headerlink" title="b.4). ETC"></a>b.4). ETC</h2><p>ETC（Ericsson Texture Compression）最初为移动设备开发，如今它是安卓的标准压缩方案，ETC1在OpenGL和OpenGL ES中都有支持。</p><p>将4x4 的像素块编码为2x4或4x2像素（<strong>64位</strong>）的两个块的方法，每个块指定一个基色，每个像素的颜色通过一个编码为相对于这些基色偏移的灰度值确定。</p><p><img src="/2023/02/15/HPP_Graphics_3.6_%E7%BA%B9%E7%90%86%E5%8E%8B%E7%BC%A9/ETC.png" alt="ETC"></p><p>具体来说，ETC1每4x4像素块编码为64位的字节数据，每一个像素块又分为两个2x4子块（由一个“flip”位控制水平或竖直划分），每个子块包含一个3位的修饰表索引（modifier table index）和一个基本颜色值，这两个颜色值要么是2*R4G4B4要么是R5G5B5+R3G3B3（由一个“ diff”位控制是哪一种）。</p><p><img src="/2023/02/15/HPP_Graphics_3.6_%E7%BA%B9%E7%90%86%E5%8E%8B%E7%BC%A9/ETC1.png" alt="ETC1" style="zoom:50%;"></p><ul><li>24位颜色块（RGB444x2 或 RGB333+RGB555）</li><li>2x4位<strong>亮度索引</strong>中<ul><li>2x3位用于修饰表索引（索引table中列数）</li><li>2x1位用于flip或diff（如左边块为flip，右边块为diff）</li></ul></li><li>每个像素中2位<strong>像素索引</strong>，索引对应列中行数</li></ul><ul><li>ETC2是ETC1的扩展，支持了Alpha通道的压缩，硬件要求OpenGL ES 3.0和OpenGL 4.3以上；</li></ul><h2 id="b-5-ASTC"><a href="#b-5-ASTC" class="headerlink" title="b.5). ASTC"></a>b.5). ASTC</h2><p>ASTC是由ARM和AMD联合开发的纹理压缩格式，ASTC在各项指标上都挺不错，优点是可根据不同图片选择不同压缩率的算法，<strong>图片不需要为2的幂次</strong>，同时<strong>支持LDR和HDR</strong>，缺点是<strong>兼容性不够完善且解码时间较长</strong>；</p><p>ASTC也是基于块的压缩算法，与BC7类似，其数据块大小固定为<strong>128</strong>位，不同的是<strong>块中的像素数量可变</strong>，从4×4到12×12像素都有；</p><p>每一个数据块中存储了两个插值端点，但<strong>不一定存储的是颜色信息，也可能是Layer信息</strong>，这样可以用来对Normal或Alpha进行更好的压缩；</p><p>对于块中每一个纹素，存储其对应插值端点的权重，存储的权重数量可以少于纹素数量，可通过插值得到每一个纹素的权重值，然后再进行颜色的计算；</p><ul><li><p><strong>11</strong>位：权重、高度信息，特殊块标识；</p></li><li><p><strong>2</strong>位：Part数量；</p></li><li><p><strong>4</strong>位：16种插值端点模式（如LDR/HDR，RGB/RGBA）；</p></li><li><p><strong>111</strong>位：插值端点信息，纹素权重值，配置信息；</p></li></ul><h2 id="b-6-PVRTC"><a href="#b-6-PVRTC" class="headerlink" title="b.6). PVRTC"></a>b.6). PVRTC</h2><p>PVRTC由Imagination公司专为PowerVR显卡设计，仅支持Iphone、Ipad和部分安卓机；</p><p>不同于DXTC和ETC这类基于块的算法，PVRTC将图像分为了低频信号和高频信号，低频信号由两张低分辨率图像AB组成，高频信号则是低精度的调制图像，记录了每个像素混合的权重，解码时AB图像经过双线性插值放大，然后根据调制图像的权重进行混合；</p><p>PVRTC 4-bpp(bit per pixel)把一个4×4的像素单元压成一个64位数据块，每一个块中存储一个32位的调制数据，一个1位的调制标志，15位的颜色$color_a$，1位颜色A不透明标志，14位颜色$color_b$，1位颜色B不透明标志；</p><ul><li><p>15+14位：储存RGB时，$color_a$ 是 RGB555，$color_b$ 是 RGB554</p><p>​                   储存RGBA时，$color_a$ 是 RGBA4443，$color_b$ 是 RGBA4433</p></li><li><p>16x2位：每个像素2位调制数据</p></li><li>1位：调制模式，0/1位不同模式得到两颜色的Alpha值（混合值）</li><li>1+1位不透明标志：决定使用RGB/RGBA储存模式（$a1 || a2$, 哪个高选哪个）</li></ul><p>而PVRTC 2-bpp则是把一个8×4的像素单元压成了64位数据块；</p><h1 id="c-对比"><a href="#c-对比" class="headerlink" title="c). 对比"></a>c). 对比</h1><ul><li><p>画质比较（参考）</p><p>RGBA &gt; ASTC 4×4 &gt; ASTC 6×6 &gt; ETC2 ≈ ETC1</p></li></ul><ul><li><p>压缩比</p><p><img src="/2023/02/15/HPP_Graphics_3.6_%E7%BA%B9%E7%90%86%E5%8E%8B%E7%BC%A9/Rate.png" alt="Rate"></p></li></ul><h1 id="d-格式使用建议"><a href="#d-格式使用建议" class="headerlink" title="d). 格式使用建议"></a>d). 格式使用建议</h1><p>PC：</p><ol><li>低质量使用DXT1格式不支持A通道，使用DXT5格式支持A通道；</li><li>高质量使用BC7格式，支持A通道；</li></ol><p>安卓：</p><ol><li>低质量使用ETC1格式，但不支持A通道；</li><li>低质量使用ETC2格式，支持A通道，需要在OpenGL ES 3.0/OpenGL 4.3以上版本；</li><li>高质量使用ASTC格式，需要在Android 5.0/OpenGL ES 3.1以上版本；</li></ol><p>IOS：</p><ol><li>高质量使用ASTC格式，需要iPhone6以上版本；</li><li>低质量使用PVRTC2格式，支持iPhone6以下版本；</li></ol><hr><h1 id="【补充链接】"><a href="#【补充链接】" class="headerlink" title="【补充链接】"></a>【补充链接】</h1><p><a href="https://docs.unity3d.com/cn/current/Manual/class-TextureImporterOverride.html">https://docs.unity3d.com/cn/current/Manual/class-TextureImporterOverride.html</a></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;a-纹理压缩简介&quot;&gt;&lt;a href=&quot;#a-纹理压缩简介&quot; class=&quot;headerlink&quot; title=&quot;a). 纹理压缩简介&quot;&gt;&lt;/a&gt;a). 纹理压缩简介&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;纹理压缩是为了解决&lt;strong&gt;内存&lt;/strong&gt;、&lt;strong&gt;带宽&lt;/strong&gt;问题，专为在计算机图形渲染系统中存储&lt;strong&gt;纹理&lt;/strong&gt;而使用的图像压缩技术；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;a-1-图片压缩-vs-纹理压缩（为什么要纹理压缩）&quot;&gt;&lt;a href=&quot;#a-1-图片压缩-vs-纹理压缩（为什么要纹理压缩）&quot; class=&quot;headerlink&quot; title=&quot;a.1). 图片压缩 vs. 纹理压缩（为什么要纹理压缩）&quot;&gt;&lt;/a&gt;a.1). 图片压缩 vs. 纹理压缩（为什么要纹理压缩）&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;图片格式：JPG、PNG、GIF、BMP等；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;纹理压缩格式：&lt;/strong&gt; ETC、DXT、ASTC等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;图片压缩格式大部分都是整体依赖，即不支持像素随机访问（基于整张图片进行压缩，无法直接实现单个像素的解析），且图片压缩格式无法被GPU识别，还需要经CPU解压缩成非压缩纹理格式才能被识别。&lt;strong&gt;因此采用基于块压缩的纹理压缩，能够更快读取像素所属字节进行解压缩以支持&lt;font color=&quot;red&quot;&gt;随机访问&lt;/font&gt;。&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;纹理管线：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.6_%E7%BA%B9%E7%90%86%E5%8E%8B%E7%BC%A9/TexturePipeline.png&quot; alt=&quot;TexturePipeline&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;b-常见纹理压缩格式&quot;&gt;&lt;a href=&quot;#b-常见纹理压缩格式&quot; class=&quot;headerlink&quot; title=&quot;b). 常见纹理压缩格式&quot;&gt;&lt;/a&gt;b). 常见纹理压缩格式&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.6_%E7%BA%B9%E7%90%86%E5%8E%8B%E7%BC%A9/常见纹理压缩格式.png&quot; alt=&quot;常见纹理压缩格式&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    <category term="优化" scheme="https://whitetail-o.github.io/tags/%E4%BC%98%E5%8C%96/"/>
    
    <category term="纹理" scheme="https://whitetail-o.github.io/tags/%E7%BA%B9%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>HPP_Graphics_3.4 前向渲染与延迟渲染</title>
    <link href="https://whitetail-o.github.io/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/"/>
    <id>https://whitetail-o.github.io/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/</id>
    <published>2023-02-15T10:40:32.000Z</published>
    <updated>2023-03-17T05:09:23.488Z</updated>
    
    <content type="html"><![CDATA[<h1 id="a-渲染路径"><a href="#a-渲染路径" class="headerlink" title="a). 渲染路径"></a>a). 渲染路径</h1><ul><li>决定光照的实现方式。简言之，就是当前渲染目标使用<strong><font color="red">光照的流程</font></strong>。</li></ul><h1 id="b-渲染方式"><a href="#b-渲染方式" class="headerlink" title="b). 渲染方式"></a>b). 渲染方式</h1><ul><li><strong>延迟渲染</strong></li><li><strong>前向渲染</strong></li></ul><p><img src="/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/Difference.png" alt="Difference"></p><p>可以看到前向渲染中，中间蓝色的灯并没被渲染。（场景8盏灯，Project Setting中Pixel Light Count设为7）</p><h2 id="b-1-前向-正向渲染-Forward-Rendering"><a href="#b-1-前向-正向渲染-Forward-Rendering" class="headerlink" title="b.1). 前向/正向渲染-Forward Rendering"></a>b.1). 前向/正向渲染-Forward Rendering</h2><ul><li>简介：每个Object对每个光照都计算；</li></ul><h3 id="b-1-1-流程"><a href="#b-1-1-流程" class="headerlink" title="b.1.1). 流程"></a>b.1.1). 流程</h3><p><img src="/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/Forward_Workflow.png" alt="Forward_Workflow"></p><ul><li>简单来说就是不管光源的影响大不大，计算的时候都会把所有光源计算进去，这样就会造成一个很大的浪费</li></ul><h3 id="b-1-2-规则和注意事项"><a href="#b-1-2-规则和注意事项" class="headerlink" title="b.1.2). 规则和注意事项"></a>b.1.2). 规则和注意事项</h3><ul><li><p><strong>发生在顶点处理阶段，会计算所有顶点的光照</strong>。全平台支持</p></li><li><ul><li>规则1：最亮的几个光源会被实现为像素光照</li><li>规则2：然后就是，最多四个光源会被实现为顶点光照</li><li>规则3：剩下的光源会实现为效率较高的球面调谐光照（Spherical Hamanic），这是一种模拟光照</li></ul></li><li><p><strong>补充说明</strong></p></li><li><ul><li>最亮的那盏光一定是像素光照</li><li>Light的Render Mode是important的光一定是像素光照</li><li>如果前面的两条加起来的像素光照小于Quality Setting里的Pixel Light Count（最大像素光照数量），那么从剩下的光源中找出最亮的那几盏光源，实现为像素光照。</li><li>最后剩下的光源，按照规则2或3。</li><li>在base pass里执行一盏像素光、所有的顶点光和球面调谐光照，并且进行阴影计算。</li><li>其余的像素光每盏一个Additional Pass，并且这些pass里没有阴影计算。</li><li>场景中看到的阴影，全是base pass里计算出最亮那盏像素光的阴影，其他像素光是不计算阴影的。</li></ul></li><li><p><strong>最多的光源数是可以更改的</strong></p><ul><li>以Unity中的为例，在project setting中</li></ul><p><img src="/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/UnityForwardSetting.png" alt="UnityForwardSetting"></p></li></ul><h2 id="b-2-延迟渲染（Deferred-Rendering）"><a href="#b-2-延迟渲染（Deferred-Rendering）" class="headerlink" title="b.2). 延迟渲染（Deferred Rendering）"></a>b.2). 延迟渲染（Deferred Rendering）</h2><h3 id="b-2-1-简介"><a href="#b-2-1-简介" class="headerlink" title="b.2.1). 简介"></a>b.2.1). 简介</h3><p>主要解决<strong>大量光照渲染</strong>的方案。</p><p>可以将延迟渲染(Deferred Rendering)理解为先将所有物体都先绘制到屏幕空间的缓冲（即<strong>G-buffer</strong>，Geometric Buffer，几何缓冲区）中，再逐光源对该缓冲进行着色的过程，从而避免了因计算被深度测试丢弃的片元的着色而产生的不必要的开销。也就是说延迟渲染<strong>基本思想</strong>是，<strong>先执行深度测试（应该也包括其他测试），再进行着色计算</strong>，将本来在物空间（三维空间）进行光照计算放到了<strong>像空间</strong>（二维空间）进行处理。</p><p>对应于正向渲染O(m*n)的 复杂度，经典的延迟渲染复杂度为O(n+m)。</p><span id="more"></span><h3 id="b-2-2-流程"><a href="#b-2-2-流程" class="headerlink" title="b.2.2). 流程"></a>b.2.2). 流程</h3><p><img src="/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/Deffer_Workflow.png" alt="Deffer_Workflow" style="zoom:33%;"></p><p><img src="/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/Deffer_Workflow2.jpg" alt="Deffer_Workflow2"></p><p>可以将延迟渲染理解为两个Pass的过程：</p><ol><li><p><strong>几何处理阶段(Geometry Pass)。</strong>这个阶段中，我们获取对象的各种<strong>几何信息</strong>（Position、Normal、Albedo、Specular等），并将第二步所需的各种数据储存（也就是渲染）到多个<strong>G-buffer</strong>中；</p><ul><li>由于有深度测试，所以最终写入G-buffer中的，都是离摄像机最近的片元的集合属性，这就意味着，在G-buffer中的片元必定要进行光照计算。</li></ul></li><li><p><strong>光照处理阶段(Lighting Pass)。</strong>在这个pass中，我们只需渲染出一个屏幕大小的二维矩形，使用第一步在G-buffer中存储的数据对此矩阵的每一个片段<strong>计算场景的光照</strong>；光照计算的过程还是和正向渲染以前一样，只是现在<strong>我们需要从对应的G-buffer而不是顶点着色器(和一些uniform变量)那里获取输入变量了</strong>。</p></li></ol><p><img src="/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/Deffer_Workflow3.jpg" alt="Deffer_Workflow3"></p><h3 id="b-2-3-G-Buffer"><a href="#b-2-3-G-Buffer" class="headerlink" title="b.2.3). G-Buffer"></a>b.2.3). G-Buffer</h3><p><strong>G-Buffer</strong>，全称Geometric Buffer ，译作几何缓冲区，它主要用于存储每个像素对应的位置（Position），法线（Normal），漫反射颜色（Diffuse Color）以及其他有用材质参数。根据这些信息，就可以在像空间（二维空间）中对每个像素进行光照处理。</p><ul><li><p>如图为一个典型的G-buffer<img src="/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/G-Buffer.jpg" alt="G-Buffer"></p></li><li><p>下图是一帧中G-buffer中存储的内容：</p><p><img src="/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/G-Buffer2.jpg" alt="G-Buffer2"></p></li><li><p>UE5中的G-Buffer</p><p><img src="/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/G-Buffer_Constant.png" alt="G-Buffer_Constant"></p></li></ul><p>在几何处理阶段中填充G-buffer非常高效，因为我们直接储存位置，颜色，法线等对象信息到帧缓冲中，这个过程几乎不消耗处理时间。</p><p>而在此基础上使用<strong>多渲染目标(Multiple Render Targets, MRT)技术</strong>，我们可以在一个Pass之内完成所有渲染工作。</p><ul><li><p>P-Code</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">For each object:</span><br><span class="line">    Render to multiple targets </span><br><span class="line">For each light:</span><br><span class="line">    Apply light as a 2D postprocess</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Two-pass deferred shading algorithm</span><br><span class="line">Pass 1: geometry pass</span><br><span class="line">- Write visible geometry information to G-buffer</span><br><span class="line">Pass 2: shading pass</span><br><span class="line">For each G-buffer sample, compute shading</span><br><span class="line">- Read G-buffer data for current sample</span><br><span class="line">- Accumulate contribution of all lights</span><br><span class="line">- Output final surface color</span><br></pre></td></tr></table></figure></li></ul><h3 id="b-2-4-延迟渲染的优缺点"><a href="#b-2-4-延迟渲染的优缺点" class="headerlink" title="b.2.4). 延迟渲染的优缺点"></a>b.2.4). 延迟渲染的优缺点</h3><ul><li><p><strong>优点：</strong></p><ol><li>复杂度仅O(n+m)</li><li>只渲染可见的像素，节省计算量</li><li>用更少的shader</li><li>对后处理支持良好（例如深度信息：直接拿G-buffer中的就行。而前向渲染需要单独Pass再渲染一张深度图）</li><li>在大量光源的场景优势尤其明显；</li></ol></li><li><p><strong>缺点：</strong></p><ol><li>内存开销较大，且占用了大量的显存带宽；<ul><li>需要传递G-Buffer；</li><li>有时需要用到G-Buffer的信息，如深度图做后处理，那将不会进行Clear；</li></ul></li><li>只能用同一套Lighting Pass；</li><li>对透明物体的渲染存在问题。在这点上需要结合正向渲染进行渲染；</li><li>对多重采样抗锯齿（MultiSampling Anti-Aliasing, MSAA）等硬件抗锯齿的支持不友好，主要因为需开启MRT；<ul><li>MSAA是依赖于子像素，而Deffered shading<strong>处在光栅化之后（单个像素内值相等）</strong>，传输数据是通过G-Buffer；</li><li>但可使用TAA</li></ul></li></ol><p><a href="https://www.zhihu.com/question/20236638/answer/44821615">问FXAA、FSAA与MSAA有什么区别？效果和性能上哪个好？ - 文刀秋二的回答 - 知乎</a></p><p><a href="https://catlikecoding.com/unity/tutorials/rendering/part-13/">https://catlikecoding.com/unity/tutorials/rendering/part-13/</a></p></li></ul><h2 id="b-3-Unity中渲染路径设置"><a href="#b-3-Unity中渲染路径设置" class="headerlink" title="b.3). Unity中渲染路径设置"></a>b.3). Unity中渲染路径设置</h2><p><img src="/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/RenderPathSetting.png" alt="RenderPathSetting"></p><h2 id="b-4-其他渲染路径"><a href="#b-4-其他渲染路径" class="headerlink" title="b.4). 其他渲染路径"></a>b.4). 其他渲染路径</h2><p>针对延迟渲染上述提到的缺点，下面简单列举一些降低 Deferred Rendering 存取带宽的改进方案。最简单也是最容易想到的就是将存取的 G-Buffer 数据结构最小化，这也就衍生出了 Light Pre-Pass（即Deferred Lighting） 方法。另一种方式是将多个光照组成一组，然后一起处理，这种方法衍生了 Tile-Based Deferred Rendering。</p><p>也就是说，常见的两种Deferred Rendering的改进是：</p><ul><li>延迟光照 Light Pre-Pass（即Deferred Lighting）</li><li>分块延迟渲染 Tile-BasedDeferred Rendering</li></ul><h3 id="b-4-1-延迟光照（LightPre-Pass-Deferred-Lighting）"><a href="#b-4-1-延迟光照（LightPre-Pass-Deferred-Lighting）" class="headerlink" title="b.4.1). 延迟光照（LightPre-Pass / Deferred Lighting）"></a>b.4.1). 延迟光照（LightPre-Pass / Deferred Lighting）</h3><ul><li>减少G-buffer占用的过多开销，支持多种光照模型</li></ul><ul><li>过程：</li></ul><ol><li><p>渲染场景中不透明（opaque ）的几何体。将法线向量n和镜面扩展因子（specular spread factor）m 写入缓冲区。这个n/m-buffer 缓冲区是一个类似 G-Buffer的缓冲区，但包含的信息更少，更轻量，适合于单个输出颜色缓冲区，因此不需要MRT支持。</p></li><li><p>渲染光照。计算漫反射和镜面着色方程，并将结果写入不同的漫反射和镜面反射累积缓冲区。这个过程可以在一个单独的pass中完成（使用MRT），或者用两个单独的pass。环境光照明可以在这个阶段使用一个 full-screen pass进行计算。</p></li><li><p>对场景中的不透明几何体进行第二次渲染。从纹理中读取漫反射和镜面反射值，对前面步骤中漫反射和镜面反射累积缓冲区的值进行调制，并将最终结果写入最终的颜色缓冲区。若在上一阶段没有处理环境光照明，则在此阶段应用环境光照明。</p></li><li><p>使用非延迟着色方法渲染半透明几何体。</p></li></ol><ul><li>用更少的buffe信息，着色计算的时候用的是forward，所以第三步开始都是前向渲染（在3D，而不是2D的像空间中渲染）</li></ul><p><img src="/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/Deffer_Light.jpg" alt="Deffer_Light"></p><h3 id="b-4-2-Forward-（即Tiled-Forward-Rendering，分块正向渲染）"><a href="#b-4-2-Forward-（即Tiled-Forward-Rendering，分块正向渲染）" class="headerlink" title="b.4.2). Forward+（即Tiled Forward Rendering，分块正向渲染）"></a>b.4.2). Forward+（<strong>即Tiled Forward Rendering，分块正向渲染</strong>）</h3><ul><li><p>减少带宽，支持多光源，强制需要一个preZ</p></li><li><ul><li>通过分块索引的方式，以及深度和法线信息来到需要进行光照计算的片元进行光照计算。</li><li>需要法线和深度的后处理需要单独渲染一个rt出来</li><li>强制使用了一个preZ（如果没涉及过这个概念的话，可以理解为进行了一个深度预计算</li></ul></li></ul><p><a href="https://zhuanlan.zhihu.com/p/28489928">https://zhuanlan.zhihu.com/p/28489928</a></p><h3 id="b-4-3-群组渲染（Clustered-Rendering）"><a href="#b-4-3-群组渲染（Clustered-Rendering）" class="headerlink" title="b.4.3). 群组渲染（Clustered Rendering）"></a>b.4.3). 群组渲染（Clustered Rendering）</h3><ul><li>带宽相对减少，多光源下效率提升</li><li>分为forward和deferred两种</li><li>详细补充拓展：<a href="https://zhuanlan.zhihu.com/p/54694743">https://zhuanlan.zhihu.com/p/54694743</a></li></ul><h2 id="c-渲染管线的优化（移动端）"><a href="#c-渲染管线的优化（移动端）" class="headerlink" title="c). 渲染管线的优化（移动端）"></a>c). 渲染管线的优化（移动端）</h2><p>IMR框架渲染对于移动端有一个很大的问题：<strong>带宽占用过高</strong>。</p><ul><li>因此在移动端，我们不采用<strong>PC端构架IMR（Immediate Mode Rendering）</strong>，而采用<strong>移动端构架TBR（Tile-Based Rendering）或TBDR（PowerVR使用）</strong></li></ul><p>简而言之，为了节省成本，移动端TBR的GPU中不使用显存（GPU Memory），而使用<strong>On_Chip Memory也就是SRAM，或者L1 L2 cache</strong><img src="/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/GPU架构.jpg" alt="GPU架构"></p><p>对于TBR来讲，整个光栅化和像素处理会被分为一个个Tile进行处理，通常为16×16大小的Tile。TBR的结构通过On-Chip Buffers来储存Tiling后的Depth Buffer和Color buffer。</p><p>也就是原先IMR架构中对主存中Color/Depth Buffer进行的读写操作变成直接在GPU中的高速内存操作，减少了最影响性能的系统内存传输的开销。通过下面这张图能够更好的来理解，下图的DRAM在手机上就是物理内存那一块。</p><p><img src="/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/On-chip.jpg" alt="On-chip"></p><p>​    </p><h2 id="d-移动设备渲染通用优化建议"><a href="#d-移动设备渲染通用优化建议" class="headerlink" title="d). 移动设备渲染通用优化建议"></a>d). 移动设备渲染通用优化建议</h2><ul><li><strong>贴图格式能压缩就压缩</strong>。贴图内存越小，片上命中率就越高，总的传输量也少</li><li><strong>能开mipmap就开mipmap</strong>（前提是能用到，UI贴图就不用开了）。减轻带宽压力，与减小实际使用的贴图内存是一个道理，但是会增加总贴图的内存占用大小，需要在内存开销和带宽开销上做一个平衡。</li><li><strong>随机纹理寻址相对于相邻纹理寻址有显著开销</strong>。提高片上命中率。</li><li><strong>3DTexture Sampling有显著的开销</strong>。3DTexture整体内存占用大，垂直方向相邻像素内存不相邻很容易cache miss，这是我个人推测。</li><li><strong>Trilinear/Anisotropic相对于Bilinear有显著的开销</strong>。Trilinear其实就相当于tex3D了(此结论不负责任)，Bilinear相对于Point几乎没有额外开销（此结论负责任，texture fetch都是一次拿相邻的四个出来），所以Bilinear能忍就尽量凑合用着吧。</li><li><strong>使用LUT（look up texture）很可能是负优化</strong>。需要对比权衡带宽占用+texture fetch操作增加与ALU占用增加降低并行效率，另外还很可能涉及到美术工作流和最终效果，所以是个不是很好进行操作的优化。之前看过腾讯的技术分享将引擎中Tonemapping那步的3DLUT（UE4和Unity都是这样的）替换为函数拟合的优化，理论上应该是会提升不少性能，但是要想真正应用到生产环境，保证效果，还要做好拟合工具链，是得费不少力气的</li><li><strong>通道图能合并就合并，减少Shader中贴图采样次数</strong>。这个不多说了</li><li><strong>控制Framebuffer大小</strong>。这个也不多说了</li><li><strong>总顶点数量也是带宽开销的影响因素</strong>。虽然以现在GPU的计算能力来说，顶点数增多产生的VS计算开销增加通常是忽略不计的。但是仍不能忽略总顶点数量对于VertexBuffer所消耗带宽的影响，对于总顶点数的限制应该更多的从带宽消耗上去进行测试和分析。</li></ul><h3 id="d-1-AlphaTest性能消耗"><a href="#d-1-AlphaTest性能消耗" class="headerlink" title="d.1). AlphaTest性能消耗"></a>d.1). AlphaTest性能消耗</h3><ul><li>只要Shader中包含discard指令的都会被GPU认为是AlphaTest图元（GPU对于AlphaTest绘制流程的判定是基于图元而不是像素）</li><li><strong>无论是PowerVR还是Mali/Adreno芯片，AlphaTest图元的绘制都会影响整体渲染性能。</strong></li><li><strong>随着芯片的发展AlphaTest图元对于渲染性能的影响主要在于Overdraw增加而非降低硬件设计流程效率，其优化思路与AlphaBlend一样，就是少画！</strong></li><li>严格按照Opaque - AlphaTest - AlphaBlend的顺序进行渲染可以最大化减小AlphaTest对于渲染性能的影响。</li><li><strong>将Opaque, AlphaTest与AlphaBlend打乱顺序渲染会极大的降低渲染性能，任何情况下都不应该这么做。</strong></li><li>不要尝试使用AlphaTest替代AlphaBlend，这并不会产生太多优化。</li><li>不要尝试使用AlphaTest替代Opaque，这会产生负优化</li><li><strong>不要尝试使用AlphaBlend替代AlphaTest</strong>，这会造成错误的渲染结果。</li><li>在保证正确渲染顺序情况下，AlphaTest与AlphaBlend开销相似，不存在任何替代优化关系</li><li>增加少量顶点以减少AlphaTest图元的绘制面积是可以提升一些渲染性能的。</li><li>首先统一绘制AlphaTest图元的DepthPrepass，再以ZTest Equal和不含discard指令的Shader统一绘制AlphaTest图元，大多数情况下是可以显著提升总体渲染性能的（需要实际测试）</li></ul><h2 id="资料补充："><a href="#资料补充：" class="headerlink" title="资料补充："></a>资料补充：</h2><p><a href="https://zhuanlan.zhihu.com/p/259760974">https://zhuanlan.zhihu.com/p/259760974</a></p><p><a href="https://www.cnblogs.com/timlly/p/11471507.html">https://www.cnblogs.com/timlly/p/11471507.html</a></p><p><a href="https://zhuanlan.zhihu.com/p/112120206">https://zhuanlan.zhihu.com/p/112120206</a></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;a-渲染路径&quot;&gt;&lt;a href=&quot;#a-渲染路径&quot; class=&quot;headerlink&quot; title=&quot;a). 渲染路径&quot;&gt;&lt;/a&gt;a). 渲染路径&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;决定光照的实现方式。简言之，就是当前渲染目标使用&lt;strong&gt;&lt;font color=&quot;red&quot;&gt;光照的流程&lt;/font&gt;&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;b-渲染方式&quot;&gt;&lt;a href=&quot;#b-渲染方式&quot; class=&quot;headerlink&quot; title=&quot;b). 渲染方式&quot;&gt;&lt;/a&gt;b). 渲染方式&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;延迟渲染&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;前向渲染&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/Difference.png&quot; alt=&quot;Difference&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以看到前向渲染中，中间蓝色的灯并没被渲染。（场景8盏灯，Project Setting中Pixel Light Count设为7）&lt;/p&gt;
&lt;h2 id=&quot;b-1-前向-正向渲染-Forward-Rendering&quot;&gt;&lt;a href=&quot;#b-1-前向-正向渲染-Forward-Rendering&quot; class=&quot;headerlink&quot; title=&quot;b.1). 前向/正向渲染-Forward Rendering&quot;&gt;&lt;/a&gt;b.1). 前向/正向渲染-Forward Rendering&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;简介：每个Object对每个光照都计算；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;b-1-1-流程&quot;&gt;&lt;a href=&quot;#b-1-1-流程&quot; class=&quot;headerlink&quot; title=&quot;b.1.1). 流程&quot;&gt;&lt;/a&gt;b.1.1). 流程&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/Forward_Workflow.png&quot; alt=&quot;Forward_Workflow&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;简单来说就是不管光源的影响大不大，计算的时候都会把所有光源计算进去，这样就会造成一个很大的浪费&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;b-1-2-规则和注意事项&quot;&gt;&lt;a href=&quot;#b-1-2-规则和注意事项&quot; class=&quot;headerlink&quot; title=&quot;b.1.2). 规则和注意事项&quot;&gt;&lt;/a&gt;b.1.2). 规则和注意事项&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;发生在顶点处理阶段，会计算所有顶点的光照&lt;/strong&gt;。全平台支持&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;ul&gt;
&lt;li&gt;规则1：最亮的几个光源会被实现为像素光照&lt;/li&gt;
&lt;li&gt;规则2：然后就是，最多四个光源会被实现为顶点光照&lt;/li&gt;
&lt;li&gt;规则3：剩下的光源会实现为效率较高的球面调谐光照（Spherical Hamanic），这是一种模拟光照&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;补充说明&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;ul&gt;
&lt;li&gt;最亮的那盏光一定是像素光照&lt;/li&gt;
&lt;li&gt;Light的Render Mode是important的光一定是像素光照&lt;/li&gt;
&lt;li&gt;如果前面的两条加起来的像素光照小于Quality Setting里的Pixel Light Count（最大像素光照数量），那么从剩下的光源中找出最亮的那几盏光源，实现为像素光照。&lt;/li&gt;
&lt;li&gt;最后剩下的光源，按照规则2或3。&lt;/li&gt;
&lt;li&gt;在base pass里执行一盏像素光、所有的顶点光和球面调谐光照，并且进行阴影计算。&lt;/li&gt;
&lt;li&gt;其余的像素光每盏一个Additional Pass，并且这些pass里没有阴影计算。&lt;/li&gt;
&lt;li&gt;场景中看到的阴影，全是base pass里计算出最亮那盏像素光的阴影，其他像素光是不计算阴影的。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;最多的光源数是可以更改的&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;以Unity中的为例，在project setting中&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/UnityForwardSetting.png&quot; alt=&quot;UnityForwardSetting&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;b-2-延迟渲染（Deferred-Rendering）&quot;&gt;&lt;a href=&quot;#b-2-延迟渲染（Deferred-Rendering）&quot; class=&quot;headerlink&quot; title=&quot;b.2). 延迟渲染（Deferred Rendering）&quot;&gt;&lt;/a&gt;b.2). 延迟渲染（Deferred Rendering）&lt;/h2&gt;&lt;h3 id=&quot;b-2-1-简介&quot;&gt;&lt;a href=&quot;#b-2-1-简介&quot; class=&quot;headerlink&quot; title=&quot;b.2.1). 简介&quot;&gt;&lt;/a&gt;b.2.1). 简介&lt;/h3&gt;&lt;p&gt;主要解决&lt;strong&gt;大量光照渲染&lt;/strong&gt;的方案。&lt;/p&gt;
&lt;p&gt;可以将延迟渲染(Deferred Rendering)理解为先将所有物体都先绘制到屏幕空间的缓冲（即&lt;strong&gt;G-buffer&lt;/strong&gt;，Geometric Buffer，几何缓冲区）中，再逐光源对该缓冲进行着色的过程，从而避免了因计算被深度测试丢弃的片元的着色而产生的不必要的开销。也就是说延迟渲染&lt;strong&gt;基本思想&lt;/strong&gt;是，&lt;strong&gt;先执行深度测试（应该也包括其他测试），再进行着色计算&lt;/strong&gt;，将本来在物空间（三维空间）进行光照计算放到了&lt;strong&gt;像空间&lt;/strong&gt;（二维空间）进行处理。&lt;/p&gt;
&lt;p&gt;对应于正向渲染O(m*n)的 复杂度，经典的延迟渲染复杂度为O(n+m)。&lt;/p&gt;</summary>
    
    
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    <category term="延迟渲染" scheme="https://whitetail-o.github.io/tags/%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93/"/>
    
    <category term="渲染管线" scheme="https://whitetail-o.github.io/tags/%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/"/>
    
  </entry>
  
  <entry>
    <title>HPP_Graphics_3.5 Early-Z和Z Prepass（Pre-Z）</title>
    <link href="https://whitetail-o.github.io/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/"/>
    <id>https://whitetail-o.github.io/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/</id>
    <published>2023-02-15T10:40:32.000Z</published>
    <updated>2023-03-17T05:10:35.950Z</updated>
    
    <content type="html"><![CDATA[<h1 id="a-Review-Z-test"><a href="#a-Review-Z-test" class="headerlink" title="a). Review Z-test"></a>a). Review Z-test</h1><ul><li>先回顾下深度测试</li></ul><p><img src="/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/ZTest_Workflow.png" alt="ZTest_Workflow" style="zoom:50%;"></p><ul><li><p><strong>问题：</strong> 被遮挡的物体也会进行shading，造成overdraw；</p><p><img src="/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/Overdraw.png" alt="Overdraw"></p><ul><li><strong>解决思路：</strong> 在shading前提前剔除被遮挡的片元；</li></ul></li></ul><h1 id="b-Early-Z"><a href="#b-Early-Z" class="headerlink" title="b). Early-Z"></a>b). Early-Z</h1><p><img src="/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/Early-Z.png" alt="Early-Z"></p><ul><li>是在传统管线中的光栅化阶段之后、片元着色器之前加的一步操作。<ul><li>提前的深度测试叫作<strong>Z-Cull</strong></li><li>后续的深度测试为了确定正确的遮挡关系，叫作<strong>Z-Check</strong></li></ul></li><li><em>Early-Z同样可以搭配使用模板测试</em></li></ul><h2 id="b-1-Early-Z失效情况"><a href="#b-1-Early-Z失效情况" class="headerlink" title="b.1). Early-Z失效情况"></a>b.1). Early-Z失效情况</h2><ol><li>开启<strong>Alpha Test</strong>或 clip/discard等手动丢弃片元操作<ul><li>通常Early-Z不仅会进行深度测试，还要进行深度写入</li><li>那在这种情况下，如果经过AlphaTest，前面渲染的片元被丢弃了（但写入了深度），那么后续的像素都将无法正常渲染。</li></ul></li><li>手动修改GPU插值得到的深度</li><li>开启<strong>Alpha Blend</strong></li><li>关闭深度测试Depth Test</li></ol><h2 id="b-2-Early-Z排序"><a href="#b-2-Early-Z排序" class="headerlink" title="b.2). Early-Z排序"></a>b.2). Early-Z排序</h2><h3 id="不透明物体由远往近渲染，early-z将没有任何优化效果"><a href="#不透明物体由远往近渲染，early-z将没有任何优化效果" class="headerlink" title="不透明物体由远往近渲染，early-z将没有任何优化效果"></a>不透明物体由远往近渲染，early-z将没有任何优化效果</h3><ul><li>在渲染前，将不透明物体<strong>从近往远渲染</strong>的话，Early-Z能发挥最大的性能优化（注意此处还是前向渲染的思路）</li><li><p>具体怎么排序？ </p><ul><li>可以让CPU将物体按照由近到远的顺序排好，再交付给GPU进行渲染</li></ul></li><li><p>问题：</p><ul><li>复杂的场景，CPU性能消耗很大</li><li>严格按照由近到远的顺序渲染，将不能同时搭配批处理优化手段。</li></ul></li><li><p><strong>解决方法：Pre-Z / Z Prepass</strong></p></li></ul><span id="more"></span><h1 id="c-Pre-Z"><a href="#c-Pre-Z" class="headerlink" title="c). Pre-Z"></a>c). Pre-Z</h1><ul><li>用于解决使用early-Z可能造成的Overdraw问题（用Drawcall或Set Pass Call的消耗换取减少Overdraw，因此使用时需要进行权衡）</li></ul><h2 id="Method1-双Pass"><a href="#Method1-双Pass" class="headerlink" title="Method1: 双Pass"></a>Method1: 双Pass</h2><p>使用两个Pass：</p><ul><li><p>第一个Pass（<strong>Z-Prepass</strong>）：仅写入深度；</p></li><li><p>第二个Pass：关闭深度写入，并将深度测试比较符改为等于；</p><p><img src="/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/D-pass_shader.png" alt="D-pass_shader" style="zoom: 33%;"></p></li></ul><p>造成问题：</p><ol><li><p>在Unity中，无法动态批处理（多Pass的Shader无法进行动态批处理）</p></li><li><p>增多DrawCall；</p><p><img src="/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/Z_Pre_Drawcall.png" alt="Z_Pre_Drawcall" style="zoom: 33%;"></p></li></ol><p>因此，我们可以提前分离Prepass，以便其可以<a href="https://blog.csdn.net/lsjsoft/article/details/90734932">进行动态批处理，减少Set pass call</a></p><h2 id="Method2-提前分离的Prepass"><a href="#Method2-提前分离的Prepass" class="headerlink" title="Method2: 提前分离的Prepass"></a>Method2: 提前分离的Prepass</h2><ul><li>将Z-Prepass分离出一个shader，用这个shader将场景中不透明物体先渲染一遍；</li><li>而原先材质只剩下原先的第二个Pass，仍然关闭深度写入，并且将深度比较函数设置为相等。</li></ul><blockquote><p>URP以后并不是所有Pass都会执行，因为它预制了两个Pass所以，优先执行”UniversalForward”在执行”SrpDefaultUnlit”的Pass</p><p>……</p><p><img src="/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/RendererFeature.png" alt="RendererFeature" style="zoom:33%;"></p><p>Link: <a href="https://www.xuanyusong.com/archives/4759">https://www.xuanyusong.com/archives/4759</a></p></blockquote><hr><h2 id="半透明渲染"><a href="#半透明渲染" class="headerlink" title="半透明渲染"></a>半透明渲染</h2><p>Pre-Z也是半透明物体渲染的解决方案；</p><p><img src="/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/PreZ_Translution.png" alt="PreZ_Translution"></p><h2 id="Z-prepass的其他问题"><a href="#Z-prepass的其他问题" class="headerlink" title="Z-prepass的其他问题"></a>Z-prepass的其他问题</h2><h3 id="1-Z-prepass的性能消耗是否能被忽视"><a href="#1-Z-prepass的性能消耗是否能被忽视" class="headerlink" title="1.Z-prepass的性能消耗是否能被忽视"></a>1.Z-prepass的性能消耗是否能被忽视</h3><ul><li><p>国外论坛一位名为lipsryme的老哥做了一项实验：</p></li><li><ul><li><img src="https://cdn.nlark.com/yuque/0/2021/png/12962324/1626442429385-0bab8f18-7ba4-44cb-96b5-4f123055a263.png" alt="img"></li><li>可以看到，Z-prepass的消耗为2.0ms，而带来的优化只减少了0.3ms（2.7-2.4）</li><li>后续讨论中，发现Z-prepass是需要根据项目的实际情况来决定是否采用的。</li></ul></li><li><p><strong>总结有以下建议</strong></p></li><li><ul><li>当一个有非常多OverDraw的场景，且不能很好的将不透明物体从前往后进行排序时，可以考虑使用PreZ进行优化</li><li>注意，PreZ会增加DrawCall，如果用错了可能是负优化</li></ul></li></ul><h1 id="d-Early-Z-和-Z-Prepass的实例应用"><a href="#d-Early-Z-和-Z-Prepass的实例应用" class="headerlink" title="d). Early-Z 和 Z-Prepass的实例应用"></a>d). <strong>Early-Z</strong> <strong>和</strong> Z-Prepass的实例应用</h1><h2 id="d-1-面片叠加的头发渲染"><a href="#d-1-面片叠加的头发渲染" class="headerlink" title="d.1). 面片叠加的头发渲染"></a>d.1). 面片叠加的头发渲染</h2><ul><li><p>对于半透明的面片来说，需要从后往前进行排序渲染才能得到正确的透明度混合结果</p><p><img src="/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/Hair_PreZ00.png" alt="Hair_PreZ00"></p></li></ul><hr><ul><li><p><strong>排序后头发的渲染</strong></p><p><img src="/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/Hair_PreZ01.png" alt="Hair_PreZ01"></p></li><li><p>分为3个pass</p><ul><li><p>pass1</p><ul><li>处理不透明部分，开启Alpha test透明度测试，仅通过不透明的像素，</li><li>关闭背面剔除</li><li>开启深度写入</li></ul></li><li><p>pass2</p><ul><li>剔除正面，渲染背面</li></ul></li><li>pass3<ul><li>剔除背面，渲染正面</li></ul></li></ul></li></ul><ul><li>问题：会带来非常多<strong>OverDraw</strong>的问题<ul><li>解决方法：Pre-Z</li></ul></li></ul><hr><p><img src="/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/Hair_PreZ02.png" alt="Hair_PreZ02"></p><ul><li>使用Early-Z剔除</li><li>透明度测试开启时Early-Z无法使用的解决方案：使用Z-Prepass  <ul><li>使用一个简单的shader进行Alpha Test生成Z-Buffer</li></ul></li></ul><hr><p><strong>改善后的渲染方案：</strong></p><p><img src="/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/Hair_PreZ03.png" alt="Hair_PreZ03"></p><ul><li><strong>不透明物体</strong><ol><li><strong>Pass1 - PreZ</strong>：<ul><li>开启透明度测试</li><li>关闭背面剔除</li><li>开启深度写入，深度测试设置为Less</li><li>关闭颜色缓冲区写入</li><li>用于一个简单的片元着色器来返回透明度值</li></ul></li><li><strong>Pass2：</strong><ul><li>关闭背面剔除</li><li>关闭深度写入，深度测试设置为Equal</li></ul></li></ol></li><li><strong>半透明物体</strong><ol><li><strong>Pass3：</strong><ul><li>剔除正面</li><li>关闭深度写入，对背面进行深度测试，设置为Less</li></ul></li><li><strong>Pass4：</strong><ul><li>剔除背面</li><li>关闭深度写入，对正面进行深度测试，设置为Less</li></ul></li></ol></li></ul><hr><p><a href="https://www.cnblogs.com/ghl_carmack/p/10166291.html">https://www.cnblogs.com/ghl_carmack/p/10166291.html</a></p><h1 id="Homework"><a href="#Homework" class="headerlink" title="Homework"></a>Homework</h1><p><img src="/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/Homework.gif" alt="Homework"></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;a-Review-Z-test&quot;&gt;&lt;a href=&quot;#a-Review-Z-test&quot; class=&quot;headerlink&quot; title=&quot;a). Review Z-test&quot;&gt;&lt;/a&gt;a). Review Z-test&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;先回顾下深度测试&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/ZTest_Workflow.png&quot; alt=&quot;ZTest_Workflow&quot; style=&quot;zoom:50%;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;问题：&lt;/strong&gt; 被遮挡的物体也会进行shading，造成overdraw；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/Overdraw.png&quot; alt=&quot;Overdraw&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;解决思路：&lt;/strong&gt; 在shading前提前剔除被遮挡的片元；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;b-Early-Z&quot;&gt;&lt;a href=&quot;#b-Early-Z&quot; class=&quot;headerlink&quot; title=&quot;b). Early-Z&quot;&gt;&lt;/a&gt;b). Early-Z&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/Early-Z.png&quot; alt=&quot;Early-Z&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;是在传统管线中的光栅化阶段之后、片元着色器之前加的一步操作。&lt;ul&gt;
&lt;li&gt;提前的深度测试叫作&lt;strong&gt;Z-Cull&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;后续的深度测试为了确定正确的遮挡关系，叫作&lt;strong&gt;Z-Check&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Early-Z同样可以搭配使用模板测试&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;b-1-Early-Z失效情况&quot;&gt;&lt;a href=&quot;#b-1-Early-Z失效情况&quot; class=&quot;headerlink&quot; title=&quot;b.1). Early-Z失效情况&quot;&gt;&lt;/a&gt;b.1). Early-Z失效情况&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;开启&lt;strong&gt;Alpha Test&lt;/strong&gt;或 clip/discard等手动丢弃片元操作&lt;ul&gt;
&lt;li&gt;通常Early-Z不仅会进行深度测试，还要进行深度写入&lt;/li&gt;
&lt;li&gt;那在这种情况下，如果经过AlphaTest，前面渲染的片元被丢弃了（但写入了深度），那么后续的像素都将无法正常渲染。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;手动修改GPU插值得到的深度&lt;/li&gt;
&lt;li&gt;开启&lt;strong&gt;Alpha Blend&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;关闭深度测试Depth Test&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;b-2-Early-Z排序&quot;&gt;&lt;a href=&quot;#b-2-Early-Z排序&quot; class=&quot;headerlink&quot; title=&quot;b.2). Early-Z排序&quot;&gt;&lt;/a&gt;b.2). Early-Z排序&lt;/h2&gt;&lt;h3 id=&quot;不透明物体由远往近渲染，early-z将没有任何优化效果&quot;&gt;&lt;a href=&quot;#不透明物体由远往近渲染，early-z将没有任何优化效果&quot; class=&quot;headerlink&quot; title=&quot;不透明物体由远往近渲染，early-z将没有任何优化效果&quot;&gt;&lt;/a&gt;不透明物体由远往近渲染，early-z将没有任何优化效果&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;在渲染前，将不透明物体&lt;strong&gt;从近往远渲染&lt;/strong&gt;的话，Early-Z能发挥最大的性能优化（注意此处还是前向渲染的思路）&lt;/li&gt;
&lt;li&gt;&lt;p&gt;具体怎么排序？ &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可以让CPU将物体按照由近到远的顺序排好，再交付给GPU进行渲染&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;复杂的场景，CPU性能消耗很大&lt;/li&gt;
&lt;li&gt;严格按照由近到远的顺序渲染，将不能同时搭配批处理优化手段。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;解决方法：Pre-Z / Z Prepass&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    <category term="延迟渲染" scheme="https://whitetail-o.github.io/tags/%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93/"/>
    
    <category term="渲染管线" scheme="https://whitetail-o.github.io/tags/%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/"/>
    
  </entry>
  
  <entry>
    <title>HPP_Graphics_2.7 模板测试和深度测试</title>
    <link href="https://whitetail-o.github.io/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/"/>
    <id>https://whitetail-o.github.io/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/</id>
    <published>2023-02-15T09:40:32.000Z</published>
    <updated>2023-03-17T05:16:04.931Z</updated>
    
    <content type="html"><![CDATA[<h2 id="a-模板测试"><a href="#a-模板测试" class="headerlink" title="a). 模板测试"></a>a). 模板测试</h2><ul><li>处于<strong>逐片元操作</strong>中</li></ul><p><img src="/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/模板测试00.png" alt="模板测试00"></p><p><img src="/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/模板测试01.png" alt="模板测试01"></p><p><img src="/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/模板测试02.png" alt="模板测试02"></p><h3 id="a-1-Unity-中的模板测试"><a href="#a-1-Unity-中的模板测试" class="headerlink" title="a.1). Unity 中的模板测试"></a>a.1). Unity 中的模板测试</h3><ul><li><p>语法表示</p><p><img src="/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/Unity_stencil.png" alt="Unity_stencil"></p><p><img src="/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/Unity_stencil_Comparison.png" alt="Unity_stencil_Comparison"></p><p><img src="/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/Unity_stencil_Update.png" alt="Unity_stencil_Update"></p></li></ul><ul><li><p>可作为遮罩等操作</p><p><img src="/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/StencilBufferValue.png" alt="StencilBufferValue"></p></li></ul><span id="more"></span><h3 id="a-2-作业：Unity中实现的效果"><a href="#a-2-作业：Unity中实现的效果" class="headerlink" title="a.2). 作业：Unity中实现的效果"></a>a.2). 作业：Unity中实现的效果</h3><p><img src="/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/StencilTest_Unity.png" alt="StencilTest_Unity"></p><hr><p><strong>【链接补充】</strong></p><p>[1]. <a href="https://blog.csdn.net/u011047171/article/details/46928463">https://blog.csdn.net/u011047171/article/details/46928463</a></p><p>[2]. <a href="https://blog.csdn.net/liu_if_else/article/details/86316361">https://blog.csdn.net/liu_if_else/article/details/86316361</a></p><p>[3]. <a href="https://gameinstitute.qq.com/community/detail/127404">https://gameinstitute.qq.com/community/detail/127404</a></p><p>[4]. <a href="https://learnopengl-cn.readthedocs.io/zh/latest/04 Advanced OpenGL/02 Stencil testing/">https://learnopenglcn.readthedocs.io/zh/latest/04%20Advanced%20OpenGL/02%20Stencil%20testing/</a></p><p>[5]. <a href="https://www.patreon.com/posts/14832618">https://www.patreon.com/posts/14832618</a></p><p>[6]. <a href="https://www.udemy.com/course/unity-shaders/">https://www.udemy.com/course/unity-shaders/</a></p><h2 id="b-深度测试"><a href="#b-深度测试" class="headerlink" title="b). 深度测试"></a>b). 深度测试</h2><p><img src="/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/ZTest.png" alt="ZTest"></p><ul><li>模板测试后，透明度混合前</li></ul><h3 id="Z-Buffer"><a href="#Z-Buffer" class="headerlink" title="Z-Buffer"></a>Z-Buffer</h3><p><img src="/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/Z_Buffer.png" alt="Z_Buffer"></p><h3 id="Z-Write"><a href="#Z-Write" class="headerlink" title="Z Write"></a>Z Write</h3><p>深度写入包括<strong>两种状态：ZWrite On 与 ZWrite Off</strong></p><p>当我们<strong>开启深度写入</strong>的时候，物体被渲染时针对物体在屏幕（更准确地说是frame buffer）上<strong>每个像素的深度都写入到深度缓冲区</strong>；反之，如果是<strong>ZWrite Off,</strong>那么物体的深度就<strong>不会写入深度缓冲区</strong>。但是，物体是否会写入深度，除了ZWrite这个状态之外，<strong>更重要的是需要深度测试通过</strong>，也就是ZTest通过，如果ZTest都没通过，那么也就不会写入深度了。</p><p>ZTest分为通过和不通过两种情况，ZWrite分为开启和关闭两种情况的四种情况：</p><ul><li>深度测试通过，深度写入开启：写入深度缓冲区，写入颜色缓冲区。</li><li>深度测试通过，深度写入关闭：不写深度缓冲区，写入颜色缓冲区。</li><li>深度测试失败，深度写入开启：不写深度缓冲区，不写颜色缓冲区。</li><li>深度测试失败，深度写入关闭：不写深度缓冲区，不屑颜色缓冲区。</li></ul><h3 id="Z-Test比较操作"><a href="#Z-Test比较操作" class="headerlink" title="Z Test比较操作"></a>Z Test比较操作</h3><p><img src="/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/Z_Comp.png" alt="Z_Comp"></p><h3 id="渲染队列"><a href="#渲染队列" class="headerlink" title="渲染队列"></a>渲染队列</h3><p>Unity中内置的几种渲染队列，按照渲染顺序，从先到后进行排序，<strong>队列数越小，越先渲染，队列数越大，越后渲染。</strong></p><ul><li><strong>Background(1000) ：</strong>最早被渲染的物体的队列。</li><li><strong>Geometry(2000) ：</strong>不透明物体的渲染队列。大多数物体都应该使用该队列进行渲染，也是Unity Shader中默认的渲染队列。</li><li><strong>AlphaTest(2450) ：</strong>有透明通道，需要进行Alpha Test的物体的队列，比在Geometry中更有效。</li><li><strong>Transparent(3000) ：</strong> 半透物体的渲染队列。一般是不写深度的物体，Alpha Blend等的在该队列渲染。</li><li><strong>Overlay(4000) ：</strong>最后被渲染的物体的队列，一般是覆盖效果，比如镜头光晕，屏幕贴片之类的。</li></ul><h3 id="Unity中设置渲染队列"><a href="#Unity中设置渲染队列" class="headerlink" title="Unity中设置渲染队列"></a>Unity中设置渲染队列</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//默认是Geometry</span></span><br><span class="line">Tags&#123;</span><br><span class="line"><span class="string">&quot;Queue&quot;</span> = <span class="string">&quot;Transparent&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>不透明物体的渲染顺序：从前往后。</strong></li><li><strong>透明物体的渲染顺序：从后往前。（OverDraw）</strong></li><li>对于使用了多个Pass的物体，其渲染队列会设置为Pass中的最小值（如两个Pass中一个是Geometry(2000)，另一个是Transparent(3000)，那该物体会按Geometry的队列渲染，然后按Shader中从上到下执行Pass）。</li></ul><h3 id="Early-Z"><a href="#Early-Z" class="headerlink" title="Early-Z"></a>Early-Z</h3><p>传统的渲染管线中，ZTest其实是在Blending阶段，这时候进行深度测试，所有对象的像素着色器都会计算一遍，没有什么性能提升，仅仅是为了得出正确的遮挡结果，会造成大量的无用计算，因为每个像素点上肯定重叠了很多计算。<strong>因此现代GPU中运用了Early-Z的技术，在Vertex阶段和Fragment阶段之间（光栅化之后，fragment之前）进行一次深度测试，如果深度测试失败，就不必进行fragment阶段的计算了，因此在性能上会有很大的提升。但是最终的ZTest仍然需要进行，以保证最终的遮挡关系结果正确。</strong>前面的一次主要是<strong><em>Z-Cull</em></strong>为了裁剪以达到优化的目的，后一次主要是<strong><em>Z-Check</em></strong>，为了检查，如下图：</p><p><img src="/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/EarlyZ.png" alt="EarlyZ"></p><h2 id="c-深度值"><a href="#c-深度值" class="headerlink" title="c). 深度值"></a>c). 深度值</h2><p><img src="/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/Deepth.png" alt="Deepth"></p><h3 id="为什么深度缓冲区存储非线性深度呢？"><a href="#为什么深度缓冲区存储非线性深度呢？" class="headerlink" title="为什么深度缓冲区存储非线性深度呢？"></a>为什么深度缓冲区存储非线性深度呢？</h3><p><strong>正确的投影特性的非线性深度方程是和1/z成正比的，</strong>这样基本上做的是在<strong>Z很近的时候是高精度和Z很远的时候是底精度</strong>。这样就是模拟了人眼观察，<strong>近处的物体很清晰，而远处的物体很模糊。</strong>（和现在还用伽马校正的原因类似）</p><script type="math/tex; mode=display">F d e p t h=\frac{1 / z-1 / \text { near }}{1 / \text { far }-1 / \text { near }}</script><h3 id="Z-fighting"><a href="#Z-fighting" class="headerlink" title="Z-fighting"></a>Z-fighting</h3><p>两个平面或三角形很<strong>紧密相互平行，深度缓冲区不具有足够的精度</strong>以至于无法得到哪一个靠前。导致了着两个形状<strong>不断切换顺序出现怪异问题</strong>。这被称为<strong>深度冲突（Z-fighting）</strong>，因为它看上去像形状争夺顶靠前的位置。（UE中重叠闪来闪去的那个）</p><ul><li><p>解决方法</p><ul><li><p>让物体之间不要离得太近。</p></li><li><p>尽可能把<strong>近平面</strong>设置得远一些。</p></li><li><p>放弃一部分性能来获得更高精度的深度值。</p></li><li>Z-Offset</li></ul></li></ul><p><img src="/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/Z_F.png" alt="Z_F"></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;a-模板测试&quot;&gt;&lt;a href=&quot;#a-模板测试&quot; class=&quot;headerlink&quot; title=&quot;a). 模板测试&quot;&gt;&lt;/a&gt;a). 模板测试&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;处于&lt;strong&gt;逐片元操作&lt;/strong&gt;中&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/模板测试00.png&quot; alt=&quot;模板测试00&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/模板测试01.png&quot; alt=&quot;模板测试01&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/模板测试02.png&quot; alt=&quot;模板测试02&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;a-1-Unity-中的模板测试&quot;&gt;&lt;a href=&quot;#a-1-Unity-中的模板测试&quot; class=&quot;headerlink&quot; title=&quot;a.1). Unity 中的模板测试&quot;&gt;&lt;/a&gt;a.1). Unity 中的模板测试&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;语法表示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/Unity_stencil.png&quot; alt=&quot;Unity_stencil&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/Unity_stencil_Comparison.png&quot; alt=&quot;Unity_stencil_Comparison&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/Unity_stencil_Update.png&quot; alt=&quot;Unity_stencil_Update&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;可作为遮罩等操作&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/StencilBufferValue.png&quot; alt=&quot;StencilBufferValue&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    
    <category term="图形学" scheme="https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    <category term="百人计划" scheme="https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"/>
    
    <category term="模板测试" scheme="https://whitetail-o.github.io/tags/%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95/"/>
    
    <category term="深度测试" scheme="https://whitetail-o.github.io/tags/%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
</feed>
