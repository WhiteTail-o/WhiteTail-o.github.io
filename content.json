{"meta":{"title":"WhiteTail's Blog","subtitle":"","description":"现已有Games101、Games202、百人计划等笔记，后续准备上传DX12、Unity的SRP等笔记。","author":"WhiteTail","url":"https://whitetail-o.github.io","root":"/"},"pages":[{"title":"书单","date":"2023-02-03T11:19:24.219Z","updated":"2023-02-03T11:19:24.219Z","comments":false,"path":"books/index.html","permalink":"https://whitetail-o.github.io/books/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2023-02-03T11:19:24.219Z","updated":"2023-02-03T11:19:24.219Z","comments":false,"path":"repository/index.html","permalink":"https://whitetail-o.github.io/repository/index.html","excerpt":"","text":""},{"title":"404 Not Found：该页无法显示","date":"2023-02-03T11:19:24.218Z","updated":"2023-02-03T11:19:24.218Z","comments":false,"path":"/404.html","permalink":"https://whitetail-o.github.io/404.html","excerpt":"","text":""},{"title":"关于","date":"2023-02-03T11:37:30.151Z","updated":"2023-02-03T11:37:30.151Z","comments":false,"path":"about/index.html","permalink":"https://whitetail-o.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"tags","date":"2023-02-01T05:38:13.000Z","updated":"2023-02-03T20:17:53.299Z","comments":true,"path":"tags/index.html","permalink":"https://whitetail-o.github.io/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2023-02-01T05:38:13.000Z","updated":"2023-02-03T20:13:53.110Z","comments":true,"path":"categories/index.html","permalink":"https://whitetail-o.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2023-02-03T17:19:06.751Z","updated":"2023-02-03T11:19:24.219Z","comments":true,"path":"links/index.html","permalink":"https://whitetail-o.github.io/links/index.html","excerpt":"","text":""}],"posts":[{"title":"目录","slug":"目录","date":"2023-03-26T17:17:18.635Z","updated":"2023-03-27T06:40:42.750Z","comments":true,"path":"2023/03/27/目录/","link":"","permalink":"https://whitetail-o.github.io/2023/03/27/%E7%9B%AE%E5%BD%95/","excerpt":"","text":"目前已有分类: Demo概述 | WhiteTail’s Blog (whitetail-o.github.io) 分类: Games101 | WhiteTail’s Blog (whitetail-o.github.io) 分类: Games202 | WhiteTail’s Blog (whitetail-o.github.io) 分类: 百人计划 | WhiteTail’s Blog (whitetail-o.github.io) 分类: 相机概述 | WhiteTail’s Blog (whitetail-o.github.io) 已完成未上传 通过Maya实现将平滑法线写入顶点色； 这里远比我原先想的要复杂，有几个点： 光滑组作用是改变顶点法线的算法，而不是将平滑法线写入顶点； 对于硬边（不同光滑组），通过顶点色去应该不可能完美解决外描边的接缝问题（？），因为对于硬边： 切线和副切线方向不一定和UV方向相同，很多时候切线和副切线甚至不在三角面片上； 对于未人为修改过的顶点法线，其方向等于面法线。而对于修改过后的法线（Maya中会显示黄色），其方向不再遵守面法线，而是固定为使用Macro Normal计算出的切线空间中的一个方向。 而切线和副切线是根据法线、UV进而计算出的正交化的向量。对于重合顶点，形变动画使得他们之间法线发生相对位移，造成的结果就是其切线空间很可能发生相对变换，使得原先还原到模型空间指向同一个方向的矢量变得不为一个方向； 使用SSSS(Separable SSS)实现SSS的SSSSS(Screen Space SSS) :D 战双帕弥什的角色渲染分析； 待完成 DX12龙书学习笔记； SRP整理；","categories":[{"name":"目录","slug":"目录","permalink":"https://whitetail-o.github.io/categories/%E7%9B%AE%E5%BD%95/"}],"tags":[]},{"title":"【转载】为不同的图形 API 编写着色器（Unity）","slug":"【转载】为不同的图形 API 编写着色器","date":"2023-03-18T12:24:32.000Z","updated":"2023-03-19T02:56:32.776Z","comments":true,"path":"2023/03/18/【转载】为不同的图形 API 编写着色器/","link":"","permalink":"https://whitetail-o.github.io/2023/03/18/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91%E4%B8%BA%E4%B8%8D%E5%90%8C%E7%9A%84%E5%9B%BE%E5%BD%A2%20API%20%E7%BC%96%E5%86%99%E7%9D%80%E8%89%B2%E5%99%A8/","excerpt":"之前刚想写一篇DX12和OpenGL在Unity Shader中的差异，没想到官网就写了…… 附上链接：为不同的图形 API 编写着色器 - Unity 手册 (unity3d.com) 以下正文 在某些情况下，不同图形 API 之间的图形渲染行为方式存在差异。大多数情况下，Unity 编辑器会隐藏这些差异，但在某些情况下，编辑器无法为您执行此操作。下面列出了这些情况以及发生这些情况时需要采取的操作。 渲染纹理坐标垂直纹理坐标约定在两种类型的平台之间有所不同，分别是 Direct3D 类和 OpenGL 类平台。 Direct3D 类：顶部坐标为 0 并向下增加。此类型适用于 Direct3D、Metal 和游戏主机。 OpenGL 类：底部坐标为 0 并向上增加。此类适用于 OpenGL 和 OpenGL ES。 除了渲染到渲染纹理的情况下，这种差异不会对您的项目产生任何影响。在 Direct3D 类平台上渲染到纹理时，Unity 会在内部上下翻转渲染。这样就会使坐标约定在平台之间匹配，并以 OpenGL 类平台约定作为标准。 在着色器中，有两种常见情况需要您采取操作确保不同的坐标约定不会在项目中产生问题，这两种情况就是图像效果和 UV 空间中的渲染。","text":"之前刚想写一篇DX12和OpenGL在Unity Shader中的差异，没想到官网就写了…… 附上链接：为不同的图形 API 编写着色器 - Unity 手册 (unity3d.com) 以下正文 在某些情况下，不同图形 API 之间的图形渲染行为方式存在差异。大多数情况下，Unity 编辑器会隐藏这些差异，但在某些情况下，编辑器无法为您执行此操作。下面列出了这些情况以及发生这些情况时需要采取的操作。 渲染纹理坐标垂直纹理坐标约定在两种类型的平台之间有所不同，分别是 Direct3D 类和 OpenGL 类平台。 Direct3D 类：顶部坐标为 0 并向下增加。此类型适用于 Direct3D、Metal 和游戏主机。 OpenGL 类：底部坐标为 0 并向上增加。此类适用于 OpenGL 和 OpenGL ES。 除了渲染到渲染纹理的情况下，这种差异不会对您的项目产生任何影响。在 Direct3D 类平台上渲染到纹理时，Unity 会在内部上下翻转渲染。这样就会使坐标约定在平台之间匹配，并以 OpenGL 类平台约定作为标准。 在着色器中，有两种常见情况需要您采取操作确保不同的坐标约定不会在项目中产生问题，这两种情况就是图像效果和 UV 空间中的渲染。 图像效果使用图像效果和抗锯齿时，系统不会翻转为图像效果生成的源纹理来匹配 OpenGL 类平台约定。在这种情况下，Unity 渲染到屏幕以获得抗锯齿效果，然后将渲染解析为渲染纹理，以便通过图像效果进行进一步处理。 如果您的图像效果是一次处理一个渲染纹理的简单图像效果，则 Graphics.Blit 会处理不一致的坐标。但是，如果您在图像效果中一起处理多个渲染纹理，则在 Direct3D 类平台中以及在您使用抗锯齿时，渲染纹理很可能以不同的垂直方向出现。要标准化坐标，必须在顶点着色器中手动上下“翻转”屏幕纹理，使其与 OpenGL 类坐标标准匹配。 以下代码示例演示了如何执行此操作： 12345678// 翻转纹理的采样：// 主纹理的// 纹理像素大小将具有负 Y。# if UNITY_UV_STARTS_AT_TOPif (_MainTex_TexelSize.y &lt; 0) uv.y = 1-uv.y;# endif GrabPass 也出现了类似的情况。生成的渲染纹理实际上可能不会在 Direct3D 类（非 OpenGL 类）平台上进行上下翻转。如果着色器代码对 GrabPass 纹理进行采样，请使用 UnityCG include 文件中的 ComputeGrabScreenPos 函数。 在 UV 空间中渲染在纹理坐标 (UV) 空间中渲染特殊效果或工具时，您可能需要调整着色器，以便在 Direct3D 类和 OpenGL 类系统之间进行一致渲染。您还可能需要在渲染到屏幕和渲染到纹理之间进行渲染调整。为进行此类调整，应上下翻转 Direct3D 类投影，使其坐标与 OpenGL 类投影坐标相匹配。 内置变量 ProjectionParams.x 包含值 +1 或 –1。-1 表示投影已上下翻转以匹配 OpenGL 类投影坐标，而 +1 表示尚未翻转。 您可以在着色器中检查此值，然后执行不同的操作。下面的示例将检查是否已翻转投影，如果已翻转，则再次进行翻转，然后返回 UV 坐标以便匹配。 123456789101112float4 vert(float2 uv : TEXCOORD0) : SV_POSITION&#123; float4 pos; pos.xy = uv; // 此示例使用上下翻转的投影进行渲染， // 因此也翻转垂直 UV 坐标 if (_ProjectionParams.x &lt; 0) pos.y = 1 - pos.y; pos.z = 0; pos.w = 1; return pos;&#125; 裁剪空间坐标与纹理坐标类似，裁剪空间坐标（也称为投影后空间坐标）在 Direct3D 类和 OpenGL 类平台之间有所不同： Direct3D 类：裁剪空间深度从近平面的 +1.0 到远平面的 0.0。此类型适用于 Direct3D、Metal 和游戏主机。 OpenGL 类：裁剪空间深度从近平面的 –1.0 到远平面的 +1.0。此类适用于 OpenGL 和 OpenGL ES。 在着色器代码内，可使用内置宏 UNITY_NEAR_CLIP_VALUE 来获取基于平台的近平面值。 在脚本代码内，使用 GL.GetGPUProjectionMatrix 将 Unity 的坐标系（遵循 OpenGL 类约定）转换为 Direct3D 类坐标（如果这是平台所期望的）。 着色器计算的精度要避免精度问题，请确保在目标平台上测试着色器。移动设备和 PC 中的 GPU 在处理浮点类型方面有所不同。PC GPU 将所有浮点类型（浮点精度、半精度和固定精度）视为相同；PC GPU 使用完整 32 位精度进行所有计算，而许多移动设备 GPU 并不是这样做。 有关详细信息，请参阅数据类型和精度的文档。 着色器中的 const 声明const 的使用在 Microsoft HSL（请参阅 msdn.microsoft.com）和 OpenGL 的 GLSL（请参阅 Wikipedia）着色器语言之间有所不同。 Microsoft 的 HLSL const 与 C# 和 C++ 中的含义大致相同：声明的变量在其作用域内是只读的，但可按任何方式初始化。 OpenGL 的 GLSL const 表示变量实际上是编译时常量，因此必须使用编译时约束（文字值或其他对于 const 的计算）进行初始化。 最好是遵循 OpenGL 的 GLSL 语义，并且只有当变量真正不变时才将变量声明为 const。避免使用其他一些可变值初始化 const 变量（例如，作为函数中的局部变量）。这一原则也适用于 Microsoft 的 HLSL，因此以这种方式使用 const 可以避免在某些平台上混淆错误。 着色器使用的语义要让着色器在所有平台上运行，一些着色器值应该使用以下语义： 顶点着色器输出（裁剪空间）位置：SV_POSITION。有时，着色器使用 POSITION 语义来使着色器在所有平台上运行。请注意，这不适用于 Sony PS4 或有曲面细分的情况。 片元着色器输出颜色：SV_Target。有时，着色器使用 COLOR 或 COLOR0 来使着色器在所有平台上运行。请注意，这不适用于 Sony PS4。 将网格渲染为点时，从顶点着色器输出 PSIZE 语义（例如，将其设置为 1）。某些平台（如 OpenGL ES 或 Metal）在未从着色器写入点大小时会将点大小视为“未定义”。 有关更多详细信息，请参阅有关着色器语义的文档。 Direct3D 着色器编译器语法Direct3D 平台使用 Microsoft 的 HLSL 着色器编译器。对于各种细微的着色器错误，HLSL 编译器比其他编译器更严格。例如，它不接受未正确初始化的函数输出值。 使用此编译器时，您可能遇到的最常见情况是： 具有 out 参数的表面着色器顶点修改器。按如下方式初始化输出： 12345void vert (inout appdata_full v, out Input o) &#123; **UNITY_INITIALIZE_OUTPUT(Input,o);** // ... &#125; 部分初始化的值。例如，函数返回 float4，但代码只设置它的 .xyz 值。如果只需要三个值，请设置所有值或更改为 float3。 在顶点着色器中使用 tex2D。这是无效的，因为顶点着色器中不存在 UV 导数。这种情况下，您需要采样显式 Mip 级别；例如，使用 tex2Dlod (tex, float4(uv,0,0))。此外，还需要添加 #pragma target 3.0，因为 tex2Dlod 是着色器模型 3.0 的功能。 着色器中的 DirectX 11 (DX11) HLSL 语法表面着色器编译管线的某些部分不能理解特定于 DirectX 11 的 HLSL（Microsoft 的着色器语言）语法。 如果您正在使用 HLSL 功能（比如 StructuredBuffers、RWTextures 和其他非 DirectX 9 语法），请将它们包裹在 DirectX X11 专用的预处理器宏中，如下例所示。 12345# ifdef SHADER_API_D3D11// DirectX11 专用代码，例如StructuredBuffer&lt;float4&gt; myColors;RWTexture2D&lt;float4&gt; myRandomWriteTexture;# endif 使用着色器帧缓冲提取一些 GPU（最明显的是 iOS 上基于 PowerVR 的 GPU）允许您通过提供当前片元颜色作为片元着色器的输入来进行某种可编程混合（请参阅 khronos.org 上的 EXT_shader_framebuffer_fetch）。 可在 Unity 中编写使用帧缓冲提取功能的着色器。要执行此操作，请在使用 HLSL（Microsoft 的着色语言，请参阅 msdn.microsoft.com）或 Cg（Nvidia 的着色语言，请参阅 nvidia.co.uk）编写片元着色器时使用 inout 颜色参数。 以下示例采用的是 Cg 语言。 123456789101112CGPROGRAM// 只为可能支持该功能的平台（目前是 gles、gles3 和 metal）// 编译着色器# pragma only_renderers framebufferfetchvoid frag (v2f i, inout half4 ocol : SV_Target)&#123; // ocol 可以被读取（当前帧缓冲区颜色） // 并且可以被写入（将颜色更改为该颜色） // ...&#125; ENDCG 着色器中的深度 (Z) 方向深度 (Z) 方向在不同的着色器平台上不同。 DirectX 11, DirectX 12, Metal: Reversed direction 深度 (Z) 缓冲区在近平面处为 1.0，在远平面处减小到 0.0。 裁剪空间范围是 [near,0]（表示近平面处的近平面距离，在远平面处减小到 0.0）。 其他平台：传统方向 深度 (Z) 缓冲区值在近平面处为 0.0，在远平面处为 1.0。 裁剪空间取决于具体平台： 在 Direct3D 类平台上，范围是 [0,far]（表示在近平面处为 0.0，在远平面处增加到远平面距离）。 在 OpenGL 类平台上，范围是 [-near,far]（表示在近平面处为负的近平面距离，在远平面处增加到远平面距离）。 请注意，使反转方向深度 (Z) 与浮点深度缓冲区相结合，可显著提高相对于传统方向的深度缓冲区精度。这样做的优点是降低 Z 坐标的冲突并改善阴影，特别是在使用小的近平面和大的远平面时。 因此，在使用深度 (Z) 发生反转的平台上的着色器时： 定义了 UNITY_REVERSED_Z。 _CameraDepth 纹理的纹理范围是 1（近平面）到 0（远平面）。 裁剪空间范围是“near”（近平面）到 0（远平面）。 但是，以下宏和函数会自动计算出深度 (Z) 方向的任何差异： Linear01Depth(float z) LinearEyeDepth(float z) UNITY_CALC_FOG_FACTOR(coord) 提取深度缓冲区如果要手动提取深度 (Z) 缓冲区值，则可能需要检查缓冲区方向。以下是执行此操作的示例： 1234float z = tex2D(_CameraDepthTexture, uv);# if defined(UNITY_REVERSED_Z) z = 1.0f - z;# endif 使用裁剪空间如果要手动使用裁剪空间 (Z) 深度，则可能还需要使用以下宏来抽象化平台差异： 1float clipSpaceRange01 = UNITY_Z_0_FAR_FROM_CLIPSPACE(rawClipSpace); 注意：此宏不会改变 OpenGL 或 OpenGL ES 平台上的裁剪空间，因此在这些平台上，此宏返回“-near”1（近平面）到 far（远平面）之间的值。 投影矩阵如果处于深度 (Z) 发生反转的平台上，则 GL.GetGPUProjectionMatrix() 返回一个还原了 z 的矩阵。 但是，如果要手动从投影矩阵中进行合成（例如，对于自定义阴影或深度渲染），您需要通过脚本按需自行还原深度 (Z) 方向。 以下是执行此操作的示例： 123456789101112131415161718var shadowProjection = Matrix4x4.Ortho(...); //阴影摄像机投影矩阵var shadowViewMat = ... //阴影摄像机视图矩阵var shadowSpaceMatrix = ... //从裁剪空间到阴影贴图纹理空间 //当引擎通过摄像机投影计算设备投影矩阵时，//&quot;m_shadowCamera.projectionMatrix&quot;被隐式反转m_shadowCamera.projectionMatrix = shadowProjection; //&quot;shadowProjection&quot;在连接到&quot;m_shadowMatrix&quot;之前被手动翻转，//因为它被视为着色器的其他矩阵。if(SystemInfo.usesReversedZBuffer) &#123; shadowProjection[2, 0] = -shadowProjection[2, 0]; shadowProjection[2, 1] = -shadowProjection[2, 1]; shadowProjection[2, 2] = -shadowProjection[2, 2]; shadowProjection[2, 3] = -shadowProjection[2, 3];&#125; m_shadowMatrix = shadowSpaceMatrix * shadowProjection * shadowViewMat; 深度 (Z) 偏差Unity 自动处理深度 (Z) 偏差，以确保其与 Unity 的深度 (Z) 方向匹配。但是，如果要使用本机代码渲染插件，则需要在 C 或 C++ 代码中消除（反转）深度 (Z) 偏差。 深度 (Z) 方向检查工具 使用 SystemInfo.usesReversedZBuffer 可确认所在平台是否使用反转深度 (Z)。","categories":[{"name":"Unity","slug":"Unity","permalink":"https://whitetail-o.github.io/categories/Unity/"}],"tags":[{"name":"图形 API","slug":"图形-API","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2-API/"},{"name":"Unity","slug":"Unity","permalink":"https://whitetail-o.github.io/tags/Unity/"},{"name":"转载","slug":"转载","permalink":"https://whitetail-o.github.io/tags/%E8%BD%AC%E8%BD%BD/"}]},{"title":"Demo","slug":"Demo","date":"2023-03-15T08:15:10.000Z","updated":"2023-03-27T03:13:58.799Z","comments":true,"path":"2023/03/15/Demo/","link":"","permalink":"https://whitetail-o.github.io/2023/03/15/Demo/","excerpt":"上传一些小Demo，基本都是实时渲染的内容，主要通过Unity和UE实现。 屏幕空间阴影 PCSS+SSAO 不同阴影方案的对比： PBR，屏幕空间反射，Bloom 此处实现的PBR是基于实时渲染中使用较多的Cook-Torrance模型，采用Disney‘s Principled BRDF，其中法线分布项（Specular D）采用了指数更高的GTR以获得更长的高光。 间接光照漫反射采用SH球谐函数 间接光照高光则采用IBL的Split Sum SSR，屏幕空间反射。算法实现倒不难，烦的在Unity左右手坐标系的问题，以及各种DX12和OpenGL之间的差异。后续会整理一篇坐标变换中，DX12和OpenGL之间的差异。 Bloom泛光","text":"上传一些小Demo，基本都是实时渲染的内容，主要通过Unity和UE实现。 屏幕空间阴影 PCSS+SSAO 不同阴影方案的对比： PBR，屏幕空间反射，Bloom 此处实现的PBR是基于实时渲染中使用较多的Cook-Torrance模型，采用Disney‘s Principled BRDF，其中法线分布项（Specular D）采用了指数更高的GTR以获得更长的高光。 间接光照漫反射采用SH球谐函数 间接光照高光则采用IBL的Split Sum SSR，屏幕空间反射。算法实现倒不难，烦的在Unity左右手坐标系的问题，以及各种DX12和OpenGL之间的差异。后续会整理一篇坐标变换中，DX12和OpenGL之间的差异。 Bloom泛光 皮肤渲染（预积分、屏幕空间次表面散射） 此处采用的是使用SSSS实现SSS的SSSSS（:D，好绕），后续会专门写一个这个的文章，写一下各种Diffusion Profile，顺便把Burley Normalized中的PDF、CDF给写一下。 通过模板测试制作出皮肤的Mask，再通过MRT，使用两张RT存储高光和漫反射的Irradiance。对漫反射的Irradiance使用Diffusion Profile（此处使用的Diffusion Profile是Separable Sum-of-Gaussians）做卷积去近似次表面散射。最后叠上高光就好啦，下面是效果图： NPR主播女孩重度依赖——超天酱 战双帕弥什——露西亚（NPR结合PBR） 曲面细分，几何着色器 + DOF景深 多层Pass短毛渲染 这里采用了30层Pass 基于UE5的动捕短片 动捕设备：诺亦腾 后期动作修改：MotionBuilder、Maya Mapping 是用于建筑Mapping的短片，因此是竖屏的 其他还在慢慢完善","categories":[{"name":"Demo","slug":"Demo","permalink":"https://whitetail-o.github.io/categories/Demo/"}],"tags":[{"name":"Demo","slug":"Demo","permalink":"https://whitetail-o.github.io/tags/Demo/"},{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}]},{"title":"Games202 作业汇总","slug":"Games202HW","date":"2023-02-20T13:42:10.000Z","updated":"2023-03-18T14:40:11.607Z","comments":true,"path":"2023/02/20/Games202HW/","link":"","permalink":"https://whitetail-o.github.io/2023/02/20/Games202HW/","excerpt":"","text":"阴影PCSS Precomputed Radiance Transfer，PRT 屏幕空间反射 Kulla-Conty Approximation TAA","categories":[{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/categories/Games202/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/tags/Games202/"}]},{"title":"Games202-7 A Glimpse of Industrial Solution","slug":"Games202_07_A Glimpse of Industrial Solution","date":"2023-02-20T13:42:10.000Z","updated":"2023-03-17T05:34:29.382Z","comments":true,"path":"2023/02/20/Games202_07_A Glimpse of Industrial Solution/","link":"","permalink":"https://whitetail-o.github.io/2023/02/20/Games202_07_A%20Glimpse%20of%20Industrial%20Solution/","excerpt":"a). Anti-Aliasinga.1). Temporal Anti-Aliasing (TAA) 复用先前帧的样本，假设画面不动，就可在单个像素内随时间规律移动感知点，进行（加权）平均； 为何规律移动感知点： 随机采样会引入高频噪声； 如画面移动，则和频域降噪相同，使用Motion vector找到对应像素，再规律移动感知点。同时也可引入Clamp和Detection的操作； a.2). MSAA vs. SSAASSAA： 相当于用更大分辨率渲染后降采样，做2倍的SSAA，相当于一个像素做4次shading； 质量最好，但是性能开销大； MSAA： 在一个像素内，同一个图元只着色一次；(如图，0、2、3为图元A，着色一次(左边的绿点)；1为图元B，着色一次；) 因此，MSAA会维护一张表，表中记录当前感知点记录的color(albedo?) 和 深度 在像素间复用样本； a.3). Image Based Anti-Aliasing Solution a.4). Note G-buffers一定不能做抗锯齿","text":"a). Anti-Aliasinga.1). Temporal Anti-Aliasing (TAA) 复用先前帧的样本，假设画面不动，就可在单个像素内随时间规律移动感知点，进行（加权）平均； 为何规律移动感知点： 随机采样会引入高频噪声； 如画面移动，则和频域降噪相同，使用Motion vector找到对应像素，再规律移动感知点。同时也可引入Clamp和Detection的操作； a.2). MSAA vs. SSAASSAA： 相当于用更大分辨率渲染后降采样，做2倍的SSAA，相当于一个像素做4次shading； 质量最好，但是性能开销大； MSAA： 在一个像素内，同一个图元只着色一次；(如图，0、2、3为图元A，着色一次(左边的绿点)；1为图元B，着色一次；) 因此，MSAA会维护一张表，表中记录当前感知点记录的color(albedo?) 和 深度 在像素间复用样本； a.3). Image Based Anti-Aliasing Solution a.4). Note G-buffers一定不能做抗锯齿 b). Temporal Super Resolution 通过深度学习告诉管线，如何使用历史帧的信息； c). Deferred Shading(详见百人计划图形3.4 延迟渲染管线)主要解决大量光照渲染和overdraw（传统渲染如果从后往前渲染，那所有fragment都会被shaded一次）的方案。 可以将延迟渲染(Deferred Rendering)理解为先将所有物体都先绘制到屏幕空间的缓冲（即G-buffer，Geometric Buffer，几何缓冲区）中，再逐光源对该缓冲进行着色的过程，从而避免了因计算被深度测试丢弃的片元的着色而产生的不必要的开销。也就是说延迟渲染基本思想是，先执行深度测试（应该也包括其他测试），再进行着色计算，将本来在物空间（三维空间）进行光照计算放到了像空间（二维空间）进行处理。 对应于正向渲染O(m*n)的 复杂度，经典的延迟渲染复杂度为O(n+m)。 c.1). 流程 可以将延迟渲染理解为两个Pass的过程： 几何处理阶段(Geometry Pass)。这个阶段中，我们获取对象的各种几何信息（Position、Normal、Albedo、Specular等），并将第二步所需的各种数据储存（也就是渲染）到多个G-buffer中； 由于有深度测试，所以最终写入G-buffer中的，都是离摄像机最近的片元的集合属性，这就意味着，在G-buffer中的片元必定要进行光照计算。 光照处理阶段(Lighting Pass)。在这个pass中，我们只需渲染出一个屏幕大小的二维矩形，使用第一步在G-buffer中存储的数据对此矩阵的每一个片段计算场景的光照；光照计算的过程还是和正向渲染以前一样，只是现在我们需要从对应的G-buffer而不是顶点着色器(和一些uniform变量)那里获取输入变量了。 c.2). 延迟渲染的优缺点 优点： Complexity: O(#fragment #light) -&gt; O(#vis. frag. #light) 只渲染可见的像素，节省计算量 用更少的shader 对后处理支持良好（例如深度信息：直接拿G-buffer中的就行。而前向渲染需要单独Pass再渲染一张深度图） 在大量光源的场景优势尤其明显； 缺点： 内存开销较大，且占用了大量的显存带宽； 需要传递G-Buffer； 有时需要用到G-Buffer的信息，如深度图做后处理，那将不会进行Clear； 只能用同一套Lighting Pass； 对透明物体的渲染存在问题。在这点上需要结合正向渲染进行渲染； 对多重采样抗锯齿（MultiSampling Anti-Aliasing, MSAA）等硬件抗锯齿的支持不友好，主要因为需开启MRT； MSAA是依赖于子像素，而Deffered shading处在光栅化之后（单个像素内值相等），传输数据是通过G-Buffer； 但可使用TAA 问FXAA、FSAA与MSAA有什么区别？效果和性能上哪个好？ - 文刀秋二的回答 - 知乎 https://catlikecoding.com/unity/tutorials/rendering/part-13/ d). Tiled Shading 基于Deferred Shading 并不是所有光源都会对Tile有贡献 Complexity: O(#vis. frag. #light) -&gt; O(#vis. frag. avg #light per tile) e). Clustered Shading(群组渲染) 在Tiled Shading的基础上再对Depth分段； Complexity: O(#vis. frag. avg #light per tile) -&gt; O(#vis. frag. avg #light per cluster) f). Level of Detail Solutions cascaded: 级联 生成时，不同Level之间有一定重叠，用于过渡时Lerp g). Global Illumination Solutions","categories":[{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/categories/Games202/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/tags/Games202/"}]},{"title":"Games202-6 Real-time Ray-Tracing","slug":"Games202_06_Real-time Ray-Tracing","date":"2023-02-19T12:42:10.000Z","updated":"2023-03-17T05:34:38.145Z","comments":true,"path":"2023/02/19/Games202_06_Real-time Ray-Tracing/","link":"","permalink":"https://whitetail-o.github.io/2023/02/19/Games202_06_Real-time%20Ray-Tracing/","excerpt":"a). IntroductionReal-time Ray-Tracing vs. Ray-Tracing: Real-time Ray-Tracing == 1/few sample per pixel(SPP) Key technology: Denoising(降噪) 一个光路样本（1 SPP path tracing）： 第一步是Rasterization，而不是Ray的原因： 从摄影机发出经过各个像素的光线，即等同于进行一次光栅化，找到Primary hitpoint 第一步如做光线求交，则为光线投射（Ray Casting）。而光线投射和光栅化没有本质区别（都是渲染一点的DI，只不过相当于深度测试被光线求交替代了） Ray Casting. 注意和光线追踪的区别，Ray Casting基本只求交一次，而不迭代追踪 &#8617; 传统的降噪方式不是效果不好，就是太慢或不靠谱 b). Temporal denoising(时域降噪) Key idea: 复用前面已经降噪过的一帧； 使用motion vector来找到先前的位置； 本质上是提高采样率； b.1). G-Buffer b.2). Back Projection Key idea：不同帧之间相同的点，意味着有着相同的世界位置（如不移动）或模型空间位置； How： 如果世界坐标 $s$ 存在于G-Buffer中，即可直接使用； 否则，$s = M^{-1}V^{-1}P^{-1}E^{-1}x$ （$E$ 为视口变换，即NDF到Viewport/Screen） 运动（Motion）情况已知，$s’ = T^{-1} s$，$s’$ 为运动前的位置，$T$ 为运动的矩阵 在 $i-1$ 帧，$s$ 对应的屏幕空间位置为 $x’=P’V’M’s’$","text":"a). IntroductionReal-time Ray-Tracing vs. Ray-Tracing: Real-time Ray-Tracing == 1/few sample per pixel(SPP) Key technology: Denoising(降噪) 一个光路样本（1 SPP path tracing）： 第一步是Rasterization，而不是Ray的原因： 从摄影机发出经过各个像素的光线，即等同于进行一次光栅化，找到Primary hitpoint 第一步如做光线求交，则为光线投射（Ray Casting）。而光线投射和光栅化没有本质区别（都是渲染一点的DI，只不过相当于深度测试被光线求交替代了） Ray Casting. 注意和光线追踪的区别，Ray Casting基本只求交一次，而不迭代追踪 &#8617; 传统的降噪方式不是效果不好，就是太慢或不靠谱 b). Temporal denoising(时域降噪) Key idea: 复用前面已经降噪过的一帧； 使用motion vector来找到先前的位置； 本质上是提高采样率； b.1). G-Buffer b.2). Back Projection Key idea：不同帧之间相同的点，意味着有着相同的世界位置（如不移动）或模型空间位置； How： 如果世界坐标 $s$ 存在于G-Buffer中，即可直接使用； 否则，$s = M^{-1}V^{-1}P^{-1}E^{-1}x$ （$E$ 为视口变换，即NDF到Viewport/Screen） 运动（Motion）情况已知，$s’ = T^{-1} s$，$s’$ 为运动前的位置，$T$ 为运动的矩阵 在 $i-1$ 帧，$s$ 对应的屏幕空间位置为 $x’=P’V’M’s’$ b.3). issues Failure case 1: 切换场景 burn-in period(即需要一定时间积累降噪质量足够好的帧，如UE中的burn-in) Failure case 2: walking backwards in a hallway screen space issue（当前帧出现上一帧屏幕外的信息） Failure case 3: suddenly appearing background disocclusion（上一帧被遮挡的物体，当前帧未被遮挡） 可能造成拖尾（lagging） b.4). Adjustments to Temp. Failure \\bar{C}^{(i)}=\\alpha \\bar{C}^{(i)}+(1-\\alpha) C^{(i-1)} Clamping Clamp上一帧的信息，使其接近当前帧。即Clamp $C^{(i-1)}$ Detection(即不符合要求时，不使用Temp. denoising) Use e.g. object ID to detect temporal failure（ID通道） 调整$\\alpha$，上一帧不可靠时，调高$\\alpha$ Problem：重新引入更多噪声； 可能需要增强空域降噪； b.5). More Temporal Failure Detaching/lagging shadows(阴影拖尾) Temporal failure can also happen in shading 如反射滞后； c). Implementation(实现)eg. Gaussian filter 滤波核可以不归一化，但对于结果需要归一化； c.1). Bilateral filtering(双边滤波)观察： 高斯模糊会将边界模糊，但我们需要保留边界； 边界 = 颜色差异大 目的： 模糊同时保留边界； 当像素$j$ 和像素$i$ 颜色差异大时，$j$贡献变少（权重变小） 像素$a$ 位置为$(i,j)$，像素$b$ 位置为$(k,l)$； $I(i,j)$ 表示$(i,j)$位置的像素值； $\\sigma$ 控制对应项的作用范围，其值越大，对应项的局部影响范围就越大，分子变化影响越小 类似于两个不同形式的高斯核相乘（指数相加），即两个标准（距离，颜色），2 metrics 可以根据需求调整，如较为看重color dist. 对weight的影响，就可以将第二项的2 调为 1； c.2). Joint Bilateral filtering(联合双边滤波)观察： Gaussian filtering: 1 metric (distance) Bilateral filtering: 2 metrics (position dist. &amp; color dist.) 因此，我们可以考虑更多的标准（metric），丰富滤波核，进行滤波（Key idea） 定义：Joint Bilateral filtering是一系列考虑更多标准的滤波方法。 Note: c.2.1). Example c.2). Large Filters对于大的滤波核，性能开销会非常大(e.g. 64x64) Solution 1: Separate Passes 将NxN大小的2D高斯核，拆分为 1xN 和 Nx1 的1D高斯核。通过两个Pass进行滤波；（注意： 并不是所有滤波核都可拆分） 原因： w(i, j, k, l)=\\exp \\left(-\\frac{(i-k)^{2}+(j-l)^{2}}{2 \\sigma_{d}^{2}}\\right)2D高斯核的形式是可拆分的，如下： G_{2D}(x, y) = G_{1D}(x) \\cdot G_{1D}(y) 理论上，双边滤波/联合双边滤波是不可拆分的（实现上，只要滤波核不特别大，如超过32x32，就可采用拆分方法） Solution 2: Progressively Growing Sizes(逐步增加尺寸)介绍： 逐Pass增加filter (间隙的)size，类似空洞卷积。第一次间隙为0，第二次间隙为1…… 原因： 逐步增加尺寸： 逐步减小信号的最高频率； 增加采样间隙： 降低采样频率，频谱搬移距离逐渐减小； 逻辑： 减少信号高频部分，并增大采样间隙（频谱搬移，将信号左边界搬移到有边界），使得不会产生信号混叠； d). Outlier Removal(and temporal clamping)d.1). IntroductionOutlier: 场景中一些特别亮的噪声，即萤火虫噪声； 出现原因： 蒙特卡洛积分时，由于采样率不足，会出现特别亮和特别暗的点； 无法用滤波解决，滤波后仍会存在，甚至从一点变为亮的色块（blocky） 解决方法： Outlier removal(clamp) Outlier removal: 应用时间： 滤波之前（但会打破能量守恒，如不想打破就得提高采样率） d.2). 实现 $\\mu$: 均值 $\\sigma$: 标准差 即将各个点Clamp到一定范围内（如担心光源被clamp掉，可以先不Render光源。Outlier removal之后再加上光源） 之前提到的Temporal Clamping同理： 将上一帧Clamp向（经过空域降噪）这一帧 e). SVGF(Spatiotemporal Variance-Guided Filtering) 降噪效果好，但仍然有拖影、反射滞后等问题； 在Overblue和更多的noise之间，选择了Overblur e.1). SVGF — Joint Bilateral Filteringe.1.1). Depth A、B在同平面深度却差异很大，使得互相之间贡献少。因此，在分母中引入梯度$\\nabla z(p)$ ，该梯度为深度在对应点法线方向的变化率（注意：梯度为向量，其方向为法线方向；）。 当平面几乎垂直于屏幕时，$\\nabla z(p)$ 变大，使得深度差异对权重的影响变小； e.1.2). Normal 应使用几何法线，而不使用经过法线扰动的Normal e.1.3). Luminance(grayscale color value) 使用亮度值； Variance: Step1: 计算空域中7x7的方差； Step2: 通过motion vectors在时域上平均（类似时域降噪）； Step3: 对平均后的结果再在空域上3x3的范围内平均； 即，spatial filter —&gt; temporal filter —&gt; spatial filter f). RAE(Recurrent AutoEncoder) 一种结构，对Monte carlo路径追踪得到的结果进行reconstruction-对RTRT做滤波。 后期处理，把noise的图变clean。 使用G-buffers 神经网络会自动将temporal的结果累积起来 g). Comparison","categories":[{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/categories/Games202/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Ray-Tracing","slug":"Ray-Tracing","permalink":"https://whitetail-o.github.io/tags/Ray-Tracing/"},{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/tags/Games202/"},{"name":"Denoise","slug":"Denoise","permalink":"https://whitetail-o.github.io/tags/Denoise/"}]},{"title":"Games202-5 Real-time Physically-based Materials","slug":"Games202_05_Real-time Physically-based Materials","date":"2023-02-18T10:42:10.000Z","updated":"2023-03-17T05:34:50.468Z","comments":true,"path":"2023/02/18/Games202_05_Real-time Physically-based Materials/","link":"","permalink":"https://whitetail-o.github.io/2023/02/18/Games202_05_Real-time%20Physically-based%20Materials/","excerpt":"Q1：在金属或高光工作流中，对于非导体材质（电介质）默认其零度菲涅尔值$R_0$ 为4%，那么按PBR来，他怎么会有颜色呢；还是说非导体的albedo就是$R_0$ ? 按作业中来好像albedo就是 $R_0$ ，后续还得深挖一下； Q2：Jacobian 项，方向导数需要去了解更多 a). Introduction 尽管实时渲染中的PBR，不一定完全基于物理。如Disney principled BRDFs (artist friendly but still not PBR) b). Microfacet BRDF 菲涅尔项； Shadowing-masking term 考虑微表面之间的遮挡和阴影； 当光线几乎平行与表面入射时(Grazing angle)，微表面之间遮挡变多 Disterbution of normals(法线分布)","text":"Q1：在金属或高光工作流中，对于非导体材质（电介质）默认其零度菲涅尔值$R_0$ 为4%，那么按PBR来，他怎么会有颜色呢；还是说非导体的albedo就是$R_0$ ? 按作业中来好像albedo就是 $R_0$ ，后续还得深挖一下； Q2：Jacobian 项，方向导数需要去了解更多 a). Introduction 尽管实时渲染中的PBR，不一定完全基于物理。如Disney principled BRDFs (artist friendly but still not PBR) b). Microfacet BRDF 菲涅尔项； Shadowing-masking term 考虑微表面之间的遮挡和阴影； 当光线几乎平行与表面入射时(Grazing angle)，微表面之间遮挡变多 Disterbution of normals(法线分布) b.1). The Fresnel Term 本质上是考虑能量的吸收和反射（即考虑BRDF就会有因为颜色的合理的能量损失） b.2). Normal Distribution Function(NDF) NDF从简单（如Gloosy）变为复杂（如Diffuse），就类似于把微表面高度场拉大； 类型： Beckmann, GGX, etc. Detailed models [Yan 2014, 2016, 2018, …] b.2.1). Beckmann NDFBeckmann NDF: 和高斯函数相似 Project Solid angel上积分为1 定义在Slope space（坡度空间） 原因： 在Slope space（法线交点处切线平面）中Support无限大，任意位置对应的夹角不会超过90°，保证微表面不会朝下 D(h)=\\frac{e^{-\\frac{\\tan ^{2} \\theta_{h}}{\\alpha^{2}}}}{\\pi \\alpha^{2} \\cos ^{4} \\theta_{h}} $\\alpha$ ：Roughness的平方 $\\theta_{h}$ ：半角向量和（宏观）法线的夹角 b.2.2). GGX (or Trowbridge-Reitz, TR) Long tail: 使得光线过度更为自然，如高光过渡柔和 b.2.3). GGGX(GTR) b.3). Shadowing-Masking Term Why is it important? 如没$G$ 项，在grazing angle时，物体表面会发亮； b.3.1). The Smith shadowing-masking term 假设： Shadow和Masking无关，即 b.3.2). Issues(Missing energy) 原因：由于Shadowing-masking只考虑了一次弹射，对于多次弹射的能量直接舍去，造成能量损失； 做法： Accurate methods exist [Heitz et al. 2016] 主要用于离线渲染，对于RTR过慢； The Kulla-Conty Approximation Being occluded == next bounce happening 构造函数去补偿损失的能量； 求得的BRDF+原BRDF，即可； b.3.3). Kulla-Conty Approximation {L}_{o}(\\omega_{o})=\\int_{\\Omega^{+}}{L}_{i}(\\omega_{i})f_{r}(\\omega_{i},\\omega_{o})cos\\theta_i\\,\\mathrm{d}\\omega_{i} 通过对$\\mathrm{d}\\omega_{i}$ 换元（即立体角） 得到： 此处假设各处入射Radiance（$L_i$） 均匀为1，因此出射的Radiance也应均匀为1； 此处假设BRDF的菲涅尔项为1，即无颜色，能量不损失。后续再考虑颜色（？待验证） 该函数是关于出射角的俯仰角$\\theta_o$ 的函数（和方位角无关是因为假设为各项同性） Key idea: 通过积分可得需要补偿的能量为 $1 - E(\\mu_{o})$； 该函数是关于出射角的俯仰角$\\theta_o$ 的函数（和方位角无关是因为假设为各项同性） 考虑到对称性质（reciprocity），即入射方向和出射方向互换，Radiance不变，补偿项的BRDF形式为$c(1 - E(\\mu_{i}))(1 - E(\\mu_{o}))$，其中 $c$ 为常数； 补偿项的BRDF（带cos） - $c(1 - E(\\mu_{i}))(1 - E(\\mu_{o}))$ 常数 $c = \\frac{1}{\\pi(1-E_{avg})}, E_{avg}=2\\int_0^1E(\\mu)\\mu\\, \\mathrm{d}\\mu$ 补偿项即为： $c$ 推导：即让补偿项的BRDF$f_{ms}(\\mu_{o},\\mu_{i})$ 的积分结果为 $1 - E(\\mu_{o})$ 预计算 对于$E_{avg}=2\\int_0^1E(\\mu)\\mu\\, \\mathrm{d}\\mu$ ，只需要得知其Roughness就可求出对应的结果，储存在1D table中； NDF等使用的模型已知； 对于$E(\\mu)$ 得知其roughness(确定函数) 和 $\\mu$ (确定函数自变量)，即可求出对应结果，储存在2D table中； Result. 原BRDF+(uncolored)补偿项BRDF &#8617; Color(energy loss) 有颜色( vec3的$R_0$项 )，意味着能量被吸收，也是能量合理的损失； 之前我们做了，不损失能量，无颜色的情况。之后，我们需要计算由于颜色的能量损失； 定义平均菲涅尔 $F_{avg}$ ，表示能量参与弹射后，平均反射出多少；（剩下的被吸收） 之前定义了 $E_{avg}$ ，表示每次弹射后，平均有多少能量被看见（即不参与之后的弹射） $F_{avg}$ 、$E_{avg}$ 都是三维的向量； 由此可得， $(1-E_{avg})$ 表示上一次弹射后，被遮挡未出射的能量； 等比数列求和； 求得的color term直接乘上uncolored additional BRDF即可； Result with color. 原BRDF + colored补偿项BRDF(color term * uncolor补偿项BRDF) &#8617; c). Linearly Transformed Cosines(LTC, 线性变换余弦)c.1). Introduction作用： Solves the shading of microfacet models 主要用于GGX，当然其他NDF也适用； No shadows Under polygon shaped lighting(多边形光源)，解决多边形光源的光照积分问题； Key idea: 对于任意一个球面分布函数，一定可以通过一个线性变换矩阵将其变化到另外一个球面分布函数(对于任意2D(二维，出射方位角和俯仰角) BRDF lobe can be transformed to a cosine) 光源的形状也可以被变换，且积分结果相同； 变换后的积分有解析解； Ref: [1] Real-Time Polygonal-Light Shading with Linearly Transformed Cosines [2] Real-Time Polygonal-Light with LTC-zhihu [3] 物理光源：Linearly Transformed Cosines [4] Eric Heitz’s Research Page [5] Global Illumination_Linearly Transformed Cosines (LTC) [6] 图形学基础|基于LTC的面光源渲染 $J$ 是雅可比行列式，更进一步的可见Ref，后续论文复现后再进一步补充此处笔记； LTC介绍. 来源Ref[3] &#8617; LTC拟合BRDF. 来源Ref[6] &#8617; d). Disney’s Principled BRDFd.1). Introduction微表面BRDF的缺点 微表面模型不擅长表示真实（基于物理）的材质； 如：Diffuse的情况不好表示，多层材质也难以表示； 微表面模型“are not artist friendly” 如： 复折射率（complex index of refraction）,$n-ik$（详见PBR-White-Paper） 需求： Artist friendly，但一定程度上physically-based 设计原则： 应该使用直观的而不是物理的参数； 使用的参数尽可能少； 参数应该在0~1； 参数在必要时允许超出0~1的范围； 参数的所有组合的外观都应该是合理、稳定的； Disney’s Principled BRDF. A table showing the effects of individual parameters &#8617; sheen: 类似天鹅绒，材质表面有一层绒毛，使得其在grazing angle有雾化的效果 sheenTint: 绒毛的颜色 clearcoat: 类似清漆（当时做雨滴就用的是clearcoat） d.2). Pros and Cons 易于理解/控制 可表现大量材质； 实现复杂，基本是去拟合PBR材质； 不基于物理，但视觉上大部分是符合的； 参数空间巨大；","categories":[{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/categories/Games202/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Materials","slug":"Materials","permalink":"https://whitetail-o.github.io/tags/Materials/"},{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/tags/Games202/"},{"name":"PBR","slug":"PBR","permalink":"https://whitetail-o.github.io/tags/PBR/"}]},{"title":"HPP_Graphics_5.1 PBR基础 BRDF介绍","slug":"HPP_Graphics_5.1_PBR基础","date":"2023-02-15T12:24:32.000Z","updated":"2023-03-27T04:20:57.958Z","comments":true,"path":"2023/02/15/HPP_Graphics_5.1_PBR基础/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_5.1_PBR%E5%9F%BA%E7%A1%80/","excerpt":"引擎为了提高性能，并且artist friendly，用漫反射项补偿微表面BRDF（打破能量守恒，如想在RTR中实现较为准确的能量补充，应使用Kulla-Conty Approximation）。使得其方便控制，如对于非金属4%的 $F_0$ 也可呈现颜色。并且把BRDF分母的 $\\pi$ ,写为4。 因此，引擎中PBR的Shading常有以下几项，并通过系数控制其不过与打破能量守恒： 直接光照漫反射； 直接光照镜面反射； 间接光照漫反射； 间接光照镜面反射； 这样做的结果是容易打破能量守恒，但是artist friendly，而且可表现更多外观。 更多请看Games202 Real-time Physically-based Materials，或以下Reference Ref: LearnOpenGL CN 201403-GDC_UnityPhysicallyBasedShading 基于物理的渲染（PBR）白皮书 基于物理的渲染—更精确的微表面分布函数GGX 如何在Unity中造一个PBR Shader轮子 Image Based Lighting with Multiple Scattering a). Unity中的PBR（Disney‘s Principled BRDF）Unity中Standard Shader基本采用Disney’s Principled BRDF，但有些许不同。Disney’s Principled BRDF可具体看其他文章，如毛星云大佬的PBR白皮书，以下就写一些实现上的不同处和细节。","text":"引擎为了提高性能，并且artist friendly，用漫反射项补偿微表面BRDF（打破能量守恒，如想在RTR中实现较为准确的能量补充，应使用Kulla-Conty Approximation）。使得其方便控制，如对于非金属4%的 $F_0$ 也可呈现颜色。并且把BRDF分母的 $\\pi$ ,写为4。 因此，引擎中PBR的Shading常有以下几项，并通过系数控制其不过与打破能量守恒： 直接光照漫反射； 直接光照镜面反射； 间接光照漫反射； 间接光照镜面反射； 这样做的结果是容易打破能量守恒，但是artist friendly，而且可表现更多外观。 更多请看Games202 Real-time Physically-based Materials，或以下Reference Ref: LearnOpenGL CN 201403-GDC_UnityPhysicallyBasedShading 基于物理的渲染（PBR）白皮书 基于物理的渲染—更精确的微表面分布函数GGX 如何在Unity中造一个PBR Shader轮子 Image Based Lighting with Multiple Scattering a). Unity中的PBR（Disney‘s Principled BRDF）Unity中Standard Shader基本采用Disney’s Principled BRDF，但有些许不同。Disney’s Principled BRDF可具体看其他文章，如毛星云大佬的PBR白皮书，以下就写一些实现上的不同处和细节。 a.1). 直接光照漫反射BRDFUnity中采用的漫反射BRDF不是Lambertian漫反射，而是Disney开发了的一种用于漫反射的新的经验模型。 Disney表示，Lambert漫反射模型在边缘上通常太暗，而通过尝试添加菲涅尔因子以使其在物理上更合理，但会导致其更暗。 思路方面，Disney使用了Schlick Fresnel近似，并修改掠射逆反射（grazing retroreflection response）以达到其特定值由粗糙度值确定，而不是简单为0。 Diffuse BRDF. 上图为Diffuse BRDF &#8617; 为保证shader看起来和Legacy版本差不多亮 ，并且避免在ibl部分对非重要光源做特殊处理，Unity会把分母中的 $\\pi$ 拿掉。同时也会在直接光照的镜面反射项上多乘上一个 $\\pi$ a.2). 直接光照镜面反射BRDF镜面反射即采用微表面BRDF，即 D为微平面分布函数，主要负责镜面反射波峰（specular peak）的形状。 F为菲涅尔反射系数（Fresnel reflection coefficient） G为几何衰减（geometric attenuation）/ 阴影项（shadowing factor） a.2.1). 法线分布项（Specular D）：GTRUnity中采用法线分布项为GGX，这里采用GTR模型。 其中，γ取2，即GGX 另外，在Disney Principled BRDF中，实际上有两个镜面反射波瓣（Specular lobe），并且都用GTR模型。其中γ=2的GRT代表基础底层材质，而γ=1的GRT则代表清漆层的反射。 a.2.2). 菲涅尔项（Specular F）：Schlick Fresnel 由于原始的菲涅尔项表示过于复杂，人们会常用其他数值近似的方法。其中，应用地较为广泛的为Schlick Fresnel。本质上是考虑能量的反射和折射（即考虑菲涅尔就会有因为颜色的合理的能量损失，这也是为什么Kulla-Conty Approximation再为考虑颜色时，不乘上菲涅尔项的原因） 这里需要注意的有两点。 $\\theta_d$ 为半角向量h和视线v之间的夹角，而不是宏观法线n和视线v的夹角。$(i, h)$和$(i, n)$的区别其实就是宏观和微观。在微表面BRDF中，$D(h)$筛选出了沿$h$方向的normal。那此时菲涅尔项中应该使用的normal即为$h$ 电介质（绝缘体）的$F_0$ 为float，金属的 $F_0$ 为float3。而最终用于菲涅尔项的 $F_0$ 常常会根据金属度在0.04(引擎中电介质默认的$F_0$)和albedo之间根据金属度Metallic插值。 a.2.3). 几何项/Shadowing-Masking（Specular G）：Smith-GGX几何项（Specular G）方面，对于主镜面波瓣（primary specular lobe），Disney参考了 Walter的近似方法，使用Smith GGX导出的G项，并将粗糙度参数进行重映射以减少光泽表面的极端增益，即将α 从[0, 1]重映射到[0.5, 1]，α的值为(0.5 + roughness/2)^2。从而使几何项的粗糙度变化更加平滑，更便于美术人员的使用。 以下为Smith GGX的几何项的表达式： 另外，对于对清漆层进行处理的次级波瓣（secondary lobe），Disney没有使用Smith G推导，而是直接使用固定粗糙度为0.25的GGX的 G项，便可以得到合理且很好的视觉效果。 a.3). 间接光照漫反射间接光照漫反射频率基本集中的低频，因此采用球谐函数取近似（Unity中采用前三阶）。 详见Games202 Real-time Environment Mapping a.4). 间接光照镜面反射间接光照镜面反射采用IBL，并通过prefiltering后采用模拟对Lighting的积分，通过Split sum对BRDF积分。（详见Games202 Real-time Environment Mapping）其中，mip和roughness之间的关系为： 12345float m = roughness*roughness;const float fEps = 1.192092896e-07F;float n = (2.0 / max(fEps, m * m)) - 2.0;n /= 4;roughness = pow( 2 / (n + 2), 0.25); Unity中，则通过 $mip = r(1.7 - 0.7r)$ 来拟合。 http://jbit.net/~sparky/academic/mm_brdf.pdf a.5). 各项比例至此，我们已经可以把各项的表达式都写出来了。那么最后需要解决的就是各项之间的比例。 a.5.1). 直接光照首先，我们考虑直接光照。直接光照中，漫反射和镜面反射的关键在于菲涅尔项。菲涅尔项本质上是考虑能量的反射和折射，而光线折射后会发生吸收和散射。而散射的尺度要是足够小，就变成了漫反射（尺度大，如大于一个像素区域时，散射变现为次表面散射，即SSS）。 镜面反射的比例已经在微表面BRDF中的F项中计算过了，因此漫反射的比例即为1 - F。同时，因为我们采用的Disney principled BRDF需要根据金属度在漫反射和镜面反射之间插值，因此漫反射项的比例为$(1 - F) \\cdot (1-Metallic) $ 。 a.5.2). 间接光照在间接光照中，与直接光照不同的地方在于在求间接光照的镜面反射时，我们对BRDF求了积分（Split sum）。因此，我们菲涅尔的不再是微表面的菲涅尔，而是使用宏观法线的菲涅尔。即，$\\theta_d$ 为法线$n$和视线$v$之间的夹角。 这里$F_0$ 与albedo之间lerp使用Roughness，而不是Metallic。（一种经验化的做法，方法来自：https://seblagarde.wordpress.com/2011/08/17/hello-world/） 附上最终Shader 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162Shader &quot;PBR/DisneyPBR&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; &#123;&#125; _Roughness (&quot;Roughness&quot;, Range(0, 1.0)) = 0.3 _Metallic (&quot;Metallic&quot;, Range(0.0, 1.0)) = 0.2 _IBLlut (&quot;IBL Lut&quot;, 2D) = &quot;while&quot; &#123;&#125; &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125; CGINCLUDE #include &quot;UnityCG.cginc&quot; #include &quot;UnityStandardBRDF.cginc&quot; #include &quot;UnityStandardUtils.cginc&quot; half DI_DisneyDiffuse(half NdotV, half NdotL, half NdotH, half perceptualRoughness) &#123; half F90 = 0.5 + 2 * perceptualRoughness * NdotH * NdotH; half lightScatter = 1 + (F90 - 1) * Pow5(1 - NdotL); half viewScatter = 1 + (F90 - 1) * Pow5(1 - NdotV); return lightScatter * viewScatter; &#125; half SmithJointGGX(half NdotV, half NdotL, half perceptualRoughness) &#123; half a = 0.5 + perceptualRoughness/2; a *= a; half a2 = a * a; half lightGGX = 2 * NdotL / (NdotL + sqrt(a2 + (NdotL - a2 * NdotL) * NdotL)); half viewGGX = 2 * NdotV / (NdotV + sqrt(a2 + (NdotV - a2 * NdotV) * NdotV)); return lightGGX * viewGGX; &#125; half GTR2(half NdotH, half perceptualRoughness) &#123; half a2 = perceptualRoughness * perceptualRoughness; half cos2 = NdotH * NdotH; half denom = (1 + (a2 - 1) * cos2); return a2 * UNITY_INV_PI / (denom * denom); &#125; half3 F_schlick(half3 F0, half HdotV) &#123; return F0 + (1 - F0) * Pow5(1 - HdotV); &#125; half3 IBL_LightSample(float3 dir, half perceptualRoughness) &#123; float mip_roughness = perceptualRoughness * (1.7 - 0.7 * perceptualRoughness); half mip = mip_roughness * UNITY_SPECCUBE_LOD_STEPS; half4 hdr_col = UNITY_SAMPLE_TEXCUBE_LOD(unity_SpecCube0, dir, mip); float3 ldr_col = DecodeHDR(hdr_col, unity_SpecCube0_HDR); return ldr_col; &#125; float3 fresnelSchlickRoughness(float cosTheta, float3 F0, float roughness) &#123; return F0 + (max(float3(1.0 - roughness, 1.0 - roughness, 1.0 - roughness), F0) - F0) * Pow5(1.0 - cosTheta); &#125; struct a2v &#123; float4 vertex : POSITION; float3 normal : NORMAL; float2 uv : TEXCOORD0; &#125;; struct v2f &#123; float2 uv : TEXCOORD0; float3 worldNormal : TEXCOORD1; float3 worldPos : TEXCOORD2; float4 vertex : SV_POSITION; &#125;; sampler2D _MainTex; sampler2D _IBLlut; float4 _MainTex_ST; float _Roughness; float _Metallic; v2f vert (a2v v) &#123; v2f o; o.vertex = UnityObjectToClipPos(v.vertex); o.uv = TRANSFORM_TEX(v.uv, _MainTex); o.worldNormal = UnityObjectToWorldNormal(v.normal); o.worldPos = mul(unity_ObjectToWorld, v.vertex); return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; float3 worldNormal = normalize(i.worldNormal); float3 worldLightDir = normalize(UnityWorldSpaceLightDir(i.worldPos)); float3 worldViewDir = normalize(UnityWorldSpaceViewDir(i.worldPos)); float3 worldHalfDir = normalize(worldLightDir + worldViewDir); float NdotV = max(dot(worldNormal, worldViewDir), 0.0001); float NdotL = max(dot(worldNormal, worldLightDir), 0.0001); float NdotH = max(dot(worldNormal, worldHalfDir), 0.0001); float HdotV = max(dot(worldHalfDir, worldViewDir), 0.0001); fixed4 albedo = tex2D(_MainTex, i.uv); float roughness = lerp(0.004, 0.9, _Roughness); //DI // DisneyDiffuse没有乘上Pi fixed3 DisneyDiffuse = albedo.rgb * DI_DisneyDiffuse(NdotV, NdotL, NdotH, roughness); // * UNITY_INV_PI fixed3 F0 = lerp(unity_ColorSpaceDielectricSpec.rgb, albedo, _Metallic); float D = GTR2(NdotH, roughness); float3 F = F_schlick(F0, HdotV); float G = SmithJointGGX(NdotV, NdotL, roughness); half3 SpeBRDF = F * D * G / (4 * NdotL * NdotV); fixed3 LightColor = _LightColor0; half kd = OneMinusReflectivityFromMetallic(_Metallic); fixed3 Ambient = albedo * UNITY_LIGHTMODEL_AMBIENT.rgb; fixed3 Diffuse = (1-F) * kd * LightColor * DisneyDiffuse * NdotL; fixed3 Specular = LightColor * SpeBRDF * NdotL * UNITY_PI; // 乘上Pi和Diffuse等比例变化； // Environment Map half3 ambient_contrib = ShadeSH9(half4(worldNormal, 1)); float3 iblLight = IBL_LightSample(reflect(-worldViewDir, worldNormal), roughness); float2 envLut = tex2D(_IBLlut, float2(lerp(0, 0.99, NdotV), roughness)).rg; float3 F0_Roughness = lerp(unity_ColorSpaceDielectricSpec.rgb, albedo, roughness); float3 Flast = fresnelSchlickRoughness(max(NdotV, 0.001), F0, roughness); float kdLast = (1 - Flast) * (1 - _Metallic); float3 iblDiffuse = (ambient_contrib + Ambient) * albedo * kdLast; float3 iblSpec = (iblLight * (Flast * envLut.r + envLut.g)); return fixed4(Diffuse + Specular + iblDiffuse + iblSpec, 1); // return fixed4(iblDiffuse, 1); &#125; ENDCG Pass &#123; Tags &#123; &quot;LightMode&quot; = &quot;ForwardBase&quot; &#125; CGPROGRAM #pragma vertex vert #pragma fragment frag ENDCG &#125; &#125;&#125; a.6). 结果 Custom PBR. 同参数下，与Standard Shader的对比（左侧为Custom PBR） &#8617; 为获得更长的拖尾，将GTR的γ取3以区别Standard。 可以看到，实现的Shader基本与Unity的Standard Shader一致。但因为法线分布使用了GTR，高光拖尾更长，更柔和。","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"PBR","slug":"PBR","permalink":"https://whitetail-o.github.io/tags/PBR/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}]},{"title":"HPP_Graphics_4.5 DOF景深基础","slug":"HPP_Graphics_4.5_DOF景深基础","date":"2023-02-15T11:26:32.000Z","updated":"2023-03-17T05:20:51.100Z","comments":true,"path":"2023/02/15/HPP_Graphics_4.5_DOF景深基础/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_4.5_DOF%E6%99%AF%E6%B7%B1%E5%9F%BA%E7%A1%80/","excerpt":"","text":"这两篇已经写得挺好的了，后续再补充。 用Unity实现景深效果 图形学基础|景深效果（Depth of Field/DOF） HW Step1: 计算CoC(弥散圆) Step2: Bokeh Filter Step3: Tent Filter Step4: Composition","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"效果","slug":"效果","permalink":"https://whitetail-o.github.io/tags/%E6%95%88%E6%9E%9C/"},{"name":"算法","slug":"算法","permalink":"https://whitetail-o.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"HPP_Graphics_4.1 Bloom算法","slug":"HPP_Graphics_4.1_Bloom算法","date":"2023-02-15T11:24:32.000Z","updated":"2023-03-17T05:18:01.920Z","comments":true,"path":"2023/02/15/HPP_Graphics_4.1_Bloom算法/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_4.1_Bloom%E7%AE%97%E6%B3%95/","excerpt":"a). Bloom算法介绍模拟光辉效果的算法简单思路：提取较亮的部分进行模糊，然后与原图叠加后输出HDR：使用HDR可以使提取到亮度大于1的区域高斯模糊：使用高斯函数得到的高斯核去卷积图像二维高斯核：将运算的复杂度从 N x N x W x H 减少到了 2 x N x W x H (对称性使N可减少到N/2+1) b). Bloom算法实现（Unity）C#部分调用OnRenderImage函数获取纹理和传输参数给Shader： Shader部分使用4个Pass计算Bloom效果： 第一个Pass提取较亮区域第二个、第三个Pass分别在竖直和水平方向上计算高斯模糊最后一个Pass将计算的结果与原图像进行混合 c). Bloom算法应用配合自发光贴图使用配合特效（如烟花）GodRay（基于径向的后处理）使用HDR时，配合Tonemapping（配合色调映射的bloom效果更加柔和）","text":"a). Bloom算法介绍模拟光辉效果的算法简单思路：提取较亮的部分进行模糊，然后与原图叠加后输出HDR：使用HDR可以使提取到亮度大于1的区域高斯模糊：使用高斯函数得到的高斯核去卷积图像二维高斯核：将运算的复杂度从 N x N x W x H 减少到了 2 x N x W x H (对称性使N可减少到N/2+1) b). Bloom算法实现（Unity）C#部分调用OnRenderImage函数获取纹理和传输参数给Shader： Shader部分使用4个Pass计算Bloom效果： 第一个Pass提取较亮区域第二个、第三个Pass分别在竖直和水平方向上计算高斯模糊最后一个Pass将计算的结果与原图像进行混合 c). Bloom算法应用配合自发光贴图使用配合特效（如烟花）GodRay（基于径向的后处理）使用HDR时，配合Tonemapping（配合色调映射的bloom效果更加柔和） Homework带Mask的Bloom效果 实现思路： 修改对应物体fragment返回的Alpha值作为Bloom遮罩 黑为Bloom效果最强，白为无Bloom（因为点光源会使得后处理中Alpha通道比FS返回的大，因此采用黑色Bloom效果最强，待验证）","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"效果","slug":"效果","permalink":"https://whitetail-o.github.io/tags/%E6%95%88%E6%9E%9C/"},{"name":"算法","slug":"算法","permalink":"https://whitetail-o.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"HPP_Graphics_4.2 SSAO","slug":"HPP_Graphics_4.2_SSAO","date":"2023-02-15T11:24:32.000Z","updated":"2023-03-17T05:18:32.679Z","comments":true,"path":"2023/02/15/HPP_Graphics_4.2_SSAO/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_4.2_SSAO/","excerpt":"a). AO(Ambient Occlusion)环境光遮蔽，全称Ambient Occlusion，是计算机图形学中的一种着色和渲染技术,模拟光线达到物体的能力的粗略的全局方法，描述光线到达物体表面的能力。 b). SSAO(Screen Space Ambient Occlusion)屏幕空间环境光遮蔽，全称Screen Space Ambient Occlusion，一种用于计算机图形中实时实现近似环境光遮蔽效果的渲染技术。通过获取像素的深度缓冲、法线缓冲以及像素坐标来计算实现，来近似的表现物体在间接光下产生的阴影。 b.1). SSAO原理 获取深度、法线（View Space）缓冲； Normal Buffer： 重构像素相机空间中的坐标； 通过深度缓冲的depth值重构（近似）该视角下的三维场景； 为什么是近似：Depth Buffer中深度值为0~1，并不能反应无穷远（天空等）。常用的办法是把1映射到View Space的远平面。 法向半球随机采样，计算掩蔽因子，进而得到AO强度（For循环）； 每一次for循环都会在法线半球中获取一个随机向量，根据这个向量我们会求出它对应的深度值，然后跟深度缓冲中对应采样像素位置的深度值做比较，如果大于（灰色点），则认为有遮蔽，算进加权中，最后我们合成AO，然后再加上一些后期处理优化效果。","text":"a). AO(Ambient Occlusion)环境光遮蔽，全称Ambient Occlusion，是计算机图形学中的一种着色和渲染技术,模拟光线达到物体的能力的粗略的全局方法，描述光线到达物体表面的能力。 b). SSAO(Screen Space Ambient Occlusion)屏幕空间环境光遮蔽，全称Screen Space Ambient Occlusion，一种用于计算机图形中实时实现近似环境光遮蔽效果的渲染技术。通过获取像素的深度缓冲、法线缓冲以及像素坐标来计算实现，来近似的表现物体在间接光下产生的阴影。 b.1). SSAO原理 获取深度、法线（View Space）缓冲； Normal Buffer： 重构像素相机空间中的坐标； 通过深度缓冲的depth值重构（近似）该视角下的三维场景； 为什么是近似：Depth Buffer中深度值为0~1，并不能反应无穷远（天空等）。常用的办法是把1映射到View Space的远平面。 法向半球随机采样，计算掩蔽因子，进而得到AO强度（For循环）； 每一次for循环都会在法线半球中获取一个随机向量，根据这个向量我们会求出它对应的深度值，然后跟深度缓冲中对应采样像素位置的深度值做比较，如果大于（灰色点），则认为有遮蔽，算进加权中，最后我们合成AO，然后再加上一些后期处理优化效果。 b.2). Unity实现部分 SSAO的shader中共有三个Pass： 计算生成AO； 模糊 / 滤波 AO与Color buffer混合； b.2.1). 计算AO在基于法线方向，建立法线空间中法向半球的采样块。 在采样块中循环生成采样点，判断是否被遮蔽 因为实时渲染的性能问题，所以采样点数量不会很多，导致出现“油漆”般的画面 引入噪声, 将每个采样点以原点法线方向为旋转轴旋转随机的角度。这样的新采样点会变得极其不规则, 更加离散化。将低频的条纹转化成高频的噪声； 计算相机到像素点的坐标（Unity Shader中的ComputeScreenPos函数）对应的远平面的向量（屏幕空间转换到裁剪空间后乘以远平面距离，再转换到观察空间）； 获得着色点的01线性深度值、观察空间下的法线向量； 然后在法向半球采样块中随机随机采样一个向量，得到法向半球向量。并由此构建经过旋转的法线空间的正交基。 将此前生成的随机向量转换到法线空间中。 循环操作，将每一个向量转换为采样点，坐标基于切线空间，再计算随机法向半球后的向量，然后进行空间转换，切线空间到裁剪空间到屏幕空间。（裁剪空间到屏幕空间进行01映射） 获得采样点的法线深度信息，计算遮蔽，最后得到AO图通过rscreenPos来采样_CameraDepthNormalsTexture，转化成屏幕空间对应的深度值，然后对比linear01Depth（着色点深度，更准确的情况下应该使用viewRandomPos对应的01线性深度），只要大于linear01Depth，则在加权计算AO AO核心代码 延迟渲染+ssao因为在前向渲染的ssao实现过程中，需要获取到相机的法线深度图进行采样得到相应的信息，进行后续的操作。而因为延迟渲染正好需要先生成一个GBuffer，即已包含了ssao执行所需要的法线深度等信息。所以在shader代码编写中有所不同 在c#脚本中需要加入渲染路径的判断 b.2.2). 基于法线的双边滤波（Bilateral Filter）https://blog.csdn.net/puppet_master/article/details/83066572 Homework场景1 这场景好像不太明显，只有在大图里看的清楚， 场景2","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"效果","slug":"效果","permalink":"https://whitetail-o.github.io/tags/%E6%95%88%E6%9E%9C/"},{"name":"算法","slug":"算法","permalink":"https://whitetail-o.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"HPP_Graphics_4.3 实时阴影介绍","slug":"HPP_Graphics_4.3_实时阴影介绍","date":"2023-02-15T11:24:32.000Z","updated":"2023-03-17T05:20:53.338Z","comments":true,"path":"2023/02/15/HPP_Graphics_4.3_实时阴影介绍/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_4.3_%E5%AE%9E%E6%97%B6%E9%98%B4%E5%BD%B1%E4%BB%8B%E7%BB%8D/","excerpt":"图形 4.3 实时阴影介绍更深的可看笔记Games202 Real-time Shadow a). 基于图片实时阴影技术a.1). Shadow Map 关键思想：一个点在相机视角中可见，但在光源视角中不可见，那该点就处于阴影中。 做法： 在光源视角下渲染深度图。对于着色点$A$，将其转换到光源视角（其他空间也行，只要两者在同一坐标空间）后，与Shadow Map中对应点进行深度比较，判断一点是否在阴影中； A 2-Pass Algorithm Light pass: Generate the SM(Shadow Map) Camera pass: uses the SM Pass 1: Render from Light 输出一张光源视角的深度图（Depth Buffer） Pass 2: Render from Eye(Camera) 将光源视角对应的深度转换到View Space, 与Camera视角的深度进行深度比较； 如$Depth_{cam} &gt; Depth_{light}$ ，那说明该点在阴影中（相机可见，光源不可见） 如$Depth_{cam} &lt; Depth_{light}$ ，那说明该点在不在阴影中（相机可见，光源可见）","text":"图形 4.3 实时阴影介绍更深的可看笔记Games202 Real-time Shadow a). 基于图片实时阴影技术a.1). Shadow Map 关键思想：一个点在相机视角中可见，但在光源视角中不可见，那该点就处于阴影中。 做法： 在光源视角下渲染深度图。对于着色点$A$，将其转换到光源视角（其他空间也行，只要两者在同一坐标空间）后，与Shadow Map中对应点进行深度比较，判断一点是否在阴影中； A 2-Pass Algorithm Light pass: Generate the SM(Shadow Map) Camera pass: uses the SM Pass 1: Render from Light 输出一张光源视角的深度图（Depth Buffer） Pass 2: Render from Eye(Camera) 将光源视角对应的深度转换到View Space, 与Camera视角的深度进行深度比较； 如$Depth_{cam} &gt; Depth_{light}$ ，那说明该点在阴影中（相机可见，光源不可见） 如$Depth_{cam} &lt; Depth_{light}$ ，那说明该点在不在阴影中（相机可见，光源可见） a.2). Unity中的屏幕空间阴影映射 Unity的阴影映射是屏幕空间阴影映射，即逐像素生成屏幕空间的阴影贴图后，再在Shading中采样，进而着色。 Step1: 渲染屏幕空间的深度贴图； Step2: 调用每个物体的Shadow Cast Pass，从光源方向生成Shadow Map； Step3: 屏幕空间进行阴影收集（Shadow Collector），即进行深度比较后，得到屏幕空间的阴影贴图； Unity采用了屏幕空间的阴影映射，在进行阴影收集时，是逐Pixel进行的。 Step4: Shading时，用屏幕空间的uv，采样Step3中得到的屏幕空间阴影贴图； b). 阴影映射优化b.1). Self occlusion(自遮挡) Self occlusion： 也被称作Z-Fighting，阴影自遮挡，造成阴影毛刺的现象； 原因： 如上图， Shadow Map分辨率有限，一个像素内记录的深度值相同。如图中红色和橙色斜线表示Shadow Map中深度相同的位置（$Depth_A = Depth_{A’}$）； 当计算平面中$B$点是否在阴影中时，$Depth_{light} = z1 = Depth_A$，而相机视角下的点$B$转换到光源视角下对应的深度为 $z2$ ，即$Depth_{cam} = z2 = Depth_B$ 因此，$Depth_{cam} &gt; Depth_{light}$ ，说明该点在阴影中，因此造成Self occlusion 解决方法： 引入Bias； 认为对于$B$点，如$Depth_{cam} &gt; Depth_{light}$，但$Depth_{light}$ 处于橙色中，那该点仍然不在阴影中； 即： $Depth_{cam} &gt; Depth_{light}+bias$，才使得该点在阴影中； $Depth_{cam} &lt; Depth_{light}+bias$，该点不在阴影中； 易得，当光源方向垂直于平面时，所需的Bias最小，因此可引入光源与平面法线的夹角 $cos\\alpha$ ，来调整Bias大小； 引入bias会造成的问题：Detached shadow(不接触阴影，Peter Panning) b.1.1). 偏移优化（Depth Bias） 深度偏移：简单添加Bias，使得该像素深度（Shading Point的深度，而不是SM中的深度）朝光源靠近； 法线偏移：沿表面法线法线向外偏移； 偏移单位是阴影纹理映射的纹素大小； b.1.2). Unity中的偏移优化 b.2). 走样以信号重建的过程来审视阴影映射： 初始采样：渲染Shadow Map; 重采样：从摄影机视角对Shadow Map重采样； b.2.1). 初始采样 - 透视走样 原因： 由于Shadow Map初始采样是在摄影机进行透视投影之前（左图），使得经过透视投影后，近景大量pixel与Shadow Map中的同一个texel对应造成走样。 解决方法： 在光源位置采样获得Shadow Map之前，我们先做一次透视投影。即采样经过透视投影后的场景； 级联阴影映射（Cascaded Shadow Map），减小近景和远景对应到屏幕空间中像素大小的差异； b.3). 级联阴影映射（Cascaded Shadow Map） 实现：通过平行于视图方向的切片将视锥体截成多个子视锥体，每一个子视锥体都对应一张Shadow Map，每张Shadow Map独立计算但分辨率相同。 如果在View Space也就是视锥体划分级联，一旦镜头转动会产生很严重的闪烁，所以一般划分级联是在光源空间中划分。(https://zhuanlan.zhihu.com/p/92017307) c). PCSS(Percentage-Closer Soft Shadow) c.1). PCF(Percentage Closer Filtering) PCF用于抗锯齿，而不用于软阴影（用于软阴影的叫PCSS，两者实质是一个东西，但应用不同叫法不同） 在生成Shadow Map后，阴影比较时（即对阴影比较的结果），进行Filtering 面光源生成Shadow Map：以面光源的中心点(放置相机)生成shadow map 做法： 不止对着色点与其在Shadow Map中的对应点进行深度比较，而是着色点深度与其在Shadow Map中对应点及其周围点深度进行比较，最后对各个Visibility的结果取平均值（或加权平均） eg1. $P$点在Cam视角下深度为$Depth_p$，转换到光源视角下深度为$Depth_{p’}$，$Depth_{p’}$ 与其在Shadow Map中对应点周围3x3（Filter size）像素进行比较，得到结果 \\begin{array}{l} 1,0,1 \\\\ 1,0,1 \\\\ 1,1,0 \\end{array}取平均得到Visibility为 0.667 Filter size Small -&gt; sharper Large -&gt; softer 为选取合适的Filter size，产生了PCSS c.2). PCSS(Percentage-Closer Soft Shadow)c.2.1). 什么是PCSS？ 关键： 自适应Filter size 观察可得： 钢笔（Blocker）与接收平面（Receiver）的距离越小（笔尖），阴影越硬 钢笔（Blocker）与接收平面（Receiver）的距离越大（笔尖），阴影越软 即阴影的软硬程度，一部分取决于Blocker和Receiver的距离 阴影的软硬取决于 $w_{Light}$ （光源的宽度） $d_{Blocker}$ 与 $d_{BtoR}$ 的比值； Blocker定义： Shading point变换到Light视角，对应深度为$Depth_{scene}$ 。查询区域内，深度值$z &lt; Depth_{scene}$ 的texel即为Blocker； $d_{Blocker}$ 为 Average blocker distance Average blocker distance： Shadow Map一定范围内的Blocker的深度平均值 类似eg1 eg1. $P$点在Cam视角下深度为$Depth_p$，转换到光源视角下深度为$Depth_{p’}$，$Depth_{p’}$ 与其在Shadow Map中对应点周围3x3（Filter size）像素进行比较，得到结果 \\begin{array}{l} 1,0,1 \\\\ 1,0,1 \\\\ 1,1,0 \\end{array}取平均得到Visibility为 0.667 其中，Visibility为0的点，即 处于阴影中，$Depth_{cam} &gt; Depth_{light}+bias$ 的点即为Blocker，对Blocker在Shadow Map中的深度值取平均值，即得到Average blocker distance c.2.2). 做法 首先将shading point点$x$投应到shadow map上,找到其对应的像素点$P$。PCSS算法的实现流程如下： 第一步：Blocker search，即获取某个区域的平均遮挡物深度（在点p附近取一个范围(这个范围是自己定义或动态计算的),将范围内各像素的最小深度与x的实际深度比较,从而判断哪些像素是遮挡物，把所有遮挡物的深度记下来取个平均值作为blocker distance。） 第二步：Penumbra estimation，使用平均遮挡物深度计算滤波核尺寸（用取得的遮挡物深度距离来算在PCF中filtering的范围。） w_{\\text {Penumbra }}=\\left(d_{\\text {Receiver }}-d_{\\text {Blocker }}\\right) \\cdot w_{\\text {Light }} / d_{\\text {Blocker }}第三步：Percentage Closer Filtering，对应该滤波核尺寸应用PCF算法。 如何动态计算Blocker search的“某个范围” Light越远，Region越小；Light越近，Region越大；（好像和图不太对应，如非要对应，就类似与Shadow Map位置不变，Light距离变大/小） 那么PCSS中那些步骤会导致速度变慢？ 第一步：Blocker search，需要多次采样查询深度信息并比较，计算Blocker的平均深度$d_{Blocker}$ 第三步：PCF，阴影越软→滤波核尺寸越大→采样查询次数变多→速度变慢 由此可见，主要是多次采样并比较的方法使得速度变慢； 加速方法： 随机采样，后降噪； 如果觉得区域过大不想对每一个texels都进行比较,就可以通过随机采样其中的texels，而不是全部采样，会得到一个近似的结果,近似的结果就可能会导致出现噪声。工业的处理的方式就是先稀疏采样得到一个有噪声的visibility的图,接着再在图像空间进行降噪。 Variance Soft Shadow Mapping(VSSM) c.2.3). Math V(x)=\\sum_{q \\in \\mathcal{N}(p)} w(p, q) \\cdot \\chi^{+}\\left[D_{\\mathrm{SM}}(q)-D_{\\text {scene }}(x)\\right] 其中$\\chi^{+}$ 类似于$step()$ 函数 $D_{\\mathrm{SM}}(q)-D_{\\text {scene }}(x) \\geq 0$， 即$Depth_{ShadowMap} \\geq Depth_{cam}$，$\\chi^{+}\\left[D_{\\mathrm{SM}}(q)-D_{\\text {scene }}(x)\\right] = 1$ $D_{\\mathrm{SM}}(q)-D_{\\text {scene }}(x) &lt; 0$， 即$Depth_{ShadowMap} &lt; Depth_{cam}$，$\\chi^{+}\\left[D_{\\mathrm{SM}}(q)-D_{\\text {scene }}(x)\\right] = 0$ Homework - 屏幕空间PCSS软阴影 本次实现了屏幕空间的软阴影。其主要步骤如下： 渲染屏幕空间的深度贴图； 从光源方向生成Shadow Map；（下图深度经过EncodeFloatRGBA()，提高精度） 屏幕空间进行阴影收集（Shadow Collector），即进行深度比较后，得到屏幕空间的阴影贴图； Shading时，用屏幕空间的uv，采样Step3中得到的屏幕空间阴影贴图； 至于为什么要使用屏幕空间的软阴影，而不是直接在Shader中实现阴影主要有以下考虑： 屏幕空间的阴影可在一个Pass内完成，管理和调整方便，更贴近实际的应用； 屏幕空间的阴影性能开销小； 方便阴影的后处理； 此方案主要考虑场景阴影，而不考虑角色阴影。 此方案主要有2个C#脚本，3个Shader实现。 C#： DepthTextureCamera.cs: 实现从光源方向生成Shadow Map； ShadowCollector.cs: 屏幕空间进行阴影收集（Shadow Collector） Shader: CustomCaster.shader: 用于渲染深度图； ShadowCollector.shader: 用于逐像素比较深度，并实现具体的PCSS算法； CustromReciver.shader: 用于应用ShadowCollector得到的阴影图片，并通过屏幕空间的坐标进行采样，得到Visibility项； 以下，给出PCSS的主要代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748float findBlocker(float2 UVfromLight, float ZReciver) &#123; // 返回Blocker的平均深度 float num_occ = 0.0f; float Z_avg = 0.0f; float filterSize = 30.0f / _cusShadowMap_TexelSize.z; for (int i = 0; i&lt;BLOCKER_SEARCH_NUM_SAMPLES; i++) &#123; float Z_SM = DecodeFloatRGBA(tex2D(_cusShadowMap, poissonDisk[i]*filterSize + UVfromLight)); if (Z_SM &lt; ZReciver) &#123; num_occ++; Z_avg += Z_SM; &#125; &#125; if (num_occ == 0) &#123; return 1.0; &#125; return Z_avg / num_occ;&#125;float PCSS(float4 coord) &#123; float zReceiver = coord.z / coord.w; float2 uv = coord.xy / coord.w; uv = uv * 0.5 + 0.5;#if defined (SHADER_TARGET_GLSL) //(-1, 1) -&gt; (0, 1) zReceiver = zReceiver * 0.5 + 0.5;#elif defined (UNITY_REVERSED_Z) zReceiver = 1 - zReceiver;#endif poissonDiskSamples(uv); // 泊松圆盘采样 float visibility = 0.0f; float zBlocker = findBlocker(uv, zReceiver); // 计算半影宽度 float wPenumbra = (zReceiver - zBlocker) * LIGHT_WIDTH / zBlocker; float scale = 1.0f; float filterSize = scale * wPenumbra / _cusShadowMap_TexelSize.z + 1.0f / _cusShadowMap_TexelSize.z;; // PCF for (int i = 0; i &lt; PCF_NUM_SAMPLES; i++) &#123; float zNear = DecodeFloatRGBA(tex2D(_cusShadowMap, poissonDisk[i]*filterSize + uv)); if (zNear &gt; zReceiver) &#123; visibility += 1; &#125; &#125; return visibility / PCF_NUM_SAMPLES;&#125;","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"算法","slug":"算法","permalink":"https://whitetail-o.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"阴影","slug":"阴影","permalink":"https://whitetail-o.github.io/tags/%E9%98%B4%E5%BD%B1/"}]},{"title":"HPP_Graphics_3.7 移动端TB(D)R架构基础","slug":"HPP_Graphics_3.7_移动端TB(D)R架构基础","date":"2023-02-15T10:44:32.000Z","updated":"2023-03-17T05:13:36.127Z","comments":true,"path":"2023/02/15/HPP_Graphics_3.7_移动端TB(D)R架构基础/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_3.7_%E7%A7%BB%E5%8A%A8%E7%AB%AFTB(D)R%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/","excerpt":"a). 名词解释System on Chip(Soc) Soc是把CPU、GPU、内存、通信基带、GPS模块等整合在一起的芯片的称呼。常见有A系Soc（苹果），骁龙Soc（高通），麒麟Soc（华为），联发科Soc，猎户座Soc（三星），去年苹果推出的M系Soc，暂用于Mac，但这说明手机、笔记本和PC的通用芯片已经出现了 物理内存 也就是我们常说的手机内存，也叫System Memory。Soc中CPU和GPU共用一块片内LPDDR物理内存。此外CPU和GPU还分别有自己的告诉SRAM的Cache缓存，也叫On-chip Memory。读取System Memory的时间消耗大概是On-chip Memory的几倍到几十倍 On-Chip Buffer在TB(D)R架构下会存储Tile的颜色、深度和模板缓冲，读写修改都非常快。如果Load/Store指令中缓冲需要被Preserve，将会被写入一份到System Memory中。 Stall当GPU两次计算结果之间有依赖关系而必须串行时，等待的过程便是Stall FillRate像素填充率 = ROP运行的时钟频率 x ROP的个数 x 每个时钟ROP可以处理的像素个数 TBR（Tile-Based (Deferred) Rendering）TBR（Tile-Based (Deferred) Rendering）是目前主流的移动GPU渲染架构，对应一般PC上的GPU渲染架构则是IMR（Immediate Mode Rendering ）。 TBR流水线：顶点着色器 - Defer - 光栅化 - 片元着色器 TBDR流水线：顶点着色器 - Defer - 光栅化 - Defer - 片元着色器 Deffer 延迟，从渲染数据的角度来看，就是 ”阻塞+批处理“ GPU ”一帧“ 的多个数据，然后一起处理 b). 立即渲染（IMR，Immediate Mode Rendering ） IMR是PC上GPU采用的架构 c). 基于块元渲染的TB(D)RTB(D)R宏观上总共分为两个阶段： 分图元： 第一阶段执行所有几何相关的处理，并生成Primitive List（图元列表），并且确定每个Tile上面有哪些Primitive 第二阶段逐Tile执行 光栅化后 写入Tile Buffer（片上内存），并在完成后将 Frame BUffer 从 Tile Buffer 写回到 System Memory中；","text":"a). 名词解释System on Chip(Soc) Soc是把CPU、GPU、内存、通信基带、GPS模块等整合在一起的芯片的称呼。常见有A系Soc（苹果），骁龙Soc（高通），麒麟Soc（华为），联发科Soc，猎户座Soc（三星），去年苹果推出的M系Soc，暂用于Mac，但这说明手机、笔记本和PC的通用芯片已经出现了 物理内存 也就是我们常说的手机内存，也叫System Memory。Soc中CPU和GPU共用一块片内LPDDR物理内存。此外CPU和GPU还分别有自己的告诉SRAM的Cache缓存，也叫On-chip Memory。读取System Memory的时间消耗大概是On-chip Memory的几倍到几十倍 On-Chip Buffer在TB(D)R架构下会存储Tile的颜色、深度和模板缓冲，读写修改都非常快。如果Load/Store指令中缓冲需要被Preserve，将会被写入一份到System Memory中。 Stall当GPU两次计算结果之间有依赖关系而必须串行时，等待的过程便是Stall FillRate像素填充率 = ROP运行的时钟频率 x ROP的个数 x 每个时钟ROP可以处理的像素个数 TBR（Tile-Based (Deferred) Rendering）TBR（Tile-Based (Deferred) Rendering）是目前主流的移动GPU渲染架构，对应一般PC上的GPU渲染架构则是IMR（Immediate Mode Rendering ）。 TBR流水线：顶点着色器 - Defer - 光栅化 - 片元着色器 TBDR流水线：顶点着色器 - Defer - 光栅化 - Defer - 片元着色器 Deffer 延迟，从渲染数据的角度来看，就是 ”阻塞+批处理“ GPU ”一帧“ 的多个数据，然后一起处理 b). 立即渲染（IMR，Immediate Mode Rendering ） IMR是PC上GPU采用的架构 c). 基于块元渲染的TB(D)RTB(D)R宏观上总共分为两个阶段： 分图元： 第一阶段执行所有几何相关的处理，并生成Primitive List（图元列表），并且确定每个Tile上面有哪些Primitive 第二阶段逐Tile执行 光栅化后 写入Tile Buffer（片上内存），并在完成后将 Frame BUffer 从 Tile Buffer 写回到 System Memory中； c.1). TBDR Pipeline下图为PowerVR的TBDR： Tilling后将图元列表和顶点数据传到System Memory，待需要光栅化时从System Memory取出。光栅化后进行HSR（因为是PowerVR的流程图所以是HSR）或Depth Test会将结果写入On-chip Buffer。同样，在逐片元操作后，会将Tile的结果写入Tile Buffer，并在完成Frame Buffer后从Tile Buffer写回到System Memory中 下图为三星提出的流程图： c.2). TBR和IMR对比(a)为TBR，(b)为IMR TBR的核心目的是降低带宽，减少功耗，但渲染帧率上并不比IMR快 图（a）TBR架构 几何处理数据形成了FrameData（放在System Memory上） 这些Frame Data经过片段处理，结果放在了Tile Buffer上（片的内存上） 最后的结果会刷到FrameBuffer中（System Memory上） 图（b）IMR架构 对比TBR有以下两种区别 几何处理数据直接到片段处理，没有中间数据（Frame Data） 直接刷到System Memory上了，没有经过片内存（On-Chip Memory） TBR优点： TBR大大减少了Overdraw，PowerVR使用了HSR技术，Mali使用了Forward Pixel Killing技术，目的是为了最大限度减少被遮挡Pixel的Texturing和shading； TBR是Cache friendly，在cache里读写的速度比全局内存的速度要快得多，以降低帧率为代价，降低带宽，省电； TBR缺点： Binning过程在Vertex阶段之后，将输出的集合数据写入到System Memory，然后才被FS读取，集合数据过多的管线，容易在Binning过程产生性能瓶颈； 如一个三角形同时在多个Tile上，需要多次绘制（和Games101RayTracing中空间划分容易造成同一个Object存在多个叶子节点的原因类似）。这意味着总渲染时间高于IMR； d). 第一个Defer：Binning 概念：将图元分配到块元的过程 过程： 注释： 第二幅图里的红色三角形，只用一个块元就能渲染，所以它只会被分配到一个块元中 第四幅图里的棕色三角形，需要多个块元才能渲染，所以它需要分配到9个块元中一起渲染 如果你的项目中binning过程相比其他耗时长的话，就要考虑一下是不是几何数据过多了 e). 第二个Defer：不同GPU 的 Early-Depth-TestForward Pixel Kill Arm Mali 采用Forward Pixel Kill技术 位于管线的位置： 发生在Early-z之后 数据结构： 先进先出的队列 简单概括一下： 队列中有4个Quad（可以理解为2×2像素的平面），每个Quad有屏幕上位置的数据和Z数据 Z越大代表离摄像机越远 根据屏幕上相同位置（pos）的不同z，对不透明的像素进行替换（有近的就不渲染远的），这个过程叫作killed HSR PowerVR的HSR HSR = Hide Surface Removal隐形面剔除 大体实现原理： 虚拟出一个射线，当它遇到第一个不透明的物体时就会停下来，这样就会打断后面三角形的后续ps处理 f). 优化建议 记得在不使用FrameBuffer的时候clear或discard 这样做主要是为了清空积存在tile buffer上的中间数据（前边提到的Frame Data）， 所以对Unity里的rt（render texture）的使用也特别说明一下： 当我们不再使用这个rt的时候，尽量调用一次Discard 在OpenGl ES上，要善用glclear，glInvalidateFrameBuffer，避免不必要的Resolve（tile buff刷新到system memory）行为 不要在一帧里频繁的切换FrameBuffer的绑定 本质：减少tile buffer和system memory之间的stall（同步）操作 对于移动平台，建议使用Alpha混合，而非Alpha测试。 是一个经验性的结论 在实际使用的过程中应该使用比较两者的表现 通常情况下，移动端应该避免使用Alpha混合来实现透明，如果确实要用，尝试缩小混合区域的覆盖范围 手机上必须用Alpha Test时，先做一遍Depth Prepass（参考Alpha Test 的双pass优化思路） 图片尽量压缩 例如ASTC 、ETC2 图片尽量走mipmap 尽量使用从vertex shader传来的Varying变量uv值采样贴图（连续的），不要在Fragment shader里动态计算贴图的uv值（非连续的），否则CacheMiss 在延迟渲染中，尽量利用Tile Buffer（参考传统延迟渲染和TBDR） 如果在Unity中调整ProjectSetting—-Quality—-Rendering—-Texture Quality的不同设置，或者不同分辨率下，帧率有很大的变化，大概率是带宽出问题了 MASS在TBDR下反而是非常快速的 MSAA是硬件上的，发生在片上的 可以看到Tilling后的几何数据存到System Memory后，在Texture and Shade时仍然可以调用，这也为MSAA提供了便利 相比FSAA，MSAA在手机上是非常快的 少在Fragment shader中使用discard函数，调用gl_FragDepth从而打断Early-DT的过程 （hlsl中为Clip，glsl中为discard） 在shader使用浮点数精度值时，有目的的区分使用float，half 优点 带宽减少 GPU中用的周期数减少，因为着色器编译器可以优化你的代码来提高并行化程度 要求的统一变量寄存器的数量减少，这样反而又降低了寄存器数量溢出风险。 具体参考：熊大的优化建议、shader数学计算优化技巧 在移动端的TBDR架构中，顶点处理部分（Binning过程）容易成为瓶颈 避免使用曲面细分shader，置换贴图等负操作 提倡使用模型LOD，（本质上减少Frame Data的压力） Unity中尽早的在应用阶段做umbra（Unity内置）遮挡剔除、gpu的occlusion cull 【补充链接】GPU性能指标 _ 三星的GPU-FrameBuff指导 英伟达的TBR教学文章 ARM的TBR教学文章 苹果OpenGL程序开发指南 OpenGL Insights 知乎文章：Tile-based 和 Full-screen 方式的 Rasterization 相比有什么优劣 移动图形芯片的故事 移动设备GPU架构知识汇总 再议移动平台的AlphaTest效率问题 移动平台GPU硬件学习与理解 PowerVR开发者指南 Performance Tunning for Tile-Based Architecture Tile-Based架构下的性能调校 TBDR的HSR流程细节和使用AlphaBlend的效率提升程度 当我们谈优化时，我们谈些什么 https://edu.uwa4d.com/course-intro/1/179 虽然是收费的 但是很值得买，推荐 Alpha Test的双pass 优化思路 个人收藏 Adreno Hardware Tutorial 3: Tile Based Rendering Mali GPU的独有特性 Mali-T880 《Unity3D内建着色器源码剖析》 作者熊大的优化建议 GPU画像素的顺序是什么 Tile-based Rasterization in Nvidia GPUs with David Kanter of Real World Tech","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"硬件","slug":"硬件","permalink":"https://whitetail-o.github.io/tags/%E7%A1%AC%E4%BB%B6/"},{"name":"移动端","slug":"移动端","permalink":"https://whitetail-o.github.io/tags/%E7%A7%BB%E5%8A%A8%E7%AB%AF/"},{"name":"架构","slug":"架构","permalink":"https://whitetail-o.github.io/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"HPP_Graphics_3.6 纹理压缩","slug":"HPP_Graphics_3.6_纹理压缩","date":"2023-02-15T10:42:32.000Z","updated":"2023-03-17T05:12:06.555Z","comments":true,"path":"2023/02/15/HPP_Graphics_3.6_纹理压缩/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_3.6_%E7%BA%B9%E7%90%86%E5%8E%8B%E7%BC%A9/","excerpt":"a). 纹理压缩简介 纹理压缩是为了解决内存、带宽问题，专为在计算机图形渲染系统中存储纹理而使用的图像压缩技术； a.1). 图片压缩 vs. 纹理压缩（为什么要纹理压缩） 图片格式：JPG、PNG、GIF、BMP等； 纹理压缩格式： ETC、DXT、ASTC等 图片压缩格式大部分都是整体依赖，即不支持像素随机访问（基于整张图片进行压缩，无法直接实现单个像素的解析），且图片压缩格式无法被GPU识别，还需要经CPU解压缩成非压缩纹理格式才能被识别。因此采用基于块压缩的纹理压缩，能够更快读取像素所属字节进行解压缩以支持随机访问。 纹理管线： b). 常见纹理压缩格式","text":"a). 纹理压缩简介 纹理压缩是为了解决内存、带宽问题，专为在计算机图形渲染系统中存储纹理而使用的图像压缩技术； a.1). 图片压缩 vs. 纹理压缩（为什么要纹理压缩） 图片格式：JPG、PNG、GIF、BMP等； 纹理压缩格式： ETC、DXT、ASTC等 图片压缩格式大部分都是整体依赖，即不支持像素随机访问（基于整张图片进行压缩，无法直接实现单个像素的解析），且图片压缩格式无法被GPU识别，还需要经CPU解压缩成非压缩纹理格式才能被识别。因此采用基于块压缩的纹理压缩，能够更快读取像素所属字节进行解压缩以支持随机访问。 纹理管线： b). 常见纹理压缩格式 b.1). DXTCDCTC纹理压缩格式来源于S3公司提出的S3TC算法，基本思想是把4×4的像素块压缩成一个64或128位的数据块，优点为创建了一个固定大小且独立的编码片段，没有共享查找表或其他依赖关系，简化了解码过程； b.1.1). DXT1(BC1)适用于：不包含透明信息RGB、只包含1位透明信息的贴图（即透明或完全不透明） 对与不包含透明信息的RGB 每一块具有两个16位RGB颜色值（RGB565）$color_a、color_b$，代表了此4x4像素块中颜色极端值，然后通过线性插值计算出两个中间颜色值，16个2位索引值则表示每一个像素的颜色值索引。 所以，对与4x4的像素块： 2x16 RGB颜色值（RGB565） 16x2 颜色索引值（索引2个颜色极端值+2个插值得到的中间值） 对与包含1位透明信息的纹理 通过$color_a、color_b$ 插值出一个颜色中间值 $color_c$ ，并用 $color_d$ 表示透明/不透明，其每个像素通过2位索引这四个颜色 压缩率：6:1 b.1.2). DXT2/DXT3 (BC2)DXT2/3与DXT1类似，表示颜色信息的64位数据块不变，另外附加了64位数据来表示每个像素的Alpha信息，整个数据块变为了128位；； 每个像素占用8位，0-3表示透明信息，4-7表示颜色信息； b.1.3). DXT4/DXT5 (BC3)DXT4/5与DXT2/3的差异在于其Alpha信息是通过线性插值所得的，表示颜色信息的64位数据块依然不变，而Alpha信息则由2个8位Alpha极端值和16个3位索引值组成； DXT5和DXT3分别计算RGB和A再混合，而DXT4和DXT2先混合RGBA，若A改变也不再重新混合而是直接改变整体颜色 b.1.4). DXTnmUnity内贴图类型选为法线后会采用DXTnm压缩格式，该格式会把法线贴图R通道存入A通道，然后RB通道清除为1，这样可以将法线XY信息分别存入到RGB/A中分别压缩，以获得更高的精度，然后再根据XY构建出Z通道数据； 即将法线贴图RGBA变为AG通道； b.2). ATI1/2b.2.1). ATI1(BC4, 4x4 4位)ATI1为ATI公司开发的纹理压缩格式，也被称为BC4，其每个数据块存储单个颜色的数据通道，以与DXT5中的Alpha数据相同的方式进行编码，常用于存储高度图、光滑度贴图，效果与原始图像基本无差异； 压缩比：2:1 b.2.2). ATI2(BC5, 4x4 8位)每一个块中存储两个颜色通道的数据，同上以与DXT5中Alpha数据相同的方式进行编码，相当于存储了两个BC4块； 压缩比：2:1 如果是在将法线存储在XY双通道中采用BC5格式压缩，由于每个通道都有自己的索引，因此法线贴图XY信息可以比在BC1中保留更多的保真度，缺点是需要使用两倍内存，也需要更多的带宽才能将纹理传递到着色器中； b.3). BC6/7BC6和BC7仅在D3D11级图形硬件中受支持，他们每个块占用16字节，BC7针对8位RGB或RGBA数据，而BC6针对RGB半精度浮点数据，因此BC6是唯一一个可以原生存储HDR的BC格式； BC6是专门针对HDR（高动态范围）图像设计的压缩算法，压缩比为6：1； BC7是专门针对LDR（低动态范围）图像设计的压缩算法，压缩比为3：1，该格式用于高质量的RGBA压缩，可以显著减少由于压缩法线带来的错误效果，但这也意味着解码所带来更多的消耗； b.4). ETCETC（Ericsson Texture Compression）最初为移动设备开发，如今它是安卓的标准压缩方案，ETC1在OpenGL和OpenGL ES中都有支持。 将4x4 的像素块编码为2x4或4x2像素（64位）的两个块的方法，每个块指定一个基色，每个像素的颜色通过一个编码为相对于这些基色偏移的灰度值确定。 具体来说，ETC1每4x4像素块编码为64位的字节数据，每一个像素块又分为两个2x4子块（由一个“flip”位控制水平或竖直划分），每个子块包含一个3位的修饰表索引（modifier table index）和一个基本颜色值，这两个颜色值要么是2*R4G4B4要么是R5G5B5+R3G3B3（由一个“ diff”位控制是哪一种）。 24位颜色块（RGB444x2 或 RGB333+RGB555） 2x4位亮度索引中 2x3位用于修饰表索引（索引table中列数） 2x1位用于flip或diff（如左边块为flip，右边块为diff） 每个像素中2位像素索引，索引对应列中行数 ETC2是ETC1的扩展，支持了Alpha通道的压缩，硬件要求OpenGL ES 3.0和OpenGL 4.3以上； b.5). ASTCASTC是由ARM和AMD联合开发的纹理压缩格式，ASTC在各项指标上都挺不错，优点是可根据不同图片选择不同压缩率的算法，图片不需要为2的幂次，同时支持LDR和HDR，缺点是兼容性不够完善且解码时间较长； ASTC也是基于块的压缩算法，与BC7类似，其数据块大小固定为128位，不同的是块中的像素数量可变，从4×4到12×12像素都有； 每一个数据块中存储了两个插值端点，但不一定存储的是颜色信息，也可能是Layer信息，这样可以用来对Normal或Alpha进行更好的压缩； 对于块中每一个纹素，存储其对应插值端点的权重，存储的权重数量可以少于纹素数量，可通过插值得到每一个纹素的权重值，然后再进行颜色的计算； 11位：权重、高度信息，特殊块标识； 2位：Part数量； 4位：16种插值端点模式（如LDR/HDR，RGB/RGBA）； 111位：插值端点信息，纹素权重值，配置信息； b.6). PVRTCPVRTC由Imagination公司专为PowerVR显卡设计，仅支持Iphone、Ipad和部分安卓机； 不同于DXTC和ETC这类基于块的算法，PVRTC将图像分为了低频信号和高频信号，低频信号由两张低分辨率图像AB组成，高频信号则是低精度的调制图像，记录了每个像素混合的权重，解码时AB图像经过双线性插值放大，然后根据调制图像的权重进行混合； PVRTC 4-bpp(bit per pixel)把一个4×4的像素单元压成一个64位数据块，每一个块中存储一个32位的调制数据，一个1位的调制标志，15位的颜色$color_a$，1位颜色A不透明标志，14位颜色$color_b$，1位颜色B不透明标志； 15+14位：储存RGB时，$color_a$ 是 RGB555，$color_b$ 是 RGB554 ​ 储存RGBA时，$color_a$ 是 RGBA4443，$color_b$ 是 RGBA4433 16x2位：每个像素2位调制数据 1位：调制模式，0/1位不同模式得到两颜色的Alpha值（混合值） 1+1位不透明标志：决定使用RGB/RGBA储存模式（$a1 || a2$, 哪个高选哪个） 而PVRTC 2-bpp则是把一个8×4的像素单元压成了64位数据块； c). 对比 画质比较（参考） RGBA &gt; ASTC 4×4 &gt; ASTC 6×6 &gt; ETC2 ≈ ETC1 压缩比 d). 格式使用建议PC： 低质量使用DXT1格式不支持A通道，使用DXT5格式支持A通道； 高质量使用BC7格式，支持A通道； 安卓： 低质量使用ETC1格式，但不支持A通道； 低质量使用ETC2格式，支持A通道，需要在OpenGL ES 3.0/OpenGL 4.3以上版本； 高质量使用ASTC格式，需要在Android 5.0/OpenGL ES 3.1以上版本； IOS： 高质量使用ASTC格式，需要iPhone6以上版本； 低质量使用PVRTC2格式，支持iPhone6以下版本； 【补充链接】https://docs.unity3d.com/cn/current/Manual/class-TextureImporterOverride.html","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"优化","slug":"优化","permalink":"https://whitetail-o.github.io/tags/%E4%BC%98%E5%8C%96/"},{"name":"纹理","slug":"纹理","permalink":"https://whitetail-o.github.io/tags/%E7%BA%B9%E7%90%86/"}]},{"title":"HPP_Graphics_3.4 前向渲染与延迟渲染","slug":"HPP_Graphics_3.4_延迟渲染管线","date":"2023-02-15T10:40:32.000Z","updated":"2023-03-17T05:09:23.488Z","comments":true,"path":"2023/02/15/HPP_Graphics_3.4_延迟渲染管线/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_3.4_%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/","excerpt":"a). 渲染路径 决定光照的实现方式。简言之，就是当前渲染目标使用光照的流程。 b). 渲染方式 延迟渲染 前向渲染 可以看到前向渲染中，中间蓝色的灯并没被渲染。（场景8盏灯，Project Setting中Pixel Light Count设为7） b.1). 前向/正向渲染-Forward Rendering 简介：每个Object对每个光照都计算； b.1.1). 流程 简单来说就是不管光源的影响大不大，计算的时候都会把所有光源计算进去，这样就会造成一个很大的浪费 b.1.2). 规则和注意事项 发生在顶点处理阶段，会计算所有顶点的光照。全平台支持 规则1：最亮的几个光源会被实现为像素光照 规则2：然后就是，最多四个光源会被实现为顶点光照 规则3：剩下的光源会实现为效率较高的球面调谐光照（Spherical Hamanic），这是一种模拟光照 补充说明 最亮的那盏光一定是像素光照 Light的Render Mode是important的光一定是像素光照 如果前面的两条加起来的像素光照小于Quality Setting里的Pixel Light Count（最大像素光照数量），那么从剩下的光源中找出最亮的那几盏光源，实现为像素光照。 最后剩下的光源，按照规则2或3。 在base pass里执行一盏像素光、所有的顶点光和球面调谐光照，并且进行阴影计算。 其余的像素光每盏一个Additional Pass，并且这些pass里没有阴影计算。 场景中看到的阴影，全是base pass里计算出最亮那盏像素光的阴影，其他像素光是不计算阴影的。 最多的光源数是可以更改的 以Unity中的为例，在project setting中 b.2). 延迟渲染（Deferred Rendering）b.2.1). 简介主要解决大量光照渲染的方案。 可以将延迟渲染(Deferred Rendering)理解为先将所有物体都先绘制到屏幕空间的缓冲（即G-buffer，Geometric Buffer，几何缓冲区）中，再逐光源对该缓冲进行着色的过程，从而避免了因计算被深度测试丢弃的片元的着色而产生的不必要的开销。也就是说延迟渲染基本思想是，先执行深度测试（应该也包括其他测试），再进行着色计算，将本来在物空间（三维空间）进行光照计算放到了像空间（二维空间）进行处理。 对应于正向渲染O(m*n)的 复杂度，经典的延迟渲染复杂度为O(n+m)。","text":"a). 渲染路径 决定光照的实现方式。简言之，就是当前渲染目标使用光照的流程。 b). 渲染方式 延迟渲染 前向渲染 可以看到前向渲染中，中间蓝色的灯并没被渲染。（场景8盏灯，Project Setting中Pixel Light Count设为7） b.1). 前向/正向渲染-Forward Rendering 简介：每个Object对每个光照都计算； b.1.1). 流程 简单来说就是不管光源的影响大不大，计算的时候都会把所有光源计算进去，这样就会造成一个很大的浪费 b.1.2). 规则和注意事项 发生在顶点处理阶段，会计算所有顶点的光照。全平台支持 规则1：最亮的几个光源会被实现为像素光照 规则2：然后就是，最多四个光源会被实现为顶点光照 规则3：剩下的光源会实现为效率较高的球面调谐光照（Spherical Hamanic），这是一种模拟光照 补充说明 最亮的那盏光一定是像素光照 Light的Render Mode是important的光一定是像素光照 如果前面的两条加起来的像素光照小于Quality Setting里的Pixel Light Count（最大像素光照数量），那么从剩下的光源中找出最亮的那几盏光源，实现为像素光照。 最后剩下的光源，按照规则2或3。 在base pass里执行一盏像素光、所有的顶点光和球面调谐光照，并且进行阴影计算。 其余的像素光每盏一个Additional Pass，并且这些pass里没有阴影计算。 场景中看到的阴影，全是base pass里计算出最亮那盏像素光的阴影，其他像素光是不计算阴影的。 最多的光源数是可以更改的 以Unity中的为例，在project setting中 b.2). 延迟渲染（Deferred Rendering）b.2.1). 简介主要解决大量光照渲染的方案。 可以将延迟渲染(Deferred Rendering)理解为先将所有物体都先绘制到屏幕空间的缓冲（即G-buffer，Geometric Buffer，几何缓冲区）中，再逐光源对该缓冲进行着色的过程，从而避免了因计算被深度测试丢弃的片元的着色而产生的不必要的开销。也就是说延迟渲染基本思想是，先执行深度测试（应该也包括其他测试），再进行着色计算，将本来在物空间（三维空间）进行光照计算放到了像空间（二维空间）进行处理。 对应于正向渲染O(m*n)的 复杂度，经典的延迟渲染复杂度为O(n+m)。 b.2.2). 流程 可以将延迟渲染理解为两个Pass的过程： 几何处理阶段(Geometry Pass)。这个阶段中，我们获取对象的各种几何信息（Position、Normal、Albedo、Specular等），并将第二步所需的各种数据储存（也就是渲染）到多个G-buffer中； 由于有深度测试，所以最终写入G-buffer中的，都是离摄像机最近的片元的集合属性，这就意味着，在G-buffer中的片元必定要进行光照计算。 光照处理阶段(Lighting Pass)。在这个pass中，我们只需渲染出一个屏幕大小的二维矩形，使用第一步在G-buffer中存储的数据对此矩阵的每一个片段计算场景的光照；光照计算的过程还是和正向渲染以前一样，只是现在我们需要从对应的G-buffer而不是顶点着色器(和一些uniform变量)那里获取输入变量了。 b.2.3). G-BufferG-Buffer，全称Geometric Buffer ，译作几何缓冲区，它主要用于存储每个像素对应的位置（Position），法线（Normal），漫反射颜色（Diffuse Color）以及其他有用材质参数。根据这些信息，就可以在像空间（二维空间）中对每个像素进行光照处理。 如图为一个典型的G-buffer 下图是一帧中G-buffer中存储的内容： UE5中的G-Buffer 在几何处理阶段中填充G-buffer非常高效，因为我们直接储存位置，颜色，法线等对象信息到帧缓冲中，这个过程几乎不消耗处理时间。 而在此基础上使用多渲染目标(Multiple Render Targets, MRT)技术，我们可以在一个Pass之内完成所有渲染工作。 P-Code 1234For each object: Render to multiple targets For each light: Apply light as a 2D postprocess 12345678Two-pass deferred shading algorithmPass 1: geometry pass- Write visible geometry information to G-bufferPass 2: shading passFor each G-buffer sample, compute shading- Read G-buffer data for current sample- Accumulate contribution of all lights- Output final surface color b.2.4). 延迟渲染的优缺点 优点： 复杂度仅O(n+m) 只渲染可见的像素，节省计算量 用更少的shader 对后处理支持良好（例如深度信息：直接拿G-buffer中的就行。而前向渲染需要单独Pass再渲染一张深度图） 在大量光源的场景优势尤其明显； 缺点： 内存开销较大，且占用了大量的显存带宽； 需要传递G-Buffer； 有时需要用到G-Buffer的信息，如深度图做后处理，那将不会进行Clear； 只能用同一套Lighting Pass； 对透明物体的渲染存在问题。在这点上需要结合正向渲染进行渲染； 对多重采样抗锯齿（MultiSampling Anti-Aliasing, MSAA）等硬件抗锯齿的支持不友好，主要因为需开启MRT； MSAA是依赖于子像素，而Deffered shading处在光栅化之后（单个像素内值相等），传输数据是通过G-Buffer； 但可使用TAA 问FXAA、FSAA与MSAA有什么区别？效果和性能上哪个好？ - 文刀秋二的回答 - 知乎 https://catlikecoding.com/unity/tutorials/rendering/part-13/ b.3). Unity中渲染路径设置 b.4). 其他渲染路径针对延迟渲染上述提到的缺点，下面简单列举一些降低 Deferred Rendering 存取带宽的改进方案。最简单也是最容易想到的就是将存取的 G-Buffer 数据结构最小化，这也就衍生出了 Light Pre-Pass（即Deferred Lighting） 方法。另一种方式是将多个光照组成一组，然后一起处理，这种方法衍生了 Tile-Based Deferred Rendering。 也就是说，常见的两种Deferred Rendering的改进是： 延迟光照 Light Pre-Pass（即Deferred Lighting） 分块延迟渲染 Tile-BasedDeferred Rendering b.4.1). 延迟光照（LightPre-Pass / Deferred Lighting） 减少G-buffer占用的过多开销，支持多种光照模型 过程： 渲染场景中不透明（opaque ）的几何体。将法线向量n和镜面扩展因子（specular spread factor）m 写入缓冲区。这个n/m-buffer 缓冲区是一个类似 G-Buffer的缓冲区，但包含的信息更少，更轻量，适合于单个输出颜色缓冲区，因此不需要MRT支持。 渲染光照。计算漫反射和镜面着色方程，并将结果写入不同的漫反射和镜面反射累积缓冲区。这个过程可以在一个单独的pass中完成（使用MRT），或者用两个单独的pass。环境光照明可以在这个阶段使用一个 full-screen pass进行计算。 对场景中的不透明几何体进行第二次渲染。从纹理中读取漫反射和镜面反射值，对前面步骤中漫反射和镜面反射累积缓冲区的值进行调制，并将最终结果写入最终的颜色缓冲区。若在上一阶段没有处理环境光照明，则在此阶段应用环境光照明。 使用非延迟着色方法渲染半透明几何体。 用更少的buffe信息，着色计算的时候用的是forward，所以第三步开始都是前向渲染（在3D，而不是2D的像空间中渲染） b.4.2). Forward+（即Tiled Forward Rendering，分块正向渲染） 减少带宽，支持多光源，强制需要一个preZ 通过分块索引的方式，以及深度和法线信息来到需要进行光照计算的片元进行光照计算。 需要法线和深度的后处理需要单独渲染一个rt出来 强制使用了一个preZ（如果没涉及过这个概念的话，可以理解为进行了一个深度预计算 https://zhuanlan.zhihu.com/p/28489928 b.4.3). 群组渲染（Clustered Rendering） 带宽相对减少，多光源下效率提升 分为forward和deferred两种 详细补充拓展：https://zhuanlan.zhihu.com/p/54694743 c). 渲染管线的优化（移动端）IMR框架渲染对于移动端有一个很大的问题：带宽占用过高。 因此在移动端，我们不采用PC端构架IMR（Immediate Mode Rendering），而采用移动端构架TBR（Tile-Based Rendering）或TBDR（PowerVR使用） 简而言之，为了节省成本，移动端TBR的GPU中不使用显存（GPU Memory），而使用On_Chip Memory也就是SRAM，或者L1 L2 cache 对于TBR来讲，整个光栅化和像素处理会被分为一个个Tile进行处理，通常为16×16大小的Tile。TBR的结构通过On-Chip Buffers来储存Tiling后的Depth Buffer和Color buffer。 也就是原先IMR架构中对主存中Color/Depth Buffer进行的读写操作变成直接在GPU中的高速内存操作，减少了最影响性能的系统内存传输的开销。通过下面这张图能够更好的来理解，下图的DRAM在手机上就是物理内存那一块。 ​ d). 移动设备渲染通用优化建议 贴图格式能压缩就压缩。贴图内存越小，片上命中率就越高，总的传输量也少 能开mipmap就开mipmap（前提是能用到，UI贴图就不用开了）。减轻带宽压力，与减小实际使用的贴图内存是一个道理，但是会增加总贴图的内存占用大小，需要在内存开销和带宽开销上做一个平衡。 随机纹理寻址相对于相邻纹理寻址有显著开销。提高片上命中率。 3DTexture Sampling有显著的开销。3DTexture整体内存占用大，垂直方向相邻像素内存不相邻很容易cache miss，这是我个人推测。 Trilinear/Anisotropic相对于Bilinear有显著的开销。Trilinear其实就相当于tex3D了(此结论不负责任)，Bilinear相对于Point几乎没有额外开销（此结论负责任，texture fetch都是一次拿相邻的四个出来），所以Bilinear能忍就尽量凑合用着吧。 使用LUT（look up texture）很可能是负优化。需要对比权衡带宽占用+texture fetch操作增加与ALU占用增加降低并行效率，另外还很可能涉及到美术工作流和最终效果，所以是个不是很好进行操作的优化。之前看过腾讯的技术分享将引擎中Tonemapping那步的3DLUT（UE4和Unity都是这样的）替换为函数拟合的优化，理论上应该是会提升不少性能，但是要想真正应用到生产环境，保证效果，还要做好拟合工具链，是得费不少力气的 通道图能合并就合并，减少Shader中贴图采样次数。这个不多说了 控制Framebuffer大小。这个也不多说了 总顶点数量也是带宽开销的影响因素。虽然以现在GPU的计算能力来说，顶点数增多产生的VS计算开销增加通常是忽略不计的。但是仍不能忽略总顶点数量对于VertexBuffer所消耗带宽的影响，对于总顶点数的限制应该更多的从带宽消耗上去进行测试和分析。 d.1). AlphaTest性能消耗 只要Shader中包含discard指令的都会被GPU认为是AlphaTest图元（GPU对于AlphaTest绘制流程的判定是基于图元而不是像素） 无论是PowerVR还是Mali/Adreno芯片，AlphaTest图元的绘制都会影响整体渲染性能。 随着芯片的发展AlphaTest图元对于渲染性能的影响主要在于Overdraw增加而非降低硬件设计流程效率，其优化思路与AlphaBlend一样，就是少画！ 严格按照Opaque - AlphaTest - AlphaBlend的顺序进行渲染可以最大化减小AlphaTest对于渲染性能的影响。 将Opaque, AlphaTest与AlphaBlend打乱顺序渲染会极大的降低渲染性能，任何情况下都不应该这么做。 不要尝试使用AlphaTest替代AlphaBlend，这并不会产生太多优化。 不要尝试使用AlphaTest替代Opaque，这会产生负优化 不要尝试使用AlphaBlend替代AlphaTest，这会造成错误的渲染结果。 在保证正确渲染顺序情况下，AlphaTest与AlphaBlend开销相似，不存在任何替代优化关系 增加少量顶点以减少AlphaTest图元的绘制面积是可以提升一些渲染性能的。 首先统一绘制AlphaTest图元的DepthPrepass，再以ZTest Equal和不含discard指令的Shader统一绘制AlphaTest图元，大多数情况下是可以显著提升总体渲染性能的（需要实际测试） 资料补充：https://zhuanlan.zhihu.com/p/259760974 https://www.cnblogs.com/timlly/p/11471507.html https://zhuanlan.zhihu.com/p/112120206","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"延迟渲染","slug":"延迟渲染","permalink":"https://whitetail-o.github.io/tags/%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93/"},{"name":"渲染管线","slug":"渲染管线","permalink":"https://whitetail-o.github.io/tags/%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/"}]},{"title":"HPP_Graphics_3.5 Early-Z和Z Prepass（Pre-Z）","slug":"HPP_Graphics_3.5_Early-z和Z-prepass","date":"2023-02-15T10:40:32.000Z","updated":"2023-03-17T05:10:35.950Z","comments":true,"path":"2023/02/15/HPP_Graphics_3.5_Early-z和Z-prepass/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_3.5_Early-z%E5%92%8CZ-prepass/","excerpt":"a). Review Z-test 先回顾下深度测试 问题： 被遮挡的物体也会进行shading，造成overdraw； 解决思路： 在shading前提前剔除被遮挡的片元； b). Early-Z 是在传统管线中的光栅化阶段之后、片元着色器之前加的一步操作。 提前的深度测试叫作Z-Cull 后续的深度测试为了确定正确的遮挡关系，叫作Z-Check Early-Z同样可以搭配使用模板测试 b.1). Early-Z失效情况 开启Alpha Test或 clip/discard等手动丢弃片元操作 通常Early-Z不仅会进行深度测试，还要进行深度写入 那在这种情况下，如果经过AlphaTest，前面渲染的片元被丢弃了（但写入了深度），那么后续的像素都将无法正常渲染。 手动修改GPU插值得到的深度 开启Alpha Blend 关闭深度测试Depth Test b.2). Early-Z排序不透明物体由远往近渲染，early-z将没有任何优化效果 在渲染前，将不透明物体从近往远渲染的话，Early-Z能发挥最大的性能优化（注意此处还是前向渲染的思路） 具体怎么排序？ 可以让CPU将物体按照由近到远的顺序排好，再交付给GPU进行渲染 问题： 复杂的场景，CPU性能消耗很大 严格按照由近到远的顺序渲染，将不能同时搭配批处理优化手段。 解决方法：Pre-Z / Z Prepass","text":"a). Review Z-test 先回顾下深度测试 问题： 被遮挡的物体也会进行shading，造成overdraw； 解决思路： 在shading前提前剔除被遮挡的片元； b). Early-Z 是在传统管线中的光栅化阶段之后、片元着色器之前加的一步操作。 提前的深度测试叫作Z-Cull 后续的深度测试为了确定正确的遮挡关系，叫作Z-Check Early-Z同样可以搭配使用模板测试 b.1). Early-Z失效情况 开启Alpha Test或 clip/discard等手动丢弃片元操作 通常Early-Z不仅会进行深度测试，还要进行深度写入 那在这种情况下，如果经过AlphaTest，前面渲染的片元被丢弃了（但写入了深度），那么后续的像素都将无法正常渲染。 手动修改GPU插值得到的深度 开启Alpha Blend 关闭深度测试Depth Test b.2). Early-Z排序不透明物体由远往近渲染，early-z将没有任何优化效果 在渲染前，将不透明物体从近往远渲染的话，Early-Z能发挥最大的性能优化（注意此处还是前向渲染的思路） 具体怎么排序？ 可以让CPU将物体按照由近到远的顺序排好，再交付给GPU进行渲染 问题： 复杂的场景，CPU性能消耗很大 严格按照由近到远的顺序渲染，将不能同时搭配批处理优化手段。 解决方法：Pre-Z / Z Prepass c). Pre-Z 用于解决使用early-Z可能造成的Overdraw问题（用Drawcall或Set Pass Call的消耗换取减少Overdraw，因此使用时需要进行权衡） Method1: 双Pass使用两个Pass： 第一个Pass（Z-Prepass）：仅写入深度； 第二个Pass：关闭深度写入，并将深度测试比较符改为等于； 造成问题： 在Unity中，无法动态批处理（多Pass的Shader无法进行动态批处理） 增多DrawCall； 因此，我们可以提前分离Prepass，以便其可以进行动态批处理，减少Set pass call Method2: 提前分离的Prepass 将Z-Prepass分离出一个shader，用这个shader将场景中不透明物体先渲染一遍； 而原先材质只剩下原先的第二个Pass，仍然关闭深度写入，并且将深度比较函数设置为相等。 URP以后并不是所有Pass都会执行，因为它预制了两个Pass所以，优先执行”UniversalForward”在执行”SrpDefaultUnlit”的Pass …… Link: https://www.xuanyusong.com/archives/4759 半透明渲染Pre-Z也是半透明物体渲染的解决方案； Z-prepass的其他问题1.Z-prepass的性能消耗是否能被忽视 国外论坛一位名为lipsryme的老哥做了一项实验： 可以看到，Z-prepass的消耗为2.0ms，而带来的优化只减少了0.3ms（2.7-2.4） 后续讨论中，发现Z-prepass是需要根据项目的实际情况来决定是否采用的。 总结有以下建议 当一个有非常多OverDraw的场景，且不能很好的将不透明物体从前往后进行排序时，可以考虑使用PreZ进行优化 注意，PreZ会增加DrawCall，如果用错了可能是负优化 d). Early-Z 和 Z-Prepass的实例应用d.1). 面片叠加的头发渲染 对于半透明的面片来说，需要从后往前进行排序渲染才能得到正确的透明度混合结果 排序后头发的渲染 分为3个pass pass1 处理不透明部分，开启Alpha test透明度测试，仅通过不透明的像素， 关闭背面剔除 开启深度写入 pass2 剔除正面，渲染背面 pass3 剔除背面，渲染正面 问题：会带来非常多OverDraw的问题 解决方法：Pre-Z 使用Early-Z剔除 透明度测试开启时Early-Z无法使用的解决方案：使用Z-Prepass 使用一个简单的shader进行Alpha Test生成Z-Buffer 改善后的渲染方案： 不透明物体 Pass1 - PreZ： 开启透明度测试 关闭背面剔除 开启深度写入，深度测试设置为Less 关闭颜色缓冲区写入 用于一个简单的片元着色器来返回透明度值 Pass2： 关闭背面剔除 关闭深度写入，深度测试设置为Equal 半透明物体 Pass3： 剔除正面 关闭深度写入，对背面进行深度测试，设置为Less Pass4： 剔除背面 关闭深度写入，对正面进行深度测试，设置为Less https://www.cnblogs.com/ghl_carmack/p/10166291.html Homework","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"延迟渲染","slug":"延迟渲染","permalink":"https://whitetail-o.github.io/tags/%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93/"},{"name":"渲染管线","slug":"渲染管线","permalink":"https://whitetail-o.github.io/tags/%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/"}]},{"title":"HPP_Graphics_2.7 模板测试和深度测试","slug":"HPP_Graphics_3.1_模板测试和深度测试","date":"2023-02-15T09:40:32.000Z","updated":"2023-03-17T05:16:04.931Z","comments":true,"path":"2023/02/15/HPP_Graphics_3.1_模板测试和深度测试/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_3.1_%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/","excerpt":"a). 模板测试 处于逐片元操作中 a.1). Unity 中的模板测试 语法表示 可作为遮罩等操作","text":"a). 模板测试 处于逐片元操作中 a.1). Unity 中的模板测试 语法表示 可作为遮罩等操作 a.2). 作业：Unity中实现的效果 【链接补充】 [1]. https://blog.csdn.net/u011047171/article/details/46928463 [2]. https://blog.csdn.net/liu_if_else/article/details/86316361 [3]. https://gameinstitute.qq.com/community/detail/127404 [4]. https://learnopenglcn.readthedocs.io/zh/latest/04%20Advanced%20OpenGL/02%20Stencil%20testing/ [5]. https://www.patreon.com/posts/14832618 [6]. https://www.udemy.com/course/unity-shaders/ b). 深度测试 模板测试后，透明度混合前 Z-Buffer Z Write深度写入包括两种状态：ZWrite On 与 ZWrite Off 当我们开启深度写入的时候，物体被渲染时针对物体在屏幕（更准确地说是frame buffer）上每个像素的深度都写入到深度缓冲区；反之，如果是ZWrite Off,那么物体的深度就不会写入深度缓冲区。但是，物体是否会写入深度，除了ZWrite这个状态之外，更重要的是需要深度测试通过，也就是ZTest通过，如果ZTest都没通过，那么也就不会写入深度了。 ZTest分为通过和不通过两种情况，ZWrite分为开启和关闭两种情况的四种情况： 深度测试通过，深度写入开启：写入深度缓冲区，写入颜色缓冲区。 深度测试通过，深度写入关闭：不写深度缓冲区，写入颜色缓冲区。 深度测试失败，深度写入开启：不写深度缓冲区，不写颜色缓冲区。 深度测试失败，深度写入关闭：不写深度缓冲区，不屑颜色缓冲区。 Z Test比较操作 渲染队列Unity中内置的几种渲染队列，按照渲染顺序，从先到后进行排序，队列数越小，越先渲染，队列数越大，越后渲染。 Background(1000) ：最早被渲染的物体的队列。 Geometry(2000) ：不透明物体的渲染队列。大多数物体都应该使用该队列进行渲染，也是Unity Shader中默认的渲染队列。 AlphaTest(2450) ：有透明通道，需要进行Alpha Test的物体的队列，比在Geometry中更有效。 Transparent(3000) ： 半透物体的渲染队列。一般是不写深度的物体，Alpha Blend等的在该队列渲染。 Overlay(4000) ：最后被渲染的物体的队列，一般是覆盖效果，比如镜头光晕，屏幕贴片之类的。 Unity中设置渲染队列1234//默认是GeometryTags&#123; &quot;Queue&quot; = &quot;Transparent&quot;&#125; 不透明物体的渲染顺序：从前往后。 透明物体的渲染顺序：从后往前。（OverDraw） 对于使用了多个Pass的物体，其渲染队列会设置为Pass中的最小值（如两个Pass中一个是Geometry(2000)，另一个是Transparent(3000)，那该物体会按Geometry的队列渲染，然后按Shader中从上到下执行Pass）。 Early-Z传统的渲染管线中，ZTest其实是在Blending阶段，这时候进行深度测试，所有对象的像素着色器都会计算一遍，没有什么性能提升，仅仅是为了得出正确的遮挡结果，会造成大量的无用计算，因为每个像素点上肯定重叠了很多计算。因此现代GPU中运用了Early-Z的技术，在Vertex阶段和Fragment阶段之间（光栅化之后，fragment之前）进行一次深度测试，如果深度测试失败，就不必进行fragment阶段的计算了，因此在性能上会有很大的提升。但是最终的ZTest仍然需要进行，以保证最终的遮挡关系结果正确。前面的一次主要是Z-Cull为了裁剪以达到优化的目的，后一次主要是Z-Check，为了检查，如下图： c). 深度值 为什么深度缓冲区存储非线性深度呢？正确的投影特性的非线性深度方程是和1/z成正比的，这样基本上做的是在Z很近的时候是高精度和Z很远的时候是底精度。这样就是模拟了人眼观察，近处的物体很清晰，而远处的物体很模糊。（和现在还用伽马校正的原因类似） F d e p t h=\\frac{1 / z-1 / \\text { near }}{1 / \\text { far }-1 / \\text { near }}Z-fighting两个平面或三角形很紧密相互平行，深度缓冲区不具有足够的精度以至于无法得到哪一个靠前。导致了着两个形状不断切换顺序出现怪异问题。这被称为深度冲突（Z-fighting），因为它看上去像形状争夺顶靠前的位置。（UE中重叠闪来闪去的那个） 解决方法 让物体之间不要离得太近。 尽可能把近平面设置得远一些。 放弃一部分性能来获得更高精度的深度值。 Z-Offset","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"模板测试","slug":"模板测试","permalink":"https://whitetail-o.github.io/tags/%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95/"},{"name":"深度测试","slug":"深度测试","permalink":"https://whitetail-o.github.io/tags/%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/"}]},{"title":"HPP_Graphics_3.3 曲面细分和几何着色器","slug":"HPP_Graphics_3.3_TessAndGs","date":"2023-02-15T09:40:32.000Z","updated":"2023-03-17T05:15:54.313Z","comments":true,"path":"2023/02/15/HPP_Graphics_3.3_TessAndGs/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_3.3_TessAndGs/","excerpt":"一、两者的应用列举1-1.曲面着色器的应用①海浪、雪地等 如右图一样，将一条直线进行细分，向一条曲线慢慢逼近 ②著名的应用：和置换贴图（DIsplacement mapping，也叫位移贴图）结合使用 使用普通法线的模型，在边缘部分的凹凸感会不理想 如果使用置换贴图，因为它是真正改变物体的形状，所以边缘部分的凹凸感就会很真实 注意：使用置换贴图，对模型的面数有要求。 正是这个原因，让它和曲面细分着色器有着很好的契合度。 ③雪地里出现的脚印 可以用曲面细分着色器进行优化 1-2.为什么不用复杂的模型，而要用曲面细分着色器？ 曲面细分着色器可以根据距离/一些规则，动态的调整模型的复杂度，带来更好的性能。","text":"一、两者的应用列举1-1.曲面着色器的应用①海浪、雪地等 如右图一样，将一条直线进行细分，向一条曲线慢慢逼近 ②著名的应用：和置换贴图（DIsplacement mapping，也叫位移贴图）结合使用 使用普通法线的模型，在边缘部分的凹凸感会不理想 如果使用置换贴图，因为它是真正改变物体的形状，所以边缘部分的凹凸感就会很真实 注意：使用置换贴图，对模型的面数有要求。 正是这个原因，让它和曲面细分着色器有着很好的契合度。 ③雪地里出现的脚印 可以用曲面细分着色器进行优化 1-2.为什么不用复杂的模型，而要用曲面细分着色器？ 曲面细分着色器可以根据距离/一些规则，动态的调整模型的复杂度，带来更好的性能。 2.几何着色器的应用①几何动画 简单的几何动画、甚至可以做一些破碎的效果 ②草地等效果（与曲面细分结合） 自定义草的画法，再和曲面细分着色器结合，就可以得到一个可以动态调整草密度的一个草地效果。 二、从管线顺序来看 整体顺序：顶点 → 曲面细分 → 几何 → 片元 曲面细分又分为：Hull shader 、Tessellation Primitive Generator 、 Domain shader Hull shader主要作用：定义一些细分的参数（如：每条边上如何细分，内部三角形如何细分） Tessellation Primitive Generator，不可编程的 Domain shader：经过曲面细分着色器细分后的点是位于重心空间的，这部分的作用就是把它转化到我们要用的空间。 在D3D11 和 OpenGL中，名字/叫法有差异，问题不大 三、曲面细分着色器-Tessellation shader（TESS）1.TESS的输入和输出输入 称为Patch，可以看成是多个顶点的集合，包含每个顶点的属性。（属性是所有顶点共享的，不是每个顶点有独自的属性） 功能 将图元进行细分。 图元可以是三角形、矩形等 不同的图元，输入参数也不一样。 输出 细分后的顶点 2.TESS的流程Hull shader → Tessellation Primitive Generator → Domain shader Hull shader 定义细分的参数 设定Tessellation factor以及Inside Tessellation factor （如果需要的话）可以对输入的Patch参数进行改变 Tessellation Primitive Generator 这部分是不可编程、无法控制的 进行细分操作 Domain shader 对细分后的点进行处理，从重心空间（Barycentric coordinate system）转换到屏幕空间 3.Hull shader参数详解①Tessellation Factor 定义把一条边分为几个部分 切分的方法有三种： equal_Spacing 把一条边等分（二、三分等等..） fractional_even_spacing 向上取最近的偶数 最小值是2 会把周长分为n-2的等长部分、以及两端不等长的部分（两端部分和小数有关，具体看gif） fractional_odd_spacing 向上取最近的奇数 最小值是1 会把周长分为n-2的等长部分、以及两端不等长的部分 目的：让细分更加平滑 ②Inner Tessellation Factor 定义内部的三角形/矩形是怎么画出来的 三角形情况 例如上图三等分的情况： 将三条边三等分，然后从一个端点开始，取邻近的两个切分点做延长线，两者的交点就是新三角形的一个端点。以此类推就是左图的效果。 上图四等分、甚至更多点的情况： 上述三等分步骤之后，内部三角形的每个边的等分点做延长线，交点就是 矩形情况 同样的，做延长线，交点，直到没有交点或者交于重心一个点 4.曲面细分Demo部分//注：代码直接复制的评论区里同学码出来的，懒得再打一遍了233 Demo1：曲面细分算法展示123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130//曲面细分Demo1Shader &quot;Unlit/TessShader&quot;&#123; Properties &#123; _TessellationUniform(&quot;TessellationUniform&quot;,Range(1,64)) = 1 &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125; LOD 100 Pass &#123; CGPROGRAM //定义2个函数 hull domain #pragma hull hullProgram #pragma domain ds #pragma vertex tessvert #pragma fragment frag #include &quot;UnityCG.cginc&quot; //引入曲面细分的头文件 #include &quot;Tessellation.cginc&quot; #pragma target 5.0 struct VertexInput &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; float3 normal : NORMAL; float4 tangent : TANGENT; &#125;; struct VertexOutput &#123; float2 uv : TEXCOORD0; float4 vertex : SV_POSITION; float3 normal : NORMAL; float4 tangent : TANGENT; &#125;; VertexOutput vert (VertexInput v) //这个函数应用在domain函数中，用来空间转换的函数 &#123; VertexOutput o; o.vertex = UnityObjectToClipPos(v.vertex); o.uv = v.uv; o.tangent = v.tangent; o.normal = v.normal; return o; &#125; //有些硬件不支持曲面细分着色器，定义了该宏就能够在不支持的硬件上不会变粉，也不会报错 #ifdef UNITY_CAN_COMPILE_TESSELLATION //顶点着色器结构的定义 struct TessVertex&#123; float4 vertex : INTERNALTESSPOS; float3 normal : NORMAL; float4 tangent : TANGENT; float2 uv : TEXCOORD0; &#125;; struct OutputPatchConstant &#123; //不同的图元，该结构会有所不同 //该部分用于Hull Shader里面 //定义了patch的属性 //Tessellation Factor和Inner Tessellation Factor float edge[3] : SV_TESSFACTOR; float inside : SV_INSIDETESSFACTOR; &#125;; TessVertex tessvert (VertexInput v)&#123; //顶点着色器函数 TessVertex o; o.vertex = v.vertex; o.normal = v.normal; o.tangent = v.tangent; o.uv = v.uv; return o; &#125; float _TessellationUniform; OutputPatchConstant hsconst (InputPatch&lt;TessVertex,3&gt; patch)&#123; //定义曲面细分的参数 OutputPatchConstant o; o.edge[0] = _TessellationUniform; o.edge[1] = _TessellationUniform; o.edge[2] = _TessellationUniform; o.inside = _TessellationUniform; return o; &#125; [UNITY_domain(&quot;tri&quot;)]//确定图元，quad,triangle等 [UNITY_partitioning(&quot;fractional_odd&quot;)]//拆分edge的规则，equal_spacing,fractional_odd,fractional_even [UNITY_outputtopology(&quot;triangle_cw&quot;)] [UNITY_patchconstantfunc(&quot;hsconst&quot;)]//一个patch一共有三个点，但是这三个点都共用这个函数 [UNITY_outputcontrolpoints(3)] //不同的图元会对应不同的控制点 TessVertex hullProgram (InputPatch&lt;TessVertex,3&gt; patch,uint id : SV_OutputControlPointID)&#123; //定义hullshaderV函数 return patch[id]; &#125; [UNITY_domain(&quot;tri&quot;)]//同样需要定义图元 VertexOutput ds (OutputPatchConstant tessFactors, const OutputPatch&lt;TessVertex,3&gt;patch,float3 bary :SV_DOMAINLOCATION) //bary:重心坐标 &#123; VertexInput v; v.vertex = patch[0].vertex*bary.x + patch[1].vertex*bary.y + patch[2].vertex*bary.z; v.tangent = patch[0].tangent*bary.x + patch[1].tangent*bary.y + patch[2].tangent*bary.z; v.normal = patch[0].normal*bary.x + patch[1].normal*bary.y + patch[2].normal*bary.z; v.uv = patch[0].uv*bary.x + patch[1].uv*bary.y + patch[2].uv*bary.z; VertexOutput o = vert (v); return o; &#125; #endif float4 frag (VertexOutput i) : SV_Target &#123; return float4(1.0,1.0,1.0,1.0); &#125; ENDCG &#125; &#125; Fallback &quot;Diffuse&quot;&#125; Demo2：和置换贴图结合 基本原理 通过置换贴图的深度，来把顶点沿着它的法线方向进行移动，以此来对mash进行形变。 代码部分和上个Demo的区别也就是在顶点shader部分对顶点进行了位移、和一些计算法线的参数。（因为顶点位移后没有对应的法线贴图，所以需要自己计算一下，具体怎么算先不讲，属于置换贴图部分的知识） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177//曲面细分Demo2：与置换贴图结合使用Shader &quot;Unlit/Tess_Diss_Shader&quot;&#123; Properties &#123; _MainTex(&quot;MainTex&quot;,2D) = &quot;white&quot;&#123;&#125; _DisplacementMap(&quot;_DisplacementMap&quot;,2D)=&quot;gray&quot;&#123;&#125; _DisplacementStrength(&quot;DisplacementStrength&quot;,Range(0,1)) = 0 _Smoothness(&quot;Smoothness&quot;,Range(0,5))=0.5 _TessellationUniform(&quot;TessellationUniform&quot;,Range(1,64)) = 1 &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &quot;LightMode&quot;=&quot;ForwardBase&quot;&#125; LOD 100 Pass &#123; CGPROGRAM //定义2个函数 hull domain #pragma hull hullProgram #pragma domain ds #pragma vertex tessvert #pragma fragment frag #include &quot;UnityCG.cginc&quot; #include &quot;Lighting.cginc&quot; //引入曲面细分的头文件 #include &quot;Tessellation.cginc&quot; #pragma target 5.0 float _TessellationUniform; sampler2D _MainTex; float4 _MainTex_ST; sampler2D _DisplacementMap; float4 _DisplacementMap_ST; float _DisplacementStrength; float _Smoothness; struct VertexInput &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; float3 normal : NORMAL; float4 tangent : TANGENT; &#125;; struct VertexOutput &#123; float2 uv : TEXCOORD0; float4 pos : SV_POSITION; float4 worldPos:TEXCOORD1; half3 tspace0 :TEXCOORD2; half3 tspace1 :TEXCOORD3; half3 tspace2 :TEXCOORD4; &#125;; VertexOutput vert (VertexInput v) //这个函数应用在domain函数中，用来空间转换的函数 &#123; VertexOutput o; o.uv = TRANSFORM_TEX(v.uv,_MainTex); //Displacement //由于并不是在Fragnent shader中读取图片，GPU无法获取mipmap信息，因此需要使用tex2Dlod来读取图片，使用第四坐标作为mipmap的level，这里取了0 float Displacement = tex2Dlod(_DisplacementMap,float4(o.uv.xy,0.0,0.0)).g; Displacement = (Displacement-0.5)*_DisplacementStrength; v.normal = normalize(v.normal); v.vertex.xyz += v.normal * Displacement; o.pos = UnityObjectToClipPos(v.vertex); o.worldPos = mul(unity_ObjectToWorld, v.vertex); //计算切线空间转换矩阵 half3 vNormal = UnityObjectToWorldNormal(v.normal); half3 vTangent = UnityObjectToWorldDir(v.tangent.xyz); //compute bitangent from cross product of normal and tangent half tangentSign = v.tangent.w * unity_WorldTransformParams.w; half3 vBitangent = cross(vNormal,vTangent)*tangentSign; //output the tangent space matrix o.tspace0 = half3(vTangent.x,vBitangent.x,vNormal.x); o.tspace1 = half3(vTangent.y,vBitangent.y,vNormal.y); o.tspace2 = half3(vTangent.z,vBitangent.z,vNormal.z); return o; &#125; //有些硬件不支持曲面细分着色器，定义了该宏就能够在不支持的硬件上不会变粉，也不会报错 #ifdef UNITY_CAN_COMPILE_TESSELLATION //顶点着色器结构的定义 struct TessVertex&#123; float4 vertex : INTERNALTESSPOS; float3 normal : NORMAL; float4 tangent : TANGENT; float2 uv : TEXCOORD0; &#125;; struct OutputPatchConstant &#123; //不同的图元，该结构会有所不同 //该部分用于Hull Shader里面 //定义了patch的属性 //Tessellation Factor和Inner Tessellation Factor float edge[3] : SV_TESSFACTOR; float inside : SV_INSIDETESSFACTOR; &#125;; TessVertex tessvert (VertexInput v)&#123; //顶点着色器函数 TessVertex o; o.vertex = v.vertex; o.normal = v.normal; o.tangent = v.tangent; o.uv = v.uv; return o; &#125; //float _TessellationUniform; OutputPatchConstant hsconst (InputPatch&lt;TessVertex,3&gt; patch)&#123; //定义曲面细分的参数 OutputPatchConstant o; o.edge[0] = _TessellationUniform; o.edge[1] = _TessellationUniform; o.edge[2] = _TessellationUniform; o.inside = _TessellationUniform; return o; &#125; [UNITY_domain(&quot;tri&quot;)]//确定图元，quad,triangle等 [UNITY_partitioning(&quot;fractional_odd&quot;)]//拆分edge的规则，equal_spacing,fractional_odd,fractional_even [UNITY_outputtopology(&quot;triangle_cw&quot;)] [UNITY_patchconstantfunc(&quot;hsconst&quot;)]//一个patch一共有三个点，但是这三个点都共用这个函数 [UNITY_outputcontrolpoints(3)] //不同的图元会对应不同的控制点 TessVertex hullProgram (InputPatch&lt;TessVertex,3&gt; patch,uint id : SV_OutputControlPointID)&#123; //定义hullshaderV函数 return patch[id]; &#125; [UNITY_domain(&quot;tri&quot;)]//同样需要定义图元 VertexOutput ds (OutputPatchConstant tessFactors, const OutputPatch&lt;TessVertex,3&gt;patch,float3 bary :SV_DOMAINLOCATION) //bary:重心坐标 &#123; VertexInput v; v.vertex = patch[0].vertex*bary.x + patch[1].vertex*bary.y + patch[2].vertex*bary.z; v.tangent = patch[0].tangent*bary.x + patch[1].tangent*bary.y + patch[2].tangent*bary.z; v.normal = patch[0].normal*bary.x + patch[1].normal*bary.y + patch[2].normal*bary.z; v.uv = patch[0].uv*bary.x + patch[1].uv*bary.y + patch[2].uv*bary.z; VertexOutput o = vert (v); return o; &#125; #endif float4 frag (VertexOutput i) : SV_Target &#123; float3 lightDir =_WorldSpaceLightPos0.xyz; float3 tnormal = UnpackNormal (tex2D (_DisplacementMap, i.uv)); half3 worldNormal; worldNormal.x=dot(i.tspace0,tnormal); worldNormal.y= dot (i.tspace1, tnormal); worldNormal.z=dot (i.tspace2, tnormal); float3 albedo=tex2D (_MainTex, i.uv). rgb; float3 lightColor = _LightColor0.rgb; float3 diffuse = albedo * lightColor * DotClamped(lightDir,worldNormal); float3 viewDir = normalize (_WorldSpaceCameraPos. xyz-i. worldPos. xyz); float3 halfVector = normalize(lightDir + viewDir); float3 specular = albedo * pow (DotClamped (halfVector, worldNormal), _Smoothness * 100); float3 result = specular + diffuse; return float4(result, 1.0); return float4(result,1.0); &#125; ENDCG &#125; &#125; Fallback &quot;Diffuse&quot;&#125; 四、几何着色器-Geometry shader （GS）1.GS的输入和输出输入 输入为单个图元（三角形、矩形、线等等） 根据不同的图元，shader中会出现不同的顶点数量 输出 输出也为图元（一个或者多个） 同时还要定义输出的最大顶点数 输出的图元需要自己一个点一个点的自己去构建，顺序很重要（这个着色器最主要的功能：自己构建图元） 2.流程 输入输出结构 定义最大输出定点数 几何着色器 五、其他资料 https://www.cnblogs.com/mazhenyu/p/3831986.html几何着色器 catlike-曲面细分着色器： https://catlikecoding.com/unity/tutorials/advanced-rendering/tessellation/ https://www.yuque.com/sugelameiyoudi-jadcc/okgm7e/xyx5h5 https://zhuanlan.zhihu.com/p/433385999 Homework","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"曲面细分着色器","slug":"曲面细分着色器","permalink":"https://whitetail-o.github.io/tags/%E6%9B%B2%E9%9D%A2%E7%BB%86%E5%88%86%E7%9D%80%E8%89%B2%E5%99%A8/"},{"name":"几何着色器","slug":"几何着色器","permalink":"https://whitetail-o.github.io/tags/%E5%87%A0%E4%BD%95%E7%9D%80%E8%89%B2%E5%99%A8/"}]},{"title":"HPP_Graphics_2.7.2 GPU硬件架构概述","slug":"HPP_Graphics_2.7.2_GPU硬件架构概述","date":"2023-02-15T09:38:32.000Z","updated":"2023-03-17T05:02:00.553Z","comments":true,"path":"2023/02/15/HPP_Graphics_2.7.2_GPU硬件架构概述/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_2.7.2_GPU%E7%A1%AC%E4%BB%B6%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0/","excerpt":"","text":"GPU逻辑管线 程序通过图形API(DX、GL、WEBGL)发出drawcall指令，指令会被推送到驱动程序，驱动会检查指令的合法性，然后会把指令放到GPU可以读取的Pushbuffer中。 经过一段时间或者显式调用flush指令后，驱动程序把Pushbuffer的内容发送给GPU，GPU通过主机接口（Host Interface）接受这些命令，并通过前端（Front End）处理这些命令。 在图元分配器(Primitive Distributor)中开始工作分配，处理indexbuffer中的顶点产生三角形分成批次(batches)，然后发送给多个GPCs。这一步的理解就是提交上来n个三角形，分配给这几个GPC同时处理。 在GPC中，每个SM中的Poly Morph Engine负责通过三角形索引(triangle indices)取出三角形的数据(vertex data)，即图中的Vertex Fetch模块。 在获取数据之后，在SM中以32个线程为一组的线程束(Warp)来调度，来开始处理顶点数据。 SM的warp调度器会按照顺序分发指令给整个warp，单个warp中的线程会锁步(lock-step)执行各自的指令，如果线程碰到不激活执行的情况也会被遮掩(be masked out) warp中的指令可以被一次完成，也可能经过多次调度，例如通常SM中的LD/ST(加载存取)单元数量明显少于基础数学操作单元。 由于某些指令比其他指令需要更长的时间才能完成，特别是内存加载，warp调度器可能会简单地切换到另一个没有内存等待的warp，这是GPU如何克服内存读取延迟的关键，只是简单地切换活动线程组。 一旦warp完成了vertex-shader的所有指令，运算结果会被Viewport Transform模块处理，三角形会被裁剪然后准备栅格化，GPU会使用L1和L2缓存来进行vertex-shader和pixel-shader的数据通信。 接下来这些三角形将被分割，再分配给多个GPC，三角形的范围决定着它将被分配到哪个光栅引擎(raster engines)，每个raster engines覆盖了多个屏幕上的tile，这等于把三角形的渲染分配到多个tile上面。也就是像素阶段就把按三角形划分变成了按显示的像素划分了。 SM上的Attribute Setup保证了从vertex-shader来的数据经过插值后是pixel-shade是可读的。 GPC上的光栅引擎(raster engines)在它接收到的三角形上工作，来负责这些这些三角形的像素信息的生成（同时会处理背面剔除和Early-Z剔除）。 32个像素线程将被分成一组，或者说8个2x2的像素块，这是在像素着色器上面的最小工作单元，在这个像素线程内，如果没有被三角形覆盖就会被遮掩，SM中的warp调度器会管理像素着色器的任务。 接下来的阶段就和vertex-shader中的逻辑步骤完全一样，但是变成了在像素着色器线程中执行。 由于不耗费任何性能可以获取一个像素内的值，导致锁步执行非常便利，所有的线程可以保证所有的指令可以在同一点。 最后一步，现在像素着色器已经完成了颜色的计算还有深度值的计算，在这个点上，我们必须考虑三角形的原始api顺序，然后才将数据移交给ROP(render output unit，渲染输入单元)，一个ROP内部有很多ROP单元，在ROP单元中处理深度测试，和framebuffer的混合，深度和颜色的设置必须是原子操作，否则两个不同的三角形在同一个像素点就会有冲突和错误。 https://www.cnblogs.com/anesu/p/15807749.html#/c/subject/p/15807749.html","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"硬件","slug":"硬件","permalink":"https://whitetail-o.github.io/tags/%E7%A1%AC%E4%BB%B6/"}]},{"title":"HPP_Graphics_2.7 HDR和LDR","slug":"HPP_Graphics_2.7_HDR和LDR","date":"2023-02-15T09:35:32.000Z","updated":"2023-03-17T05:01:21.251Z","comments":true,"path":"2023/02/15/HPP_Graphics_2.7_HDR和LDR/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_2.7_HDR%E5%92%8CLDR/","excerpt":"a). 基本概念 因为HDR可超过1，又被叫做浮点图像 也因为HDR可超过1，bloom会有较好的表现； b). Unity中的HDR Camera Lightmap 拾色器 Unity中HDR的优缺点： c). Bloom 基础做法： 后处理中，选取高于一定亮度的像素区域，进行Blur（高斯模糊之类的），最后进行叠加； Unity中的做法： d). Toon Mapping 原因： 照相机和摄像机可以捕捉到HDR的影响，渲染过程中可以产生HDR的画面。这些内容如果需要显示到LDR的设备上，就需要一个称为tone mapping的过程，把HDR变成LDR。 ACES曲线： ToonMapping算法：https://zhuanlan.zhihu.com/p/21983679 Lut： 略","text":"a). 基本概念 因为HDR可超过1，又被叫做浮点图像 也因为HDR可超过1，bloom会有较好的表现； b). Unity中的HDR Camera Lightmap 拾色器 Unity中HDR的优缺点： c). Bloom 基础做法： 后处理中，选取高于一定亮度的像素区域，进行Blur（高斯模糊之类的），最后进行叠加； Unity中的做法： d). Toon Mapping 原因： 照相机和摄像机可以捕捉到HDR的影响，渲染过程中可以产生HDR的画面。这些内容如果需要显示到LDR的设备上，就需要一个称为tone mapping的过程，把HDR变成LDR。 ACES曲线： ToonMapping算法：https://zhuanlan.zhihu.com/p/21983679 Lut： 略 【参考资料】 《Unity Shader入门精要》 https://docs.unity.cn/cn/current/Manual/HDR.html https://zhuanlan.zhihu.com/p/91390940 https://zhuanlan.zhihu.com/p/80253409 https://zhuanlan.zhihu.com/p/21983679 http://www.openexr.org/ http://www.hdrlabs.com/sibl/archive.html 作业：试试IBL在HDR和LDR的区别https://blog.csdn.net/qq_43210334/article/details/117415250 以下是在Unity中的对比，分别是使用ACES曲线的LDR和HDR的对比，同时加入了轻微的Bloom；","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"色彩管理","slug":"色彩管理","permalink":"https://whitetail-o.github.io/tags/%E8%89%B2%E5%BD%A9%E7%AE%A1%E7%90%86/"}]},{"title":"HPP_Graphics_2.6 伽马校正","slug":"HPP_Graphics_2.6_伽马校正","date":"2023-02-15T09:30:32.000Z","updated":"2023-03-17T04:59:14.194Z","comments":true,"path":"2023/02/15/HPP_Graphics_2.6_伽马校正/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_2.6_%E4%BC%BD%E9%A9%AC%E6%A0%A1%E6%AD%A3/","excerpt":"","text":"渲染时，着色器中计算颜色最好在线性空间下（从辐射度量学的角度来看，是计算radiance和Irradiance） a). Unity中的色彩管理https://docs.unity.cn/cn/current/Manual/LinearLighting.html Unity中选择色彩空间为Gamma时，渲染管线将使用伽马颜色空间中存储的所有颜色（比如灯光的颜色）和纹理。着色器不会对输入的贴图做sRGB采样，同时也不会对灯光颜色进行伽马转线性 Unity中色彩空间设置为Linear时，Unity会默认勾选sRGB，着色器会对勾选sRGB的进行sRGB采样（伽马转线性），详见后图 选择 Color Space: Linear 将假设纹理位于伽马颜色空间内。Unity 在默认情况下使用 GPU 的 sRGB 采样器从伽马颜色空间跨越到线性颜色空间。如果纹理是在线性颜色空间内创建的，则需要绕过 sRGB 采样。请参阅有关使用线性纹理的文档以了解更多信息。 SP-U3D（SP的新版色彩管理OpenColorIO非常好，不清楚就去看看） PS-U3D PS的色彩管理","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"色彩管理","slug":"色彩管理","permalink":"https://whitetail-o.github.io/tags/%E8%89%B2%E5%BD%A9%E7%AE%A1%E7%90%86/"}]},{"title":"HPP_Graphics_2.5 Bump Mapping","slug":"HPP_Graphics_2.5_Bump Mapping","date":"2023-02-15T09:28:32.000Z","updated":"2023-03-17T04:59:00.652Z","comments":true,"path":"2023/02/15/HPP_Graphics_2.5_Bump Mapping/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_2.5_Bump%20Mapping/","excerpt":"a). Bump Map的分类 b). Normal Map 法线贴图：存有物体局部（切线空间）表面法线信息的一张贴图 Link1 NOTE.md Link2 储存空间： （一般采用）切线空间 模型空间 b.1). Tangent SpaceLink3 切线空间(Tangent Space) 切线空间中，x轴为切线，y轴为副切线，z轴为表面初始法线 其中，切线的方向对应UV空间的 $u$ 轴，副切线对应 $v$ 轴（详见Link1、Link3） 使用切线空间的优点： 自由度高，可复用 可进行uv动画 可压缩 c). Unity中的法线压缩格式","text":"a). Bump Map的分类 b). Normal Map 法线贴图：存有物体局部（切线空间）表面法线信息的一张贴图 Link1 NOTE.md Link2 储存空间： （一般采用）切线空间 模型空间 b.1). Tangent SpaceLink3 切线空间(Tangent Space) 切线空间中，x轴为切线，y轴为副切线，z轴为表面初始法线 其中，切线的方向对应UV空间的 $u$ 轴，副切线对应 $v$ 轴（详见Link1、Link3） 使用切线空间的优点： 自由度高，可复用 可进行uv动画 可压缩 c). Unity中的法线压缩格式 d). Parallax Mapping(时差映射) d.1). 普通实现方式 这里能用切线空间的视线方向 $viewDirTS$ 来计算 UV 的偏移的原因正是因为切线空间的$x, y$轴和UV空间的 $u, v$ 轴对应； d.2). Steep Parallax Mapping(陡峭视差映射) 采用光线步进； 但如效果仍有不足，可采用浮雕贴图（Relief Mapping） e). Relief Mapping（浮雕贴图） 实现方法： 最后一步步进后，在最后一步的范围内使用二分查找，直到找到近似P点的点； 优化方法： 二分法性能开销过大； 最后一个步进时得到高度 $h1$ 和 $h2$ ，$H_p = (h1+h2)/2$ （见上图） 作业 视差贴图、浮雕贴图的实现 资料补充：视差贴图（Parallax Mapping）与陡峭视差贴图(Steep Palallax Mapping, 已收藏在收藏夹) Shader见 S_Parallax_Relief.shader 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226Shader &quot;BRJH/MetallicWorkflow&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; &#123;&#125; _DiffuseTint (&quot;Diffuse Tint&quot;, color) = (1, 1, 1, 1) _Metallic (&quot;Metallic&quot;, Range(0, 1)) = 0.5 _Gloss (&quot;Gloss&quot;, Range(1, 255)) = 20 _NormalMap (&quot;Normal&quot;, 2D) = &quot;bump&quot; &#123;&#125; _NormalScale (&quot;Normal Scale&quot;, Range(0, 5)) = 1 _HeightMap (&quot;Height Map&quot;, 2D) = &quot;black&quot; &#123;&#125; _HeightScale (&quot;Height Scale&quot;, Range(0, 0.3)) = 0.2 _CubeMap (&quot;Cube Map&quot;, Cube) = &quot;_skybox&quot; &#123;&#125; _EnvIntensity (&quot;Envirment Intensity&quot;, Range(0, 5)) = 1 [KeywordEnum(Default, POM)] _PARALLAX_MAPPING(&quot;Parallax Mapping Type&quot;, Float) = 0 [KeywordEnum(T, F, C)] _USING_IBL(&quot;If use IBL&quot;, Float) = 0 &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &quot;LightMode&quot;=&quot;ForwardBase&quot; &#125; Pass &#123; CGPROGRAM #pragma vertex vert #pragma fragment frag // make fog work #pragma multi_compile_fog #pragma multi_compile _USING_IBL_T _USING_IBL_F #pragma multi_compile _PARALLAX_MAPPING_Default _PARALLAX_MAPPING_POM #include &quot;UnityCG.cginc&quot; #include &quot;UnityPBSLighting.cginc&quot; #include &quot;Lighting.cginc&quot; #define MAX_LAYER_NUM 20 #define MIN_LAYER_NUM 20 sampler2D _MainTex; fixed4 _MainTex_ST; sampler2D _NormalMap; fixed4 _NormalMap_ST; sampler2D _HeightMap; samplerCUBE _CubeMap; fixed4 _DiffuseTint; half _Metallic; fixed _Gloss; fixed _NormalScale; fixed _HeightScale; fixed _EnvIntensity; struct a2v &#123; float4 vertex : POSITION; float3 normal : NORMAL; float4 tangent : TANGENT; float2 texcoord : TEXCOORD0; &#125;; struct v2f &#123; float4 pos : SV_POSITION; float3 TangentLightDir : TEXCOORD0; float3 TangentViewDir : TEXCOORD1; float2 uv : TEXCOORD2; #if defined(_USING_IBL_T) float4 TtoW0 : TEXCOORD4; float4 TtoW1 : TEXCOORD5; float4 TtoW2 : TEXCOORD6; #endif &#125;; float3 ACESToneMapping(float3 color, float adapted_lum) &#123; const float A = 2.51f; const float B = 0.03f; const float C = 2.43f; const float D = 0.59f; const float E = 0.14f; color *= adapted_lum; return (color * (A * color + B)) / (color * (C * color + D) + E); &#125; // 浮雕映射 float2 ReliefMapping(float2 uv, half3 TangentViewDir) &#123; float NumLayer = 40;//lerp(MIN_LAYER_NUM, MAX_LAYER_NUM, abs(dot(Normal, TangentViewDir))); float2 dtex = _HeightScale * TangentViewDir.xy / TangentViewDir.z / NumLayer; float2 addUV = float2(0, 0); float2 currentUV = uv + addUV; float currentLayerHeight = 0; float currentHeightMapValue = tex2D(_HeightMap, currentUV + addUV).r; for (int n = 0; n &lt; NumLayer; n++) &#123; currentLayerHeight += 1.0/NumLayer; currentUV += dtex; currentHeightMapValue = tex2D(_HeightMap, currentUV).r; if (currentHeightMapValue &lt; currentLayerHeight) &#123; break; &#125; &#125; float2 T0 = currentUV, T1 = currentUV - dtex; for (int j = 0; j&lt;20 ;j++) &#123; float2 P0 = (T0+T1)/2; float P0_HeightMapValue = tex2D(_HeightMap, P0).r; float P0_LayerHeight = length(P0) / length(dtex*NumLayer); if (P0_HeightMapValue &lt; P0_LayerHeight) &#123; T1 = P0; &#125; else &#123; T0 = P0; &#125; &#125; return (T0 + T1) / 2 - uv; &#125; v2f vert(a2v v) &#123; v2f o; o.pos = UnityObjectToClipPos(v.vertex); o.uv = v.texcoord.xy * _MainTex_ST.xy + _MainTex_ST.zw; TANGENT_SPACE_ROTATION; o.TangentLightDir = mul(rotation, ObjSpaceLightDir(v.vertex)).xyz; o.TangentViewDir = mul(rotation, ObjSpaceViewDir(v.vertex)).xyz; #if defined(_USING_IBL_T) float3 worldPos = mul(unity_ObjectToWorld, v.vertex).xyz; float3 worldNormal = UnityObjectToWorldNormal(v.normal); float3 worldTangent = UnityObjectToWorldDir(v.tangent.xyz); float3 worldBinormal = cross(worldNormal, worldTangent) * v.tangent.w; o.TtoW0 = float4(worldTangent.x, worldBinormal.x, worldNormal.x, worldPos.x); o.TtoW1 = float4(worldTangent.y, worldBinormal.y, worldNormal.y, worldPos.y); o.TtoW2 = float4(worldTangent.z, worldBinormal.z, worldNormal.z, worldPos.z); #endif return o; &#125; fixed4 frag(v2f i) : SV_TARGET &#123; //Base fixed3 TangentLightDir = normalize(i.TangentLightDir); fixed3 TangentViewDir = normalize(i.TangentViewDir); fixed3 HalfDir = normalize(TangentLightDir + TangentViewDir); float Height = tex2D(_HeightMap, i.uv).x; fixed4 packedNormal = (1-tex2D(_NormalMap, i.uv)); fixed3 Normal = UnpackNormal(packedNormal); #if defined(_PARALLAX_MAPPING_Default) // 视察贴图 float2 offsetUV = TangentViewDir.xy / TangentViewDir.z * Height * _HeightScale; i.uv += offsetUV; #elif defined(_PARALLAX_MAPPING_POM) // 浮雕贴图 // float NumLayer = 20;//lerp(MIN_LAYER_NUM, MAX_LAYER_NUM, abs(dot(Normal, TangentViewDir))); // float2 dtex = _HeightScale * TangentViewDir.xy / TangentViewDir.z / NumLayer; // float currentLayerHeight = 0; // for (int n = 0; n &lt; NumLayer; n++) &#123; // currentLayerHeight += 1.0/NumLayer; // i.uv += dtex; // if (Height &gt; currentLayerHeight) &#123; // Height = tex2D(_HeightMap, i.uv).r; // &#125; // else &#123; // Height = (Height + tex2D(_HeightMap, i.uv).r)/2; // break; // &#125; // &#125; i.uv += ReliefMapping(i.uv, TangentViewDir); Height = tex2D(_HeightMap, i.uv).x; #endif fixed3 albedo = tex2D(_MainTex, i.uv) * _DiffuseTint.rgb; fixed3 SpecularTint; fixed OneMinusReflectivity; albedo = DiffuseAndSpecularFromMetallic(albedo, _Metallic, SpecularTint, OneMinusReflectivity); packedNormal = tex2D(_NormalMap, i.uv); Normal = UnpackNormal(packedNormal); // 通过高度计算IBL方向 #if defined(_USING_IBL_T) float3 worldPos = float3(i.TtoW0.w, i.TtoW1.w, i.TtoW2.w); float3 worldNormal = normalize(float3(i.TtoW0.z, i.TtoW1.z, i.TtoW2.z)); float3 worldPosUndata = worldPos - worldNormal*Height*_HeightScale; float3 worldViewDir = normalize(UnityWorldSpaceViewDir(worldPosUndata)); float NormalRef = normalize(cross(ddy(worldPosUndata), ddx(worldPosUndata))); // 通过高度贴图计算法线方向; fixed3 worldRef = reflect(-worldViewDir, NormalRef); // fixed3 WorldRef = normalize(fixed3(dot(i.TtoW0.xyz, TangentRef), // dot(i.TtoW1.xyz, TangentRef), // dot(i.TtoW2.xyz, TangentRef))); fixed3 Reflection = ACESToneMapping(texCUBElod(_CubeMap, float4(worldRef, (255-_Gloss)*8/255)).rgb, 1) * SpecularTint * _EnvIntensity; #endif Normal.xy *= _NormalScale; Normal.z = sqrt(1.0 - saturate(dot(Normal.xy, Normal.xy))); fixed3 Ambient = UNITY_LIGHTMODEL_AMBIENT.rgb * albedo; fixed3 Diffuse = lerp(Ambient, _LightColor0.rgb * albedo, saturate(dot(Normal, TangentLightDir))); fixed3 Specular = _LightColor0.rgb * SpecularTint * pow(saturate(dot(HalfDir, Normal)), _Gloss); #if defined(_USING_IBL_T) //Reflection.rgb = lerp(diffuse*Specular, ) fixed4 color = fixed4(Ambient+Diffuse+Specular+Reflection, 1); #elif defined(_USING_IBL_F) fixed4 color = fixed4(Ambient+Diffuse+Specular, 1); #endif return color; &#125; ENDCG &#125; &#125;&#125; 在使用浮雕/视差贴图时，使用IBL； 需要用Offset后的高度图和世界空间坐标得到更新后的世界坐标，再通过ddx，ddy叉乘获得世界法线，进一步进行CubeMap的采样；","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"Bump Mapping","slug":"Bump-Mapping","permalink":"https://whitetail-o.github.io/tags/Bump-Mapping/"}]},{"title":"HPP_Graphics_2.4 传统经验光照模型","slug":"HPP_Graphics_2.4_传统经验光照模型","date":"2023-02-15T09:27:32.000Z","updated":"2023-03-17T04:55:16.314Z","comments":true,"path":"2023/02/15/HPP_Graphics_2.4_传统经验光照模型/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_2.4_%E4%BC%A0%E7%BB%9F%E7%BB%8F%E9%AA%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"图形2.4 传统经验光照模型 Lambert Phong Blinn-Phong Blinn-Phong对比Phong的优点： halfDir好计算 半角向量和法线点乘不会截断（saturate），即夹角总小于90°，不会断层 Cubemap：texCubelod","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"HLSL","slug":"HLSL","permalink":"https://whitetail-o.github.io/tags/HLSL/"}]},{"title":"HPP_Graphics_2.3 HLSL常用函数介绍","slug":"HPP_Graphics_2.3_HLSL常用函数介绍","date":"2023-02-15T09:26:32.000Z","updated":"2023-03-17T04:53:35.895Z","comments":true,"path":"2023/02/15/HPP_Graphics_2.3_HLSL常用函数介绍/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_2.3_HLSL%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E4%BB%8B%E7%BB%8D/","excerpt":"a). HLSL常用函数分类https://blog.csdn.net/eloudy/article/details/71258367 基本数学运算 幂指对函数 数据范围类 类型判断类 三角函数与双曲线函数 向量与矩阵类 光线运算类 1D纹理查找 2D纹理查找 立体纹理查找","text":"a). HLSL常用函数分类https://blog.csdn.net/eloudy/article/details/71258367 基本数学运算 幂指对函数 数据范围类 类型判断类 三角函数与双曲线函数 向量与矩阵类 光线运算类 1D纹理查找 2D纹理查找 立体纹理查找 b). 具体内容 勘误：radians(x) frexp(x, out exp) smoothstep会比lerp更加平滑，如混合颜色时 any(x) 指定量的所有分量中如出现true（非零），则返回true，否则返回false；","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"HLSL","slug":"HLSL","permalink":"https://whitetail-o.github.io/tags/HLSL/"}]},{"title":"HPP_Graphics_2.2 模型与材质","slug":"HPP_Graphics_2.2 模型与材质","date":"2023-02-15T09:25:32.000Z","updated":"2023-03-27T04:30:13.372Z","comments":true,"path":"2023/02/15/HPP_Graphics_2.2 模型与材质/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_2.2%20%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%9D%90%E8%B4%A8/","excerpt":"a). 渲染管线与模型基础1.图形渲染管线一如既往熟悉的渲染管线，蓝色背景的都是可编程的，稍微复习下： 顶点着色器：将顶点坐标从模型空间转换到齐次裁剪空间，我们可以通过在顶点着色器中改变顶点位置实现动画；（可参考实战篇中的幽灵小人） ； 片段着色器：将光栅化阶段所插值的模型信息进行计算，可以进行一些光照计算； 2.模型的实现原理 先是点，点连成线，线构成面，最后组合成多边形模型。 3.UV 在建模过程中，有一部非常重要的操作，就是展UV，那么UV是个啥？ 通俗地理解，展UV可以理解为将原本是三维的模型给全部剪开成面，平铺好的所有面放在一个以U轴（横向）和V轴（纵向）为坐标轴的正方形里就是UV，UV上的点和三维模型上的点一一对应，其位置就是顶点的纹理坐标。比如小学美术课用卡纸做骰子，将其拆开可以直接拆成六个面，这个过程就叫展UV。当在这个面上绘制数字时，对应的最后做好的骰子也会有所显示，这一步就是在UV上绘制贴图。 UV展好的话，其表现平整干净，就像是直接从模型上扒下来的纸张，展不好的话，其效果表现就是扒下来的纸张像是叠了好几次，皱皱巴巴的。 在片段着色器阶段，利用纹理坐标可以获取贴图所存储的信息。 展开好后的UV，一般利用Substance Painter(简称SP，次时代建模流程必备工具)，BodyPainter（老一代的绘制贴图工具），Photoshop(PS绘图没啥好说的，SAI估计也行和PS同理)； 绘制贴图不仅仅只输出一个简单的颜色贴图，根据项目需求还需要法线贴图，金属度贴图，AO贴图等。各种贴图存储的信息不同，所占据的通道有多有少。所以我们还可以将一些通道不够占满RGBA的贴图进行整合，放在一张贴图里的不同通道，达到采样一次，获取多个信息的目的，可以有效提高性能。常见的如将没有透明度，仅存储RGB的颜色贴图与AO贴图压在一张图，AO贴图放在A通道。缺点是不同通道直接还是可能会有相互影响，但是不明显，按需取舍。","text":"a). 渲染管线与模型基础1.图形渲染管线一如既往熟悉的渲染管线，蓝色背景的都是可编程的，稍微复习下： 顶点着色器：将顶点坐标从模型空间转换到齐次裁剪空间，我们可以通过在顶点着色器中改变顶点位置实现动画；（可参考实战篇中的幽灵小人） ； 片段着色器：将光栅化阶段所插值的模型信息进行计算，可以进行一些光照计算； 2.模型的实现原理 先是点，点连成线，线构成面，最后组合成多边形模型。 3.UV 在建模过程中，有一部非常重要的操作，就是展UV，那么UV是个啥？ 通俗地理解，展UV可以理解为将原本是三维的模型给全部剪开成面，平铺好的所有面放在一个以U轴（横向）和V轴（纵向）为坐标轴的正方形里就是UV，UV上的点和三维模型上的点一一对应，其位置就是顶点的纹理坐标。比如小学美术课用卡纸做骰子，将其拆开可以直接拆成六个面，这个过程就叫展UV。当在这个面上绘制数字时，对应的最后做好的骰子也会有所显示，这一步就是在UV上绘制贴图。 UV展好的话，其表现平整干净，就像是直接从模型上扒下来的纸张，展不好的话，其效果表现就是扒下来的纸张像是叠了好几次，皱皱巴巴的。 在片段着色器阶段，利用纹理坐标可以获取贴图所存储的信息。 展开好后的UV，一般利用Substance Painter(简称SP，次时代建模流程必备工具)，BodyPainter（老一代的绘制贴图工具），Photoshop(PS绘图没啥好说的，SAI估计也行和PS同理)； 绘制贴图不仅仅只输出一个简单的颜色贴图，根据项目需求还需要法线贴图，金属度贴图，AO贴图等。各种贴图存储的信息不同，所占据的通道有多有少。所以我们还可以将一些通道不够占满RGBA的贴图进行整合，放在一张贴图里的不同通道，达到采样一次，获取多个信息的目的，可以有效提高性能。常见的如将没有透明度，仅存储RGB的颜色贴图与AO贴图压在一张图，AO贴图放在A通道。缺点是不同通道直接还是可能会有相互影响，但是不明显，按需取舍。 4.模型包含的信息（OBJ为例） 包含顶点位置信息（v开头），纹理坐标（vt开头），法线信息（vn开头），还有片元材质信息（最后f开头）可参考下面； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# This file uses centimeters as units for non-parametric coordinates.mtllib 2.mtlg defaultv -0.500000 -0.500000 0.500000v 0.500000 -0.500000 0.500000v -0.500000 0.500000 0.500000v 0.500000 0.500000 0.500000v -0.500000 0.500000 -0.500000v 0.500000 0.500000 -0.500000v -0.500000 -0.500000 -0.500000v 0.500000 -0.500000 -0.500000vt 0.375000 0.000000vt 0.625000 0.000000vt 0.375000 0.250000vt 0.625000 0.250000vt 0.375000 0.500000vt 0.625000 0.500000vt 0.375000 0.750000vt 0.625000 0.750000vt 0.375000 1.000000vt 0.625000 1.000000vt 0.875000 0.000000vt 0.875000 0.250000vt 0.125000 0.000000vt 0.125000 0.250000vn 0.000000 0.000000 1.000000vn 0.000000 0.000000 1.000000vn 0.000000 0.000000 1.000000vn 0.000000 0.000000 1.000000vn 0.000000 1.000000 0.000000vn 0.000000 1.000000 0.000000vn 0.000000 1.000000 0.000000vn 0.000000 1.000000 0.000000vn 0.000000 0.000000 -1.000000vn 0.000000 0.000000 -1.000000vn 0.000000 0.000000 -1.000000vn 0.000000 0.000000 -1.000000vn 0.000000 -1.000000 0.000000vn 0.000000 -1.000000 0.000000vn 0.000000 -1.000000 0.000000vn 0.000000 -1.000000 0.000000vn 1.000000 0.000000 0.000000vn 1.000000 0.000000 0.000000vn 1.000000 0.000000 0.000000vn 1.000000 0.000000 0.000000vn -1.000000 0.000000 0.000000vn -1.000000 0.000000 0.000000vn -1.000000 0.000000 0.000000vn -1.000000 0.000000 0.000000s offg pCube1usemtl initialShadingGroupf 1/1/1 2/2/2 4/4/3 3/3/4f 3/3/5 4/4/6 6/6/7 5/5/8f 5/5/9 6/6/10 8/8/11 7/7/12f 7/7/13 8/8/14 2/10/15 1/9/16f 2/2/17 8/11/18 6/12/19 4/4/20f 7/13/21 1/1/22 3/3/23 5/14/24 关于视频中讲到OBJ文件中存储顶点颜色的信息，我个人在用MAYA绘制顶点色后输出查看是不存在的。FBX是可以的，这一点在实践篇中也是有用到。 5.OBJ与FBX格式 b). 材质基础在上一篇光的那里讲过，人眼看见的物体颜色是光经过反射或折射后的。现实中，看不同的物体有不同的感觉，其材质的表现也和光密切相关。 1.漫反射最容易也是较基础的。常用的漫反射模型是兰伯特（Lambertian），它简单粗暴地认为光线均匀反射出去。兰伯特是基于法线向量与指向光源的向量点积结果。在向量基础里我们就简单的介绍过兰伯特模型的点积结果与颜色关系。2.镜面反射 光滑镜面反射。镜面反射就是将入射光线根据表面法线进行反射，并且只有在反射方向有能量，其他方向能量均为0。常用的镜面反射模型有Phong和Blinn-Phong。下面两张ShaderForge节点图中，上面的是Phong，下面是Blinn-Phong。 3.折射 提及折射一般想起的肯定是水面了，一部分光反射出去，另一部分则发生折射。反射和折射分别占多少占比可根据菲涅尔定律决定。关于菲涅尔在实践篇中也做过简单的运用，多是把它作为边缘光来使用。 4.粗糙镜面反射 法线偏移较小，反射集中在一个区域，有磨砂感。关于这个在实践篇中倒是未曾涉猎。为了表现磨砂感，一般用CubeMap调整Mip去处理。 5.粗糙镜面折射与粗糙镜面反射类似，不过比起粗糙镜面反射，粗糙镜面折射中有一部分光可以透过去发生折射。 6.多层材质涂漆的地板上有木纹，有漆面的质感。7.次表面散射 如皮肤，牛奶，玉石等，玉石的制作在实践篇中以调子映射制作，皮肤则是用Lut图。 8.关于皮肤 皮肤可以看成三层：油脂，表皮，真皮。油脂层直接把光反射出去，所以皮肤上才出现高光，未被反射的光通过折射进入子表面层，进入该层后，部分被吸收和散射，再从皮肤中入射点附近出射点射出从而形成次表面散射效果。参考上图。 9.改变材质表面现实中不存在绝对光滑的表面，且一个模型顶点所带法线有限。而漫反射，镜面反射，折射都有法线参与。改变法线就可以影响光照计算结果。在卡通渲染中，我们可以利用修改法线的方式，对效果进行一定的优化。如《火影忍者：究极风暴》中先膨胀法线，然后计算光照后再用到原模型上，降低三维感。顺带模型和材质都会影响画面是否好看，模型做得好用zbrush直接雕刻一个人像，就可以表现皮肤的皱纹，模型做不好，就算是再好的贴图和渲染方案也拯救不了。 c). 模型数据解析1.模型数据在渲染中的作用 可以用于顶点动画，纹理动画，顶点色，这三点在实践篇中的赛博朋克特效小人里都有所涉及。 2.纹理动画包括UV扰动，UV流动，序列帧播放其实也可以算在UV流动里，个人感觉它是特意规定特殊流动方向的UV流动。 下图的gif里就包括UV扰动，对水面下的纹理进行干扰变换，UV流动，自左往右。关于这俩的实现，都是对UV坐标进行改变进而干涉采样结果。其中UV扰动中还利用GrabPass去获取背后的物体，将其渲染成一张纹理再进行干扰。视频中还使用了法线贴图。 原理1通过对法线改变，从而导致左上角中纹理采样进行改变。 原理2就是之前讲的通过改变UV坐标实现动画3.顶点动画 通过在顶点着色器中对模型顶点操作，进而产生动画。 顶点着色器计算的是每一个顶点，各点数据不同，进而同一个公司在不同顶点有不同效果。 K帧也可以看做是一种顶点动画，比如在某轴上平移就是对所有顶点数据的某个轴上加上一个值。 顶点动画想要做好看，请尽可能多加顶点，如果顶点不够，其表现就不会如下图这般丝滑，且会效果不明显。4.顶点色我们可以利用绘制顶点色的做法，从而达到类似遮罩的效果。在MAYA中绘制顶点色时可以明显看到是三角面。因为在渲染或导入游戏引擎时，四边面被转成了三角形进行计算。三角形内像素点的色彩会在光栅化时进行插值混合。插值原理：根据重心坐标进行计算。例子5.顶点法线和面法线 面法线其实还是顶点法线不过是存储方式不同罢了。当前像素点的法线是通过周围顶点法线插值获得的，而从下图中可以明显看到面法线与顶点法线因为方向不同，插值结果也不同。其中面法线三个点共用一个法线。 面法线有多少面存储多少法线，顶点法线则是有多少顶点存多少法线。在卡渲中，描边时，通常使用罪恶装备的Backfacing外扩边描线法。也就是在顶点着色器中将法线方向偏移。该方法在处理硬表面时会出现断裂的情况。这是因为没有对法线进行平滑，导致法线不连续，进而描边不连续。 d). 顶点色作用、光滑组对法线的影响https://www.yuque.com/sugelameiyoudi-jadcc/okgm7e/fxvhxl#b4lco 光滑组的本质是改变点法线，进而影响面法线，进而影响三角线遍历中Normal的插值； e). 法线烘焙原理烘焙低模时，在切线空间计算低模与高模的法线差异。即低模切线空间中，高模对应位置法线的方向。烘焙为贴图。","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"材质","slug":"材质","permalink":"https://whitetail-o.github.io/tags/%E6%9D%90%E8%B4%A8/"},{"name":"模型","slug":"模型","permalink":"https://whitetail-o.github.io/tags/%E6%A8%A1%E5%9E%8B/"}]},{"title":"HPP_Graphics_1.3 纹理的秘密","slug":"HPP_Graphics_1.3 纹理的秘密","date":"2023-02-15T09:24:32.000Z","updated":"2023-03-27T04:29:04.970Z","comments":true,"path":"2023/02/15/HPP_Graphics_1.3 纹理的秘密/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_1.3%20%E7%BA%B9%E7%90%86%E7%9A%84%E7%A7%98%E5%AF%86/","excerpt":"a). 什么是纹理一种可供着色器读写的结构化存储形式（采样器变量的形式，sampler） b). 纹理管线 模型空间位置→投影函数（不同与摄像机投影矩阵，是展UV其中一步）→纹理映射→纹理坐标→通讯函数→新纹理坐标→纹理采样（避免依赖纹理读取，如果片元着色器中不是使用顶点着色器中传递的数值，而是经过计算，那么就会产生依赖纹理读取，影响性能。因此，uv的偏移通常在顶点着色器中完成）→纹理值 c). Wrap Mode 简介： 决定uv[0, 1]以外的表现 OpenGL —— 包装模式（Wrapping Mode） DirectX —— 纹理寻址模式（Texture Addressing Mode） 类型： Repeat Mirror Clamp Border d). Filter Mode 在不同形状、大小、缩放比时，纹理过滤模式，可由专用硬件实现，也可由软件中实现，也可软硬件搭配完成 d.1) 放大（Magnification） 最近邻（性能消耗小，放大时每个像素读取最邻近的纹素，可能出现马赛克像素风格） 双线性插值——对于每一个像素点都寻找邻近的四个像素点（实际），在二维空间进行的线性插值得到的最终混合值 双线型内插值算法就是一种比较好的图像缩放算法，它充分的利用了源图中虚拟点四周的四个真实存在的像素值来共同决定目标图中的一个像素值，因此缩放效果比简单的最邻近插值要好很多 $P(u,v)$是屏幕空间的坐标，屏幕空间左下角为$(0, 0)$，而左下角第一个像素的像素中心坐标为$(0.5, 0.5)$ The Center of the Pixel is (0.5,0.5) 立方卷积插值 兰索斯插值（不常见，性能开销大） Quilez 的光滑曲线插值 —— 在立方卷积插值与双线性插值的一个折中效果，画面表现效果要比双线性插值好，比立方卷积插值差 在纹理坐标带入到双线性插值过程之前再额外进行了一步处理 效果对比： d.2) 缩小 可能出现的问题：出现颜色丢失与闪烁（奈奎斯特定律） 解决方式： 最邻近、双线性插值（有限地增加采样频率） Mipmap（减小纹理频率）","text":"a). 什么是纹理一种可供着色器读写的结构化存储形式（采样器变量的形式，sampler） b). 纹理管线 模型空间位置→投影函数（不同与摄像机投影矩阵，是展UV其中一步）→纹理映射→纹理坐标→通讯函数→新纹理坐标→纹理采样（避免依赖纹理读取，如果片元着色器中不是使用顶点着色器中传递的数值，而是经过计算，那么就会产生依赖纹理读取，影响性能。因此，uv的偏移通常在顶点着色器中完成）→纹理值 c). Wrap Mode 简介： 决定uv[0, 1]以外的表现 OpenGL —— 包装模式（Wrapping Mode） DirectX —— 纹理寻址模式（Texture Addressing Mode） 类型： Repeat Mirror Clamp Border d). Filter Mode 在不同形状、大小、缩放比时，纹理过滤模式，可由专用硬件实现，也可由软件中实现，也可软硬件搭配完成 d.1) 放大（Magnification） 最近邻（性能消耗小，放大时每个像素读取最邻近的纹素，可能出现马赛克像素风格） 双线性插值——对于每一个像素点都寻找邻近的四个像素点（实际），在二维空间进行的线性插值得到的最终混合值 双线型内插值算法就是一种比较好的图像缩放算法，它充分的利用了源图中虚拟点四周的四个真实存在的像素值来共同决定目标图中的一个像素值，因此缩放效果比简单的最邻近插值要好很多 $P(u,v)$是屏幕空间的坐标，屏幕空间左下角为$(0, 0)$，而左下角第一个像素的像素中心坐标为$(0.5, 0.5)$ The Center of the Pixel is (0.5,0.5) 立方卷积插值 兰索斯插值（不常见，性能开销大） Quilez 的光滑曲线插值 —— 在立方卷积插值与双线性插值的一个折中效果，画面表现效果要比双线性插值好，比立方卷积插值差 在纹理坐标带入到双线性插值过程之前再额外进行了一步处理 效果对比： d.2) 缩小 可能出现的问题：出现颜色丢失与闪烁（奈奎斯特定律） 解决方式： 最邻近、双线性插值（有限地增加采样频率） Mipmap（减小纹理频率） e). Mipmap 特点：每一级纹理的大小都是上一级的1/4,因此整套纹理只比原来的单张多占1/3内存（等比数列） e.1) ddx、ddy(片元着色器指令，注意是在片元着色器中的！) GPU并不是一个个Pixel执行的，而是分成2*2的组，分块并行执行 通过ddx、ddy可对各种数据（uv、normal……）求偏导 ddx、ddy是x、y方向上的偏导数，通过ddx、ddy可对各种数据（uv、normal……）求偏导，可用于 mipmap：通过ddx、ddy求uv的偏导，得到的最长边用于确定mipmap的level 可求法线 三线性插值（待看） 特点：mipmap内存大1/3，但带宽压力变小（有时候只用传输小的贴图就行） 缺点：假设各向同性，但当缩放不一致（倾斜角过大）时可能模糊 解决方式：各向异性过滤（Anisotropic Filtering） f). 各向异性过滤（Anisotropic Filtering） 作用：减少模糊，保护在极端观察角度下的细节 当纹理在x坐标方向和在y坐标方向缩放的比例不一样，纹理的缩放是各异向的，Pmax/Pmin代表了各异向的程度。举个例子来说，64 x 64的纹理贴到一个开始平行于xy平面的正方形上，但是正方形绕y轴旋转60度，最后投影到屏幕上占了16 x 32的象素矩阵。纹理在x坐标方向上缩放的比例因子为64/16等于4，在y坐标方向缩放的比例因子为64/32等于2，Pmax等于4，Pmin等于2。缩放的各异向程度为2。(https://blog.csdn.net/u013467442/article/details/44466069) 各向异性过滤是一系列过滤方法，是搭配其他过滤方式一起使用的，常见的方法有Ripmap、积分图（SAT, Summed-Area Table）、重用mipmap等 f.1) Ripmap 做各种比例的预处理，部分解决问题 内存会大三倍 f.2) 积分图（SAT, Summed-Area Table） 每一位以更多位数储存，储存与左上纹素的总和（具体等看GAMES202补充） 右边表格的数据怎么来的呢？就跟图上上面的公式是一样的 比如2行2列的8 就是 2 + 3 + 3 + 0 再比如一行四列的8 就是 2 + 3 + 2 + 1以此类推 f.3) 重用Mipmap 不是用ripmap，而是重用mipmap，屏幕像素反向投影到纹理空间，通过纹理空间中长方形的最短边确定level。缩放的各异向程度后（看前面例子），创建各向异性线，穿过方块中心，根据程度，确定采样次数，并沿线段进行采样、混合 目前GPU一般支持16x的各向异性过滤 一般基于三线性过滤 g). CPU渲染优化常见方式 减少DrawCall 纹理图集、纹理数组 h). GPU渲染优化常见方式 降低显存带宽压力 纹理压缩 i). Other texturei.1) Cubemap 纹理左下角(0, 0) i.2) Bump Mapping i.3) Displacement Mapping 搭配曲面细分着色器 【Work】 Filter Mode： 纹理优化方式及其原理：","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"材质","slug":"材质","permalink":"https://whitetail-o.github.io/tags/%E6%9D%90%E8%B4%A8/"}]},{"title":"HPP_Art_3.1 动作理论基础","slug":"HPP_Art_03.1 动作理论基础","date":"2023-02-15T09:23:32.000Z","updated":"2023-03-17T04:43:44.446Z","comments":true,"path":"2023/02/15/HPP_Art_03.1 动作理论基础/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Art_03.1%20%E5%8A%A8%E4%BD%9C%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/","excerpt":"a). 动画基础知识 蒙皮： 定义骨骼数据如何驱动顶点数据； 引擎内不支持双四元数蒙皮，那使用线性混合蒙皮如何改善关节形状： JCM(Maya中叫PSD)：性能开销相对大； RBF：加几根辅助骨骼； b). 动画类型 逐帧动画：sprite（精灵）动画 骨骼动画：3D动画、spine动画（2D骨骼） 顶点动画：物理模拟后的动画数据，不便于用骨骼驱动，如布料，流体、破碎等 VAT(Vertex Animation Texture) VAT（Vertex Animation Texture）通常包括两张纹理：PositionTexture和RotationTexture。他们分别记录了一个Mesh在指定帧数下的位置、旋转变化。VAT的行坐标表示动画帧索引，列坐标表示对应顶点的位移数据。因此，VAT的高度一般对应整个动画的总帧数，而宽度对应着Mesh中根据Animation变化的顶点数。(https://zhuanlan.zhihu.com/p/585471941) Shader顶点动画 离线顶点动画 …….","text":"a). 动画基础知识 蒙皮： 定义骨骼数据如何驱动顶点数据； 引擎内不支持双四元数蒙皮，那使用线性混合蒙皮如何改善关节形状： JCM(Maya中叫PSD)：性能开销相对大； RBF：加几根辅助骨骼； b). 动画类型 逐帧动画：sprite（精灵）动画 骨骼动画：3D动画、spine动画（2D骨骼） 顶点动画：物理模拟后的动画数据，不便于用骨骼驱动，如布料，流体、破碎等 VAT(Vertex Animation Texture) VAT（Vertex Animation Texture）通常包括两张纹理：PositionTexture和RotationTexture。他们分别记录了一个Mesh在指定帧数下的位置、旋转变化。VAT的行坐标表示动画帧索引，列坐标表示对应顶点的位移数据。因此，VAT的高度一般对应整个动画的总帧数，而宽度对应着Mesh中根据Animation变化的顶点数。(https://zhuanlan.zhihu.com/p/585471941) Shader顶点动画 离线顶点动画 ……. c). 动画表现提升点c.1). IK 和 FK c.2). 动画质量和流畅度 好的动画看起来流畅——符合运动规律，运动轨迹是弧线 c.3). 打击感 合理的打击反馈，被打击方在受到攻击时一般会做出相应的受击反馈 受击、击退、击飞、浮空等受击反馈，浮空怪物下落的加速度、被击飞呈抛物线飞出 打击抽帧/顿帧 抽帧：省略动作的中间过程； 顿帧：动作的停顿，画面震动； 攻击节奏和按键反馈 大技能—小技能—小技能—大技能切换，保持一定节奏的攻击方式 硬直和打断 c.4). 夸张 挤压和拉伸 拖尾和变形 模仿视觉残留，在写实中是运动模糊。非写实则是模型形变 三维动画实现上比较麻烦，美式卡通更倾向于做模型上的挤压拉伸，但日式更多会做像速度线，色块残留的OBAKE（OBAKE：日式作画中表现高速运动的作画技巧） 不正确的透视 【动画原画笔记】透视不对？透视不对就对了！ 时间操控","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"美术","slug":"美术","permalink":"https://whitetail-o.github.io/tags/%E7%BE%8E%E6%9C%AF/"},{"name":"动画","slug":"动画","permalink":"https://whitetail-o.github.io/tags/%E5%8A%A8%E7%94%BB/"}]},{"title":"HPP_Graphics_1.2.3 MVP矩阵运算","slug":"HPP_Graphics_1.2.3 MVP矩阵运算","date":"2023-02-15T09:23:32.000Z","updated":"2023-03-17T04:46:56.263Z","comments":true,"path":"2023/02/15/HPP_Graphics_1.2.3 MVP矩阵运算/","link":"","permalink":"https://whitetail-o.github.io/2023/02/15/HPP_Graphics_1.2.3%20MVP%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97/","excerpt":"","text":"a). 简介MVP矩阵分别是模型(Model)、观察(View)、投影(Projection)三个矩阵。我们的顶点坐标起始于局部空间(Local Space),在这里它称为局部坐标(Local Coordinate),它在之后会变为世界坐标(World Coordinate),观察坐标(View Coordinate),裁剪坐标(Clip Coordinate),并最后以屏幕坐标(Screen Coordinate)的形式结束。下面的这张图展示了整个流程以及各个变换过程做了什么： b). M: 模型空间→世界空间 变换顺序 缩放 旋转 平移 \\mathbf{M_{model}}=\\left[\\begin{array}{llll} 1 & 0 & 0 & t x \\\\ 0 & 1 & 0 & t y \\\\ 0 & 0 & 1 & t z \\\\ 0 & 0 & 0 & 1 \\end{array}\\right]\\left[\\begin{array}{cccc} \\cos \\theta & 0 & \\sin \\theta & 0 \\\\ 0 & 1 & 0 & 0 \\\\ -\\sin \\theta & 0 & \\cos \\theta & 0 \\\\ 0 & 0 & 0 & 1 \\end{array}\\right]\\left[\\begin{array}{cccc} k x & 0 & 0 & 0 \\\\ 0 & k y & 0 & 0 \\\\ 0 & 0 & k z & 0 \\\\ 0 & 0 & 0 & 1 \\end{array}\\right] c). V: 世界空间→观察空间 变换顺序： 平移 旋转 Z分量取反（观察空间采用的是右手坐标系，而Unity则是左手坐标系） V=\\left[\\begin{array}{cccc} 1 & 0 & 0 & 0 \\\\ 0 & \\cos \\theta & -\\sin \\theta & 0 \\\\ 0 & \\sin \\theta & \\cos \\theta & 0 \\\\ 0 & 0 & 0 & 1 \\end{array}\\right]\\left[\\begin{array}{cccc} 1 & 0 & 0 & t x \\\\ 0 & 1 & 0 & t y \\\\ 0 & 0 & 1 & t z \\\\ 0 & 0 & 0 & 1 \\end{array}\\right]d). P: 观察空间→裁剪空间 不是真正的投影，为投影做准备 目的：判断顶点是否在可见范围内 P矩阵：对x,y,z分量进行缩放，用w分量做范围值。如果x,y,z都在w范围内，那么该点在裁剪空间内。 d.1) 正交矩阵d.2) 透视矩阵TODO: 推导各项矩阵 e). 光栅化补充 三角形设置：得到图元的边界条件，并对边进行插值； 三角形遍历：对单行进行插值","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"数学","slug":"数学","permalink":"https://whitetail-o.github.io/tags/%E6%95%B0%E5%AD%A6/"}]},{"title":"Games202-5 Non-Photorealistic Rendering (NPR)","slug":"Games202_05_Non-Photorealistic Rendering (NPR)","date":"2023-02-10T09:42:10.000Z","updated":"2023-02-12T13:17:53.768Z","comments":true,"path":"2023/02/10/Games202_05_Non-Photorealistic Rendering (NPR)/","link":"","permalink":"https://whitetail-o.github.io/2023/02/10/Games202_05_Non-Photorealistic%20Rendering%20(NPR)/","excerpt":"a). Photorealistic vs. Non-PhotorealisticPhotorealistic Rendering Non-Photorealistic Rendering 描边 色块（量化Quantization 颜色） 风格化阴影 b). Outline Rendering 边界（B, 属于剪影的线，但只属于一个面） 折痕（C） 材质的边界（M） 轮廓（CS, 属于剪影的线，且有多个面共享）","text":"a). Photorealistic vs. Non-PhotorealisticPhotorealistic Rendering Non-Photorealistic Rendering 描边 色块（量化Quantization 颜色） 风格化阴影 b). Outline Rendering 边界（B, 属于剪影的线，但只属于一个面） 折痕（C） 材质的边界（M） 轮廓（CS, 属于剪影的线，且有多个面共享） shading 法线和摄影机夹角：即轮廓都是grazing angle Geometry Image Soble算子做卷积 综合多种信息，如法线和深度等 c). Color blockers d). Strokes Surface Stylization","categories":[{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/categories/Games202/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Materials","slug":"Materials","permalink":"https://whitetail-o.github.io/tags/Materials/"},{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/tags/Games202/"},{"name":"NPR","slug":"NPR","permalink":"https://whitetail-o.github.io/tags/NPR/"}]},{"title":"Games202-4 Real-time Global Illumination(Screen Space)","slug":"Games202_04_Real-time Global Illumination(Screen Space)","date":"2023-02-10T08:52:10.000Z","updated":"2023-02-12T13:16:48.370Z","comments":true,"path":"2023/02/10/Games202_04_Real-time Global Illumination(Screen Space)/","link":"","permalink":"https://whitetail-o.github.io/2023/02/10/Games202_04_Real-time%20Global%20Illumination(Screen%20Space)/","excerpt":"a). Screen Space Ambient Occlusion(SSAO)a.1). Introduction SSAO: 在屏幕空间中，对全局光照的近似； Key idea: 假设各方向间接光照的强度相同（类似于Phong模型中的Ambition light） 考虑不同着色点，有不同的Visibility 假设材质为diffuse 假设间接光照来自于比较远的地方。因此，橙色的光线，即一定范围内不被遮挡的光线会贡献间接光。（如假设间接光来自比较近的地方，则是红色射线方向贡献间接光） a.2). Theory 通过不等式，拆分渲染方程为： $k_A$ 项代表不同方向Visibility的（加权）平均 黄色框可用一个Constant color表示 假设了间接光 $L_i^{indir}$ 各方向强度相同，因此为常数； 假设了材质为Diffuse，因此BRDF为常数； $cos\\theta$ 半球积分为$\\pi$ 同样，因为黄色框，即$g(x)$为常数，其Support极小。因此，应用该不等式是精确的 A deeper understanding 1: A deeper understanding 2:（为什么Visibility项会有$cos\\theta$） 加上 $cos\\theta$ 的含义是把积分域从单位半球投影到单位圆上(Projected solid angle)； 为什么要这么做呢？","text":"a). Screen Space Ambient Occlusion(SSAO)a.1). Introduction SSAO: 在屏幕空间中，对全局光照的近似； Key idea: 假设各方向间接光照的强度相同（类似于Phong模型中的Ambition light） 考虑不同着色点，有不同的Visibility 假设材质为diffuse 假设间接光照来自于比较远的地方。因此，橙色的光线，即一定范围内不被遮挡的光线会贡献间接光。（如假设间接光来自比较近的地方，则是红色射线方向贡献间接光） a.2). Theory 通过不等式，拆分渲染方程为： $k_A$ 项代表不同方向Visibility的（加权）平均 黄色框可用一个Constant color表示 假设了间接光 $L_i^{indir}$ 各方向强度相同，因此为常数； 假设了材质为Diffuse，因此BRDF为常数； $cos\\theta$ 半球积分为$\\pi$ 同样，因为黄色框，即$g(x)$为常数，其Support极小。因此，应用该不等式是精确的 A deeper understanding 1: A deeper understanding 2:（为什么Visibility项会有$cos\\theta$） 加上 $cos\\theta$ 的含义是把积分域从单位半球投影到单位圆上(Projected solid angle)； 为什么要这么做呢？ a.2.1). Simpler understanding 那么，我们怎么算 $k_A$ 项（不同方向Visibility的（加权）平均）呢？这就是AO算法实现的，如SSAO； 在计算AO时，我们计算的Visibility是限制在一定半径内的一个半球的局部遮挡。如在封闭的区域，如室内，如不限制半径，那Visibility将会为0。因此需要限制半径。 a.3). 实现 屏幕空间环境光遮蔽，全称Screen Space Ambient Occlusion，一种用于计算机图形中实时实现近似环境光遮蔽效果的渲染技术。通过获取像素的深度缓冲、法线缓冲以及像素坐标来计算实现，来近似的表现物体在间接光下产生的阴影。 做法总览（详情见百人计划图形4.2 SSAO）： 在法向半球内随机采样，采样点 $p$ 的深度$Z_p$与 点$p$ 在屏幕空间中对应位置 点$p’$ 的Z-Buffer中的深度$Z_{p’Zbuffer}$比较。 如 $Z_p&gt;Z_{p’Zbuffer}$，说明该采样点被遮蔽（红点），Visibility为0； 如 $Z_p&lt;Z_{p’Zbuffer}$，说明该采样点可见（绿点），Visibility为1； Cons： 由于是通过屏幕空间像素坐标和Z-Buffer取近似场景，只模拟了离屏幕最近的表面，对于一些点（如箭头所指的红点）的Visibility会误判；（从着色点看向该点可以看到，但SSAO中却将该点视为被遮蔽） 没有$cos\\theta $ 项的加权，因此在物理上是不准确的； [^SSAO]: 经过滤波后的SSAO $$ k_&#123;A&#125;=\\frac&#123;\\int_&#123;\\Omega^&#123;+&#125;&#125; V\\left(\\mathrm&#123;p&#125;, \\omega_&#123;i&#125;\\right) \\cos \\theta_&#123;i&#125; \\mathrm&#123;~d&#125; \\omega_&#123;i&#125;&#125;&#123;\\pi&#125; $$ - 采用了$cos\\theta $ 项的加权的算法：Horizon based ambient occlusion(HBAO) 由于SSAO中未考虑深度比较时采样点深度和Z-Buffer深度的差值，造成相距比较远的物体之间也会存在AO (HBAO解决了) b). Screen Space Directional Occlusion(SSDO)b.1). Introduction An imporovement over SSAO; 考虑了更准确的间接光照（不再假设各方向的间接光照相同） Key idea: 考虑了更准确的间接光照 使用已知的间接光源信息 如RSM得到的Secondary Light Source 的flux等； 效果： 间接光照更为准确，出现了color blooding 做法：（与Path Tracing非常相似） 着色 $p$点 时，发射随机光线； 如未被遮挡（无交点）： 该点受直接光照影响（如Ambient Light）； 如被遮挡（有交点）： 该点受间接光照影响； b.2). 实现 与SSAO相比： SSAO为被遮挡的光线的方向为间接光照贡献方向，SSDO则是被遮挡的光线方向为间接光照贡献方向； （SSAO）假设间接光照来自于比较远的地方。因此，橙色（被红圈圈起来的）的光线，即一定范围内不被遮挡的光线会贡献间接光。（如假设间接光来自比较近的地方（SSDO），则是红色射线（被橙圈圈起来的）方向贡献间接光） 间接光照的计算则可采用RSM、或者LPV、VXGI等； 具体做法： 和SSAO类似，在着色点P周围，一定半径的法向半球内进行随机给出采样点（A、B、C、D……），并和Z-Buffer中的深度进行比较； 如$Z_{sample} &gt; Z_{sample\\, Z-buffer}$ ，说明该点（A、B、D）被遮挡，该点则会对点P贡献间接光； 判断： 贡献间接光的Patch的方向是否会能贡献到，如点A ，${Normal_A}\\cdot \\vec{AP} &lt; 0$ ，则该点不贡献间接光； Reflector的反射方向只在法向半球上，法向半球的方向覆盖不到的Shading Point自然不受该Reflector的影响 如$Z_{sample} &lt; Z_{sample\\, Z-buffer}$ ，说明该点（A、B、D）未被遮挡，该点则不会对点P贡献间接光，而是贡献直接光（Ambition Light）； 缺点： 如上图最右 b.3). Issues 只能计算小范围的AO； 是通过采样点深度和Z-buffer比较得出Visibility，而不是从P点出射光线计算交点，导致Visibility不精准； 屏幕空间的通病： 失去了屏幕中未被显示（如屏幕外）的表面的信息； 屏幕空间只能表现场景最表面(Depth最小)的一层“壳”； c). Screen Space Reflection(SSR)c.1). IntroductionWhat is SSR? Still, one way to introduce Global Illumination in RTR; 执行上为光线追踪； 光线追踪的求交并不要求3D图元，而是屏幕空间的一层“壳”（通过Z-Buffer还原的场景） Two fundamental tasks of SSR： 求交：任何光线和场景； 着色：交点对Shading point的贡献； 效果： 可实现Specular reflection和Gloosy reflection； 对于Specular只用追踪镜面反射方向即可； 对于Gloosy知道BRDF后需追踪入射方向的Lobe； c.2). 实现 Two fundamental tasks of SSR： 求交：任何光线和场景； 着色：交点对Shading point的贡献； c.2.1). Intersection（求交） 使用光线步进（Raymarch），那么如何确定步进的步长？ Hierarchical tracing 不想一层一层步进，而是允许时步长变大； Hierarchical tracing Step1: Generate Depth Mip-Map(使用最小池化，而不是平均) 取最小： 如2x2的像素中，取最小深度值作为下一层该位置的深度； 最小池化构造出类似与KD-tree的结构； 逻辑： 取最小后，如果光线不和父（更大的）节点相交，那就不会和子节点相交； P-Code 开始在Mip0层步进 没交点则进入下一层Mip（父节点）； 有交点则进入上一层Mip（子节点），并在交点对应位置的子节点继续求交； 直到找到Mip0层的交点，结束循环；（演示看PPT） c.2.2). Shading Shading过程和Path tracing相似； 假设： Reflectors(反射物)/ Secondary light source是Diffuse的 原因： 生成Shaded场景时，只知道屏幕空间下一个点的Radiance（即Shading Point到Camera的Radiance）。如假设Reflector为Diffuse，那么该点的$L_i$就为framebuffer中的颜色； c.2.3). 效果 可实现锐利或模糊的反射； Contact hardening（接触的地方反射较为锐利，类似PCSS） Specular elongation 类似雨天红绿灯反射垂直拉长的效果； 给定视角后，各项同性的法线分布，造成的反射Lobe为垂直方向椭圆的Lobe； 每个像素不同的Roughness和Normal c.3). Issues Edge Cutoff 缓解方法：根据反射长度进行Fade off d). Pros And Cons","categories":[{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/categories/Games202/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/tags/Games202/"},{"name":"GI","slug":"GI","permalink":"https://whitetail-o.github.io/tags/GI/"}]},{"title":"Games202-4 Real-time Global Illumination(in 3D)","slug":"Games202_04_Real-time Global Illumination(in 3D)","date":"2023-02-10T08:42:10.000Z","updated":"2023-02-12T13:16:55.513Z","comments":true,"path":"2023/02/10/Games202_04_Real-time Global Illumination(in 3D)/","link":"","permalink":"https://whitetail-o.github.io/2023/02/10/Games202_04_Real-time%20Global%20Illumination(in%203D)/","excerpt":"a). Introduction In RTR, people seek simple and fast solutions to one bounce indirect illumination Primary LIght Source（真正的光源，太阳） Secondary Light Source(次级光源，Q点) 观察（要得到$p$点的间接光照我们需要做什么）： 得到Secondary light source（哪些点被光源照射到） 方法： Shadow Mapping 得到各个Secondary light source对 $p$点 Radiance的贡献 方法： 解渲染方程 以下是实时渲染中常用的在3D空间中（意为渲染效果不取决于相机位置/屏幕空间）的GI方法（主要针对one bounce indirect illumination）： Reflective Shadow Maps (RSM) Light Propagation Volumes (LPV) Voxel Global Illumination (VXGI) b). Reflective Shadow Maps (RSM) 得到Secondary light source（哪些点被光源照射到） Shadow map中每一个Texel都是一个作为Secondary light sourc的面片（Surface patch） Shadow map做阴影中是光源视角的$Depth$，和相机视角的比较；这里是光源视角的$Depth$和 点$p$ 视角比较 得到各个Secondary light source对 $p$点 Radiance的贡献 但是，对于不同的 点$p$ 次级光源入射方向是不一定的。即，即使观察角度固定，同一个Shadow map中的Surface patch，对不同的 $p$ 贡献不同； 假设： 次级光源均为Diffuse（观察角度固定，同一个次级光源对不同 点$p$ 的贡献相同） Therefore, outgoing radiance is uniform toward all directions b.1). 得到各个Secondary light source对 $p$点 Radiance的贡献 \\begin{aligned} L_{o}\\left(\\mathrm{p}, \\omega_{o}\\right) & =\\int_{\\Omega_{\\mathrm{patch}}} L_{i}\\left(\\mathrm{p}, \\omega_{i}\\right) V\\left(\\mathrm{p}, \\omega_{i}\\right) f_{r}\\left(\\mathrm{p}, \\omega_{i}, \\omega_{o}\\right) \\cos \\theta_{i} \\mathrm{~d} \\omega_{i} \\\\ & =\\int_{A_{\\mathrm{patch}}} L_{i}(\\mathrm{q} \\rightarrow \\mathrm{p}) V\\left(\\mathrm{p}, \\omega_{i}\\right) f_{r}\\left(\\mathrm{p}, \\mathrm{q} \\rightarrow \\mathrm{p}, \\omega_{o}\\right) \\frac{\\cos \\theta_{p} \\cos \\theta_{q}}{\\|q-p\\|^{2}} \\mathrm{~d} A \\end{aligned} 对于每个diffuse reflective patch(点$q$) 点$q$ 的BRDF: $f_{rq} = \\rho/\\pi$ $L_i(q\\rightarrow p) = f_{rq} \\cdot \\frac{\\Phi}{d A}$ ( $\\Phi$ 是光源的辐射通量，将该式带入渲染方程，${d A}$ 被消除) E_{q}(x,n)=\\Phi_{q}\\frac{\\mathrm{max}\\{0,\\langle n_{q}|x-x_{q}\\rangle\\}\\mathrm{max}\\{0,\\langle n|x_{q}-x\\rangle\\}}{||x-x_{q}||^{4}}. ${||x-x_{q}||^{4}}$ 是因为分子上$x-x_{q}$是未归一化的向量； $\\Phi_p$ 为 $f_{rq} \\cdot {\\Phi}$ 将$E_p(x,n)$ 乘上 点$p$ 的BRDF即可得出$L_o$ $V$：Visibility项就不算了 Not all pixels in the RSM can contribute Visibility (难处理，不管了) Orientation（方向，Reflector的反射方向只在法向半球上，法向半球的方向覆盖不到的Shading Point自然不受该Reflector的影响） Distance（只有和Shading Point近的Reflector才做贡献） 假设： 世界坐标下，两点接近 $\\rightarrow$ Shadow Map（世界空间转换到光源空间）中距离比较近，且深度相差不大； 进一步加速（类似于Step 1 and 3 in PCSS），在shading point转换到Shadow Map后对应点$(s,t)$ 的一定范围内，做随机采样 b.2). 光源视角下储存的信息（Shadow Map） 深度 世界坐标 法线 辐射通量（flux） etc. b.3). Pros And Cons Pros: 好写（类似于Shadow Map） Cons: 计算量随光源（Primary Light Source）数量增多线性增加 Visibility无法处理 很多假设：diffuse reflectors, depth as distance, etc. 只能处理次级光源为Diffuse 质量依赖于采样率","text":"a). Introduction In RTR, people seek simple and fast solutions to one bounce indirect illumination Primary LIght Source（真正的光源，太阳） Secondary Light Source(次级光源，Q点) 观察（要得到$p$点的间接光照我们需要做什么）： 得到Secondary light source（哪些点被光源照射到） 方法： Shadow Mapping 得到各个Secondary light source对 $p$点 Radiance的贡献 方法： 解渲染方程 以下是实时渲染中常用的在3D空间中（意为渲染效果不取决于相机位置/屏幕空间）的GI方法（主要针对one bounce indirect illumination）： Reflective Shadow Maps (RSM) Light Propagation Volumes (LPV) Voxel Global Illumination (VXGI) b). Reflective Shadow Maps (RSM) 得到Secondary light source（哪些点被光源照射到） Shadow map中每一个Texel都是一个作为Secondary light sourc的面片（Surface patch） Shadow map做阴影中是光源视角的$Depth$，和相机视角的比较；这里是光源视角的$Depth$和 点$p$ 视角比较 得到各个Secondary light source对 $p$点 Radiance的贡献 但是，对于不同的 点$p$ 次级光源入射方向是不一定的。即，即使观察角度固定，同一个Shadow map中的Surface patch，对不同的 $p$ 贡献不同； 假设： 次级光源均为Diffuse（观察角度固定，同一个次级光源对不同 点$p$ 的贡献相同） Therefore, outgoing radiance is uniform toward all directions b.1). 得到各个Secondary light source对 $p$点 Radiance的贡献 \\begin{aligned} L_{o}\\left(\\mathrm{p}, \\omega_{o}\\right) & =\\int_{\\Omega_{\\mathrm{patch}}} L_{i}\\left(\\mathrm{p}, \\omega_{i}\\right) V\\left(\\mathrm{p}, \\omega_{i}\\right) f_{r}\\left(\\mathrm{p}, \\omega_{i}, \\omega_{o}\\right) \\cos \\theta_{i} \\mathrm{~d} \\omega_{i} \\\\ & =\\int_{A_{\\mathrm{patch}}} L_{i}(\\mathrm{q} \\rightarrow \\mathrm{p}) V\\left(\\mathrm{p}, \\omega_{i}\\right) f_{r}\\left(\\mathrm{p}, \\mathrm{q} \\rightarrow \\mathrm{p}, \\omega_{o}\\right) \\frac{\\cos \\theta_{p} \\cos \\theta_{q}}{\\|q-p\\|^{2}} \\mathrm{~d} A \\end{aligned} 对于每个diffuse reflective patch(点$q$) 点$q$ 的BRDF: $f_{rq} = \\rho/\\pi$ $L_i(q\\rightarrow p) = f_{rq} \\cdot \\frac{\\Phi}{d A}$ ( $\\Phi$ 是光源的辐射通量，将该式带入渲染方程，${d A}$ 被消除) E_{q}(x,n)=\\Phi_{q}\\frac{\\mathrm{max}\\{0,\\langle n_{q}|x-x_{q}\\rangle\\}\\mathrm{max}\\{0,\\langle n|x_{q}-x\\rangle\\}}{||x-x_{q}||^{4}}. ${||x-x_{q}||^{4}}$ 是因为分子上$x-x_{q}$是未归一化的向量； $\\Phi_p$ 为 $f_{rq} \\cdot {\\Phi}$ 将$E_p(x,n)$ 乘上 点$p$ 的BRDF即可得出$L_o$ $V$：Visibility项就不算了 Not all pixels in the RSM can contribute Visibility (难处理，不管了) Orientation（方向，Reflector的反射方向只在法向半球上，法向半球的方向覆盖不到的Shading Point自然不受该Reflector的影响） Distance（只有和Shading Point近的Reflector才做贡献） 假设： 世界坐标下，两点接近 $\\rightarrow$ Shadow Map（世界空间转换到光源空间）中距离比较近，且深度相差不大； 进一步加速（类似于Step 1 and 3 in PCSS），在shading point转换到Shadow Map后对应点$(s,t)$ 的一定范围内，做随机采样 b.2). 光源视角下储存的信息（Shadow Map） 深度 世界坐标 法线 辐射通量（flux） etc. b.3). Pros And Cons Pros: 好写（类似于Shadow Map） Cons: 计算量随光源（Primary Light Source）数量增多线性增加 Visibility无法处理 很多假设：diffuse reflectors, depth as distance, etc. 只能处理次级光源为Diffuse 质量依赖于采样率 c). Light Propagation Volumes(LPV) CryEngine3 里用到了，在孤岛危机里应用 快而且质量好 同样也只能处理次级光源为Diffuse Key idea: 光线直线传播中，Radiance大小不变； Key solution: 通过3D网格(体素，Voxel)，传播Secondary Light Source/dirctly illminated surfaces的Radiance到其他地方； Steps: 生成场景中被直接光照照射到的Radiance point(即Secondary light source)； 将Radiance point注入到体素中； Radiance在体素中传播； 传播稳定后（一般迭代4、5次），通过体素中储存的Radiance进行Shading； c.1). 做法Step 1: Generation 找到Secondary light source 使用Reflective Shadow Maps (RSM)； Step 2: Injection(注入) 预先划分好3D网格（体素）； 对于每一个体素，找到其内部的Secondary light source； 将他们出射的Radiance大小和方向看做是球面函数，投影到2阶（4个）的球谐函数上； Step 3: Propagation(传播) 对于每一个Voxel，都会传播到相邻的6个面（3D，前后左右上下，不会斜向传播），也会接收6个面的Radiance； 接收6个面的Radiance并相加后，再次使用SH表示； 重复上述步骤，直至传播接近稳定（一般整体迭代4-5次） Step4: Rendering 对于每一个着色点，找到他们所处的Voxel； 使用该Voxel中存储的Radiance（from all direction, 是一个SH表达的球面函数），进行Shading； 因为存储的是球面函数形式的Radiance，所以既可以做Diffuse也可以做Gloosy 造成的问题： 由于同一个Voxel中Radiance相同，对于薄的几何体可能造成Light leaking d). Voxel Global Illumination (VXGI) 与RSM两点主要的不同 将被光源直接照射的像素变为带有层级的体素（hierarchical voxels）（即Secondary light source不再看成surface patch，而是hierarchical voxels） 光线传播方式： 从摄像机开始传播，进行锥形传播（Cone tracing，比如光线在Gloosy表面弹射，出射方向为一个锥形），计算锥体相交的Voxel对该点的Radiance贡献； d.1). 做法 Pass 1: from the light 储存每个点的入射Radiance，并储存到对应的Voxel中； Voxel中存储Incident lighting和normal的分布，以便支持Gloosy等材质； 存储Lobe分布的基础：Cone Trace 根据这两个分布，即可得出 出射Radiance 的分布情况； Pass 2: from the camera 对于Gloosy的表面，追踪1个朝向反射方向的圆锥； 根据圆锥的（grow）大小，查询相应层级； 对于Diffuse，追踪多个Cones","categories":[{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/categories/Games202/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/tags/Games202/"},{"name":"GI","slug":"GI","permalink":"https://whitetail-o.github.io/tags/GI/"}]},{"title":"HPP_Art_2.7 Metallic与Speculer流程","slug":"HPP_Art_02.7_Metallic与Speculer流程","date":"2023-02-03T09:23:32.000Z","updated":"2023-02-04T06:49:27.828Z","comments":true,"path":"2023/02/03/HPP_Art_02.7_Metallic与Speculer流程/","link":"","permalink":"https://whitetail-o.github.io/2023/02/03/HPP_Art_02.7_Metallic%E4%B8%8ESpeculer%E6%B5%81%E7%A8%8B/","excerpt":"a). PBR模型基于物理的渲染模型，是当前主流游戏引擎使用的真实感3D渲染模型。 a.1). 两种工作流游戏资源中常见的贴图类型 PBR Guide PBR流程中，常用的有两种工作流程： 金属/粗糙度工作流(Metal/Roughness) 符合直觉，容易调参 更不容易打破能量守恒 高光（镜面反射）/光泽度（Specular/Glossiness）工作流 可自由调节$F_0$（零度菲涅尔反射）值 容易打破能量守恒 a.2). F0反射率值 大多数常用的电介质的F0范围从0.02-0.05（线性值）。对于导体，F0值 范围为0.5-1.0。因此表面的反射率由折射率决定，正如下面的方程式所示（Lagarde 2011）。 图1. 金属和非金属的$F_0$​值 &#8617; 图2. 电介质$F_0$值和金属反射率值 &#8617; 通用贴图：法线贴图、AO贴图、高度贴图等","text":"a). PBR模型基于物理的渲染模型，是当前主流游戏引擎使用的真实感3D渲染模型。 a.1). 两种工作流游戏资源中常见的贴图类型 PBR Guide PBR流程中，常用的有两种工作流程： 金属/粗糙度工作流(Metal/Roughness) 符合直觉，容易调参 更不容易打破能量守恒 高光（镜面反射）/光泽度（Specular/Glossiness）工作流 可自由调节$F_0$（零度菲涅尔反射）值 容易打破能量守恒 a.2). F0反射率值 大多数常用的电介质的F0范围从0.02-0.05（线性值）。对于导体，F0值 范围为0.5-1.0。因此表面的反射率由折射率决定，正如下面的方程式所示（Lagarde 2011）。 图1. 金属和非金属的$F_0$​值 &#8617; 图2. 电介质$F_0$值和金属反射率值 &#8617; 通用贴图：法线贴图、AO贴图、高度贴图等 b). Metal/Roughness工作流b.1). Base color(RGB-sRGB)储存数据： 非导体 的漫反射颜色/反照率颜色（Diffuse Reflected Color/Albedo） 金属导体 的镜面反射$F_0$值 非导体使用4%(0.04) 的$F_0$反射值（在一些软件中可以自定义） 混合材质（即非导体和金属导体混合材质，如锈蚀）则可以认为同时储存了两种数据 注意事项： 非导体（即电介质，非金属）： 暗色值，尽量不要低于30-50sRGB，严格控制下应不低于50sRGB。对于亮色值，贴图中不应高于240sRGB； 导体（金属）： 金属一般会有70-100%的镜面反射，映射到sRGB大概为180-255； 在SP中，可通过滤镜中的PBR检查；SD可通过PBR BaseColor/Metallic Validate节点验证是否在合适范围内； BaseColor中除了微观遮蔽信息（Micro-occlusion）以外，不应包含任何光照信息； b.2). Metallic(Grey-Linear)储存数据： 对应区域的金属度。0.0纯黑代表非金属，1.0纯白代表纯金属。 注意事项： 纯金属灰度范围在235-255 sRGB，其对应的反射率范围为70%-100%（180-255sRGB） 在Metallic贴图中，纯黑(0.0)代表了非金属，纯白(1.0)代表了金属，我们可以用过渡的灰阶来表示不同程度氧化和污垢； 对于金属，如Metallic低于235 sRGB，在BaseColor中反射率值应降低。（如一个地方锈蚀特别严重，Metallic低于235sRGB，那么需要降低BaseColor）； b.3). Roughness(Grey-Linear) Roughness中，纯黑（0.0）代表平滑表面，纯白（1.0）代表粗糙平面。 这改变了光的方向，但是光强度保持恒定不变。表面越粗糙，高光越散越暗。表面越光滑，高光反射集中，尽管反射的光的总量是一点的，表面也会更亮，光会更强。 c). Specular/Glossiness工作流c.1). Diffuse(RGB-sRGB)储存数据： 漫反射颜色（Albedo） 注意事项： Diffuse贴图表示的是漫反射颜色，Raw Metal没有漫反射，因此为纯黑（0.0）。如果发生氧化现象，金属区域就会有颜色； Diffuse中除了微观遮蔽信息（Micro-occlusion）以外，不应包含任何光照信息； 除了表示金属的纯黑（0.0）外，暗色值不应低于30sRGB，严格上说，不应该低于50sRGB； 亮色值不应该高于240sRGB； c.2). Specular(RGB-sRGB)储存数据： $F_0$（0度菲涅尔反射值） 注意事项： 镜面反射贴图包含$F_0$值； 普遍非导体的反射值为2-5%（线性），对应40-75 sRGB； 普通宝石的反射值范围在0.05-0.17（线性）； 普通液体的反射值范围在0.02-0.04（线性）； 而原始金属（Raw Metal）的反射值则可以高达70-100%的镜面反射，sRGB约为180-255； 如果你无法找到某个材质的折射率(IOR)，可以先假设F0为4%，也就是塑料的F0。 c.3). Glossiness(Grey-Linear)储存数据： 对应区域的光泽度。0.0纯黑代表粗糙，1.0纯白代表光滑。和金属工作流的Roughness为反相的关系； d). Metallic vs. Specular 边缘效应： 金属工作流导致金属和非金属的边缘出现白色边界 高光工作流导致金属和非金属边缘出现黑色伪影 原因： 纹理插值（放大），贴图分辨率和Texel密度直接影响边界伪影的可见度 解决方法： 尽可能使纹理的UV利用率高； Metallic/Roughness流程 Specular/Glossiness流程 优势 1. 在M/R工作流中，由于非导体（电介质）的FO都是规定好的所以设计师在对非导体FO赋值时不易出错。2. 纹理的缓存压力更小，因为金属贴图和粗糙度贴图都是灰度贴图。3. 目前来说是兼容性最广的工作流。 1. 边缘效应不会那么明显。2. 可以在镜面反射贴图中对非导体（电介质）材质的F0值自由调整。 劣势 1. 非导体（电介质）F0的值固定为4%，无法调整。然而，在大多是实现流程中都有控制器可以直接复写这个值，所以也不能算硬伤。2.白色边缘问题较明显，尤其在低分辨率的情况下问题突出。 1. 由于在S/G工作流的镜面反射贴图中，非导体（电介质）材质的℉0值是可以自由调整的，所以也会导致设计师容易输入错误的值。而这些错误的值被着色器误读后可能会打破能量守恒定律，从而造成不正确的渲染效果。2.由于新增了一张RGB通道的镜面反射贴图，所以对性能消耗会更大。3. S/G工作流有些名词和传统的工作流太相似，但是实质所对应的数据可能是不样的，因此会导致设计师容易误解或误操作。这种情况下就要求设计师有更好的PBR理论知识，例如了解非导体（电介质）的正确FO值，金属在漫反射色下表现为纯黑，以及在着色器没有自动校正情况下，能量守恒相关的基础知识。 e). Metallic和Specular流程的贴图转换（PS演示）金属工作流各贴图含义： 贴图 含义 Base color 漫反射颜色+镜面反射$F_0$ Metallic 材质区分，辅助解读Base color Roughness 表面状态参数 高光工作流各贴图含义： 贴图 含义 Diffuse 漫反射颜色 Specular 镜面反射$F_0$ Glossiness 表面状态参数（Roughness反相） e.1). Metallic流程 → Specular流程BaseColor + Metallic → Diffuse 方法： 去掉Base Color中金属和混合材质的$F_0$数据 实操： 打开BaseColor和Metallic，RGB模式 新建Diffuse图层，纯黑填充； 选择Metallic任一通道，得到带灰度的区域$a$； Diffuse图层新建区域 $a$ 的蒙版，底层为BaseColor； BaseColor + Metallic → Specular 方法： 去掉BaseColor中的漫反射数据，并加上非导体和混合材质的$F_0$ （默认0.04，56 sRGB，#383838） 实操： 打开BaseColor和Metallic，RGB模式 新建Specular图层，填充#383838（0.04对于22-Linear，对应56 sRGB，即#383838）； 反相Metallic，选择Metallic任一通道，得到带灰度的区域$b$； Specular图层新建区域 $b$的蒙版，底层为BaseColor； Roughness → Glossiness 方法： 反相 e.2). Specular流程 → Metallic流程Diffuse + Specular → BaseColor + Metallic 方法： 找出金属区域对应的数据，金属的特性是$F_0$在0.7-1.0之间，而非金属一般不超过0.04（宝石最高0.17），差异明显。 实操： Specular,菜单选择，色彩范围，选择阴影，灰度预览，调整参数。（也可以使用Diffuse图层)(效果不好的话可以将阴影换为取样颜色，选择纯黑，调整容差)shift+ctrl+i反选，创建蒙版。 alt+左键拖动蒙版到Diffuse图层，选择蒙版，ctrl+i反相。Base color完成 新建Metallicl图层，填充黑色，ctrl+左键点击Specular蒙版进行选区，填充白色。Metallic完成 Glossiness → Roughness 方法： 反相 Homework高光工作流转金属工作流 对比： 金属工作流转高光工作流 对比： 乍一看，经过两次转换（原资源为高光工作流，经过PS转为金属工作流后又转到高光工作流），表面上看起来区别不大，但其实已经有所变化，因此，需要在PS中多次尝试； 图3. 左侧为原Specular贴图，右侧为转换两次后的Specular贴图，可以看到已经丢失了许多细节； &#8617;","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"美术","slug":"美术","permalink":"https://whitetail-o.github.io/tags/%E7%BE%8E%E6%9C%AF/"},{"name":"模型制作流程","slug":"模型制作流程","permalink":"https://whitetail-o.github.io/tags/%E6%A8%A1%E5%9E%8B%E5%88%B6%E4%BD%9C%E6%B5%81%E7%A8%8B/"}]},{"title":"HPP_Art_2.5 模型常见问题及规范","slug":"HPP_Art_02.5_模型常见问题及规范","date":"2023-02-03T07:23:32.000Z","updated":"2023-02-04T06:49:15.824Z","comments":true,"path":"2023/02/03/HPP_Art_02.5_模型常见问题及规范/","link":"","permalink":"https://whitetail-o.github.io/2023/02/03/HPP_Art_02.5_%E6%A8%A1%E5%9E%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%84%E8%8C%83/","excerpt":"a). 布线合理性 动画角度： 横平竖直，均匀清晰，结构线密度足够（动画线一般为三根）（动画线即关节线：脖子，肩膀，肘关节，腰，膝关节，踝关节），由于肘关节和膝关节一般是单向弯曲，所以在面数有限的情况下，也可以使用前三后二的布线 模型角度： 尽量把线使用在体现剪影上，单纯的在平面上加线是没有意义的，平面上的细节会在之后的制作中用法线来体现 注意事项1：多星点 多星点（度大于4的顶点）：如果是在中模阶段，减少使用多星点，因为会在细分时出现凸点的问题，如果要使用多星点，请通过布线技巧把它移动至平面处，不要让它出现在倒角边缘。 在模型上挖洞，且要保证都是四边面的情况下，是必然会出现五星点的，五星点不可避免，但可以优化。也有把五星点转换为假四边的方法（模型师把这种布线叫做假四边） 五星点同样会影响点法线。 如使用了面积权重，那可能会导致点法线发生偏移。 注意事项1：预连接对于”不在同一个平面“的四边形，不同软件的预连接是不同的。 所以如果四边形的四个点不在一个平面里时，请连接对角线，否则会出现如下图情况，这个同样会影响到之后的法线烘焙。","text":"a). 布线合理性 动画角度： 横平竖直，均匀清晰，结构线密度足够（动画线一般为三根）（动画线即关节线：脖子，肩膀，肘关节，腰，膝关节，踝关节），由于肘关节和膝关节一般是单向弯曲，所以在面数有限的情况下，也可以使用前三后二的布线 模型角度： 尽量把线使用在体现剪影上，单纯的在平面上加线是没有意义的，平面上的细节会在之后的制作中用法线来体现 注意事项1：多星点 多星点（度大于4的顶点）：如果是在中模阶段，减少使用多星点，因为会在细分时出现凸点的问题，如果要使用多星点，请通过布线技巧把它移动至平面处，不要让它出现在倒角边缘。 在模型上挖洞，且要保证都是四边面的情况下，是必然会出现五星点的，五星点不可避免，但可以优化。也有把五星点转换为假四边的方法（模型师把这种布线叫做假四边） 五星点同样会影响点法线。 如使用了面积权重，那可能会导致点法线发生偏移。 注意事项1：预连接对于”不在同一个平面“的四边形，不同软件的预连接是不同的。 所以如果四边形的四个点不在一个平面里时，请连接对角线，否则会出现如下图情况，这个同样会影响到之后的法线烘焙。 b). UV合理性 UV基础规范：如果是使用UDIM（多象限UV），从【0,1】框开始依次摆放，正常情况下全部UV放于【0,1】框内，虽然UV是平铺的，但是我们常用的软件，例如SP，绘制过程中，只能在【0,1】框中绘制 提高UV利用率： 打直UV 可进行均匀缩放（但非均匀缩放大部分情况是不允许的） 公用UV注意事项： 对于公用的UV（比如一条左右纹理相同的裤子，为了节省UV空间，使得左半边和右半边UV重叠），在烘焙时，如果有公用的UV需要挪出【0,1】框，如果不挪出去烘焙时会识别不了你需要烘哪一边作为结果，导致得到的法线贴图出现错误 硬边的地方UV必须断开，否则会出现接缝 UV接缝的两侧对最好是对齐状态，特别是使用Tiling贴图时 c). 光滑组（软硬边） 值得注意的是，在三维软件中（maya，max）导出模型法线会处于锁定状态，而导入模型后解锁法线，由于maya和max定义软硬边的方式不同（maya直接对边定义软硬边，max通过定义面的光滑组定义软硬边），会导致光滑组/软硬边丢失，可以通过插件实现在保持软硬边的情况下解锁法线，也就是先记录软硬边信息再去解锁，解锁后重新赋予即可 由于定义了软硬边，后期的烘焙过程中，烘焙时拾取的是你最后使用的模型的点的法线，如果你在烘焙结束后又去修改了软硬边信息，正常情况下软硬边信息不对等的地方法线会出现错误。简而言之就是，烘焙的信息是对于当前光滑组的信息，光滑组修改了就要重新烘焙。 d). 检查1.该合并的点全部合完了 2.没有非法面，N边面等不规范面的存在 3.有UV，用于贴图 4.不出现镂空面穿帮 5.场景大小设置正确 6.拥有规范命名，方便资产整理（模型一般前缀使用“SM_”，及static mesh） 7.Maya模型请检查历史清除干净没有，Max模型请塌陷编辑器 8.模型的坐标轴归零（习惯问题，否则进入引擎后你可能法线坐标轴不在你模型的周围） 9.进入引擎前最好三角面化 e). 命名及存储规范 规范内容 修改建议 文件及文件夹命名 统一命名规范，方便管理；分类整理，不同用途的文件在不同的文件夹中（可详细定制） 存放文件夹 角色模型-/char 场景模型-/scene 道具模型-/prop 动画-/anim 命名规范之前后缀（导出后） 特效_vfx 带通道图_al 模型SM_ 命名规范（模型）（导出前） Door-red-01 命名规范（贴图）（导出前） Door-red-01-cm/sm/nm 命名规范（材质球）（导出前） Door-red-01-mat 贴图命名 无中文、不重名，带有A通道的导出TGA或PNG（后缀_al） f). 制作规范 规范内容 修改建议 单位 在建模软件中正确的设置单位 方向 根据不同的使用场景（如从Max到unity）保持方向统一 顶点数与面数 建模时的数量信息可能和导出后不一致（例如1个点对应不同UV点后，会在Unity中变成2个点），注意减少面数 面数控制 设定一个具体的面数范围（针对不同的性能需求），我没经验我也不知道 顶点属性 建模中清除掉不必要的顶点属性信息（如删除没用到的UV2，UV3，只保留一套） 骨骼绑定 IK、CAT、BIP，其他Unity不认，单个物体骨骼数量限制为具体个数 动画帧数 约定每秒多少帧，一个动画多少秒 贴图格式和尺寸 文件尺寸为2的n次方、确定具体最大的贴图尺寸 UV 打直UV，提高利用率，减少不均匀的拉伸，烘焙时，共用的UV移出01框（如重叠的UV），断开硬边避免接缝，接缝处的UV两边对齐，避免Tiling时出现错误 布线合理性 低模中减少不必要的线，增加关节处的线，避免五星线出现在卡线上，连接好边再导出，注意布线导致的法线方向错误 光滑组 展UV时断开硬边，注意法线的锁定问题 g). 完成导出检查 规范内容 修改建议 坐标归零 制作完成后坐标轴归零，根据实际场景选择不同的零点 检查模型 检查反面、废点、废线、废面、不规范面，完成后重置变换 优化模型 删除不必要的面、合并顶点、在特定部位进行修改（关节处增加线） 模型导出 清除场景中不必要的物件，清除历史记录、塌陷编辑器 贴图支持 检查使用场景下，导出的贴图是否被支持 蒙皮、动作调节 见动画规范表（暂无） 动画导出 导出只有动画的fbx 导入法线锁定 注意重新设置软硬边或光滑组","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"美术","slug":"美术","permalink":"https://whitetail-o.github.io/tags/%E7%BE%8E%E6%9C%AF/"},{"name":"模型制作流程","slug":"模型制作流程","permalink":"https://whitetail-o.github.io/tags/%E6%A8%A1%E5%9E%8B%E5%88%B6%E4%BD%9C%E6%B5%81%E7%A8%8B/"}]},{"title":"HPP_Art_2.3 硬表面基础","slug":"HPP_Art_02.3_硬表面基础","date":"2023-02-03T05:23:32.000Z","updated":"2023-02-04T06:49:21.036Z","comments":true,"path":"2023/02/03/HPP_Art_02.3_硬表面基础/","link":"","permalink":"https://whitetail-o.github.io/2023/02/03/HPP_Art_02.3_%E7%A1%AC%E8%A1%A8%E9%9D%A2%E5%9F%BA%E7%A1%80/","excerpt":"a). 什么是硬表面 从外表/建模来说：有着重工业质感、该平滑的时候平滑，该硬朗的时候硬朗。即平的平，弯的弯。 从光影来说：光影变化均匀，硬朗，有经过打磨的感觉。 需要区别于LowPoly，Lowpoly有种纸片的拼凑感，更像是纸膜，主要是倒角所给予硬表面的厚度。即缺少最重要的倒角。 b). 如何制作硬表面（高模上倒角方法） 在游戏中硬表面通常是使用低模进行体现。因为硬表面的质感很大程度上取决于倒角。倒角会很大的增加模型面数。对于一些较小的结构，小凹槽，实际在低模上进行倒角或者卡边做出结构是不太划算的。本质上是要让高光的呈现更加集中，如果高光过于散开，就会显得较软，漂亮的高光边会表现很强的质感。 b.1). 卡双线 第一对线用于Smooth后形成倒角，第二对线用于收敛高光 b.2). 方倒角 对两个倒角卡双线 b.3). 直接倒角效果最好，可得到漂亮的高光边，但是因为增加的边数很多，过于密集，修改起来麻烦。 b.4). 光滑组（软硬边）+ 卡单线 通过将两个面设为同一光滑组（Maya里则将连接边设为软边）+ 两边各卡一条线用于收敛高光区域 光滑组的本质： 改变点法线光滑组的本质是改变点法线，进而影响面法线，进而影响三角线遍历中Normal的插值；","text":"a). 什么是硬表面 从外表/建模来说：有着重工业质感、该平滑的时候平滑，该硬朗的时候硬朗。即平的平，弯的弯。 从光影来说：光影变化均匀，硬朗，有经过打磨的感觉。 需要区别于LowPoly，Lowpoly有种纸片的拼凑感，更像是纸膜，主要是倒角所给予硬表面的厚度。即缺少最重要的倒角。 b). 如何制作硬表面（高模上倒角方法） 在游戏中硬表面通常是使用低模进行体现。因为硬表面的质感很大程度上取决于倒角。倒角会很大的增加模型面数。对于一些较小的结构，小凹槽，实际在低模上进行倒角或者卡边做出结构是不太划算的。本质上是要让高光的呈现更加集中，如果高光过于散开，就会显得较软，漂亮的高光边会表现很强的质感。 b.1). 卡双线 第一对线用于Smooth后形成倒角，第二对线用于收敛高光 b.2). 方倒角 对两个倒角卡双线 b.3). 直接倒角效果最好，可得到漂亮的高光边，但是因为增加的边数很多，过于密集，修改起来麻烦。 b.4). 光滑组（软硬边）+ 卡单线 通过将两个面设为同一光滑组（Maya里则将连接边设为软边）+ 两边各卡一条线用于收敛高光区域 光滑组的本质： 改变点法线光滑组的本质是改变点法线，进而影响面法线，进而影响三角线遍历中Normal的插值； c). 烘焙（低模） 事先准备： 准备好低模（在中模的基础上简化） 展UV 分好光滑组（软硬边） c.1). 烘焙过程中，光滑组注意事项对于倒角的部分，烘焙前需要设置好光滑组，对于硬边需要断开UV，否则会出现接缝； 即：对于需要烘焙的低模，同一光滑组（软边），UV需相连；对于不同光滑组（硬边），UV需断开且隔开一定距离 如低模中，本需硬边烘焙的Normal使用了软边，那烘焙时会通过用反相的Normal把Normal复原（在法线本应改在（0,0,1）时） d). 硬表面其他制作方法假高模 用图片转normal 在SP里面印normal 使用OpenSubdiv 使用ZBrush做倒角 使用点法线","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"美术","slug":"美术","permalink":"https://whitetail-o.github.io/tags/%E7%BE%8E%E6%9C%AF/"},{"name":"模型制作流程","slug":"模型制作流程","permalink":"https://whitetail-o.github.io/tags/%E6%A8%A1%E5%9E%8B%E5%88%B6%E4%BD%9C%E6%B5%81%E7%A8%8B/"}]},{"title":"HPP_Art_1 美术理论基础(角色/场景设计精要)","slug":"HPP_Art_01_美术理论基础","date":"2023-02-03T03:23:32.000Z","updated":"2023-02-04T06:48:01.369Z","comments":true,"path":"2023/02/03/HPP_Art_01_美术理论基础/","link":"","permalink":"https://whitetail-o.github.io/2023/02/03/HPP_Art_01_%E7%BE%8E%E6%9C%AF%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/","excerpt":"","text":"https://www.yuque.com/sugelameiyoudi-jadcc/okgm7e/pfo9oz","categories":[{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"美术","slug":"美术","permalink":"https://whitetail-o.github.io/tags/%E7%BE%8E%E6%9C%AF/"},{"name":"美术理论","slug":"美术理论","permalink":"https://whitetail-o.github.io/tags/%E7%BE%8E%E6%9C%AF%E7%90%86%E8%AE%BA/"}]},{"title":"相机概述","slug":"相机概述","date":"2023-02-01T09:23:32.000Z","updated":"2023-03-17T05:33:23.590Z","comments":true,"path":"2023/02/01/相机概述/","link":"","permalink":"https://whitetail-o.github.io/2023/02/01/%E7%9B%B8%E6%9C%BA%E6%A6%82%E8%BF%B0/","excerpt":"前言最近在搭建完整的PBR环境时，用到了挺多相机的知识。借此机会重新温习了下大一写摄影技术的词条，同时为了适应博客删掉了很多不必要的内容。 不过既然是大一写的，想必难免会有一些疏漏，而且当初的目标形式是词条，相应知识也不会过于深入，但大体上还是没问题的。 a). 摄影机成像原理一、小孔成像​ 光线沿直线传播。用一个带小孔的板遮挡在物体与成像面间，物体反射的光线经过小孔，在成像面上形成倒立的像。在一定范围内，小孔越小，成像越清晰，但小孔过小会导致发生衍射，使成像模糊。","text":"前言最近在搭建完整的PBR环境时，用到了挺多相机的知识。借此机会重新温习了下大一写摄影技术的词条，同时为了适应博客删掉了很多不必要的内容。 不过既然是大一写的，想必难免会有一些疏漏，而且当初的目标形式是词条，相应知识也不会过于深入，但大体上还是没问题的。 a). 摄影机成像原理一、小孔成像​ 光线沿直线传播。用一个带小孔的板遮挡在物体与成像面间，物体反射的光线经过小孔，在成像面上形成倒立的像。在一定范围内，小孔越小，成像越清晰，但小孔过小会导致发生衍射，使成像模糊。 二、透镜成像1. 凸透镜(正透镜、汇聚透镜)​ 中间厚、两边薄的透镜。平行于光轴的方向入射的光线会汇聚于光轴上的一点，这个点称为焦点，焦点到透镜中心点的距离称为焦距。 2. 凹透镜(负透镜、发散透镜)​ 中间薄、两边厚的透镜。平行于光轴的方向入射的光线穿过镜身后会发散。发散后的光线的反向延长线会交于光轴上的一点，这个点称为虚焦点，虚焦点到透镜中心点的距离的负值为凹透镜的焦距。 b). 光学镜头一、定义​ 由一块或多块(一般在三块以上)光学玻璃组成的透镜组，用于使物体成像在照相胶片、电子传感器或其他能以化学或电子方式储存图象的媒体上。光学镜头也称摄影物镜。 二、构造1. 镜头筒​ 摄影机物镜镜片的支撑体。镜头筒上附有调节光圈、焦距等参数的装置。现代变焦镜头具有多重的镜头组合和复杂的手动或自动调节系统。这些调节装置设计得越精细，使用者操作起来就越方便。[1] [1] 常乐，车欣等.电影制作技术手册[M].北京:北京联合出版公司,2017:144. 2. 镜片​ 构成物镜成像系统的光学玻璃。 三、镜头分类​ 镜头按是否具备变焦能力，可分为变焦镜头和定焦镜头。按焦距的长短(视角的大小)，可分为远摄镜头、标准镜头、广角镜头、鱼眼镜头等。 1. 标准镜头​ 学名为标准摄影物镜。指接近人眼观察视角的镜头。 ​ 在摄影中，标准镜头的焦距大致与底片或传感器对角线的长度大致相等，其视角约为53度。如将由标准镜头拍摄出的图像，放置于观察者前方约等于图像对角线长度的距离，观察者看到的图像的大小将会与在拍摄地用肉眼观察到的真实场景相同。对于全画幅相机，标准镜头焦距通常为50mm。 ​ 在电影中，电影的标准镜头的镜头焦距近似于图像对角线的2倍。SMPTE(the Society of Motion Picture and Television Engineers，电影和电视工程师协会)在几乎一个世纪前制定了此标准。他们认为这符合当时人们的观影习惯，可给观众席中央(处于屏幕和投影仪之间的位置)的观众提供更自然的视野。[1]这是因为人们对电影和照片有着不同的观看习惯，在当时观众观看电影时，与电影屏幕的距离通常是电影屏幕对角线两倍。 [1] 参考自https://neiloseman.com/the-normal-lens/ 2.长焦镜头​ 又称长焦距镜头、远摄镜头、望远镜头。焦距大于标准镜头焦距的镜头。具有焦距长、视角小、景深小的特点。 3.广角镜头​ 又称短焦镜头。焦距小于标准镜头焦距的镜头。具有焦距短、视角大、景深大的特点。根据视场角大小可分为普通广角镜头和超广角镜头。 4.鱼眼镜头​ 又称全景摄影镜。视角为180°左右到220°。全画幅中，焦距在16mm及以下的镜头通常可被称为鱼眼镜头。 四、镜头卡口(表格来自Wikipedia) 名称 机身像场定位距离（mm） 卡口环直径（mm） 卡口环类型 旋转方向 常见相机品牌 4/3 38.6 46.5 内三爪 顺时针 奥林巴斯、松下、Leica AR 40.5 47.0 内三爪 顺时针 柯尼卡 FD/FL 42.1 48.0 外三爪 顺时针 佳能T、A、F MD/MC 43.5 45.0 内三爪 顺时针 美能达、海鸥 AX 43.5 49.0 内三爪 顺时针 Fujica EF 44.0 54.0 内三爪 顺时针 佳能EOS系列 SA 44.0 48.5 内三爪 顺时针 适马 A 44.5 50.0 内外三爪 顺时针 索尼、柯尼卡美能达、美能达AF C/Y 45.5 48.0 内三爪 顺时针 Contax、Yashica、凤凰 Kyocera/Yashica AF 45.5 50.0 内三爪 顺时针 Kyocera、Yashica AF K/PK/RK 45.5 48.5 内三爪 顺时针 宾得、理光、Chinon、Cosina、凤凰 M42 45.5 50.0 螺纹 顺时针 Mamiya 45.5 49.0 内三爪 顺时针 Mamiya NC/ZE系列照相机 OM 46.0 47.5 内三爪 顺时针 奥林巴斯 F 46.5 47.0 内三爪 顺时针 尼康、凤凰 R 46.9 49.0 螺纹 顺时针 Leica R Kyocera Contax-N 48.0 55.0 内三爪 顺时针 Contax N 五、镜头的光圈​ 系指摄影物镜中的可变光阑，由若干薄片构成，用于控制镜头的孔径大小，与快门协同控制进光量。照相机和摄影机中都装有可变的孔径光阑，俗称光圈。[1] ​ 光圈的大小用F值或T值表示，普通照相机镜头通常使用F值，电影镜头则使用T值 [1] 常乐，车欣等.电影制作技术手册[M].北京:北京联合出版公司,2017:146. 1. F值光圈系数​ 又称F光圈数。F值等于相对孔径的倒数，即镜头焦距与摄影物镜的入瞳之比。这样定义的原因是，在忽略镜头玻璃对光线的吸收的情况下，快门速度不变，F值恒定可保持曝光量(像平面照度与曝光时间的乘积)相等，而不受镜头焦距影响。 F值={f\\over D}，其中f为镜头焦距，D为入瞳孔径​ 国际通用的F值为根号2的等比级数分级，即1、1.4、2、2.8、4、5.6、8、11、16、22。两级之间曝光量相差一倍。F值越大，相对孔径越小，通光越少；F值越小，相对孔径越大，通光越多。 2. T值光圈系数​ T值表征摄影物镜实际透光能力的参数，简称T光圈或T值。T值等于相对孔径的倒数除以物镜透光率的开平方。理想条件下，即一个镜头的透光率为100%时，其T值与F值相等。但在实际情况中，同一个镜头的T值一定大于它的F值。 ​ T值={F值光圈系数\\over\\sqrt{物镜透光率}}​ 一般在专业摄影机镜头上，F值用白色刻度标明，T值用红色刻度标明。 六、模糊圈与景深1. 弥散圆(Circle of Confusion, CoC)​ 也称模糊圆。 ​ 点光源发射出的光线经过镜头折射汇聚于一点，经过此点放置一块垂直于光轴的屏幕，并沿平行于光轴的方向移动点光源一定距离。此时，点光源在屏幕上会呈现出一个可辨认为圆形的像，这个圆形的像被称为弥散圆。当点光源向最初始的位置移动时，弥散圆逐渐变小，当它小到一定程度而人眼不可辨认时，我们将其视为一个清晰的点像，此时弥散圆被称作容许弥散圆（最小弥散圆）。 图片引自Wikipedia ​ 传感器或底片上最小弥散圆直径与拍摄照片的机器的传感器或底片对角线的长度一般成正比。假设在我们正前方距离L的地方放置一个屏幕，屏幕对角线长度为a，这种情况我们观看屏幕的最小弥散圆直径为d（或可引入人眼最小分辨角θ，计算得最小弥散圆直径为2L*tan(θ/2)）。摄影机的传感器对角线长度为b,将摄影机拍得的照片投影到屏幕上，照片的放大倍数K=a/b，那传感器上最小弥散圆直径就为d/K,即b\\d/a*，其中d/a为常数。但由于最小弥散圆直径还受许多主客观因素影响，不同相机厂商所给定的弥散圆直径会略微不同。 2. 景深​ 景深是一个空间范围，凡在此范围内的被摄物体都能够在成像元件上形成足够清晰的影像。 ​ 在临界焦点前后两侧各存在一个区域，在这两个区域合起来的区域范围内，被摄物体上各个点在影片上都能呈现为等于或小于最小弥散圆的一个圆，这个区域称之为景深。 图片引自http://www2.xitek.com/info/showarticle.php?id=1148 ​ 聚焦的被摄物的前后景深并非是一样的，一般估计后景深为前景深的两倍。因此，如果两个物体距离镜头远近不同，要想使两者都再现得清晰，应当把聚焦点取在从较近物体算到较远物体距离1/3处。[1] ​ 景深随焦距、对焦距离、光圈值的变化而变化。焦距和对焦距离不变时，光圈值越小，即光孔越大，景深越浅。 ​ 附景深计算公式： 字符 含义 δ 容许弥散圆直径 f 镜头焦距 F 镜头的拍摄光圈值 L 对焦距离 ΔL1 前景深 ΔL2 后景深 ΔL 景深 ΔL1={FδL^2\\over f^2+FδL},ΔL2={FδL^2\\over f^2-FδL} ΔL={2f^2FδL^2\\over f^4-F^2δ^2L^2}[1] 常乐，车欣等.电影制作技术手册[M].北京:北京联合出版公司,2017:147. 七、超焦距​ 给定光圈和焦距，逐渐调大对焦距离，当景深后界被扩展到无穷远时，景深前界到镜头中心点的距离即为超焦距。当调焦到超焦距时，从超焦距的二分之一处到无穷远的景物都可在感光元件上呈现清晰的像。超焦距计算公式： H={f^2\\over FE},f为焦距，F为光圈系数，E为容许弥散圆直径八、沙姆定律​ 沙姆定律最初是由奥地利军官沙姆发现的，用于航空摄影中校正透视变形。沙姆定律的内容为：如果像平面与镜头平面不平行，而是交与一条直线l，那么能清晰成像于像平面上的物平面(即合焦平面)同样经过直线l。 图片引自Wikipedia ​ 沙姆定律常用于移轴摄影。(图片引自50 Beautiful Examples Of Tilt-Shift Photography) 移轴摄影 九、主点和主面(引自Wikipedia)​ 主点(Principal points)，是厚透镜光轴上的一对共轭点。平行于光轴的一条入射光线穿过透镜后的折射光线会经过焦点,两条光线之延长线会相交于一点,所有这类的交点(主点为其中特例)构成一个曲面。 ​ 就接近光轴附近而言，该曲面近似一个平面，称之为主面(Principal plane)主面与光轴的交点,即为主点。 P 为前侧主点、 P' 为后侧主点 十、节点​ 节点(Nodal points)，是厚透镜光轴上的一对共轭点。一条朝节点方向射入的光线，经透镜折射后的折射光线的反向延长线经过另一条节点，且两条光线于光轴所成的夹角大小相等(角向放大率为+1)。如果光学系统两侧的介质相同(如空气)，则前后节点分别与前后主点重合。 N, N' 分别是厚透镜的前后节点 ​ 当相机绕着镜头节点旋转时，物体的透视关系不会发生变化，利用此特点，我们在拼接照片时可以保证拼接的精度。定焦镜头只有一个固定的节点，而变焦镜头在不同的焦段有不同的节点。 当相机绕着镜头节点旋转时，物体的透视关系不会发生变化。图片引自http://www.xiletuphoto.com/zx/20160928/36.html ​ 十一、MTF曲线​ MTF(Modulation Transfer Function,调制传递函数，模量传递函数)是衡量镜头性能的一个重要指标，可用于评价镜头还原调制度(对比度)的能力。 ​ MTF所表示的是镜头实际成像与理想成像之间调制度之比随空间频率和像场位置变化的函数。 MTF={输出图像调制度\\over输入图像调制度}1. 调制度​ 在研究摄影镜头成像质量时，调制度等于景物最大亮度和景物最小亮度之差于景物最大亮度和景物最小亮度之和的比值。 M={L_{max}-L_{min}\\over L_{max}+L_{min}}2. 像场(待补充)3. MTF曲线图(图片待补充)​ MTF曲线图的纵坐标为调制传递函数值，根据横坐标的不同最主要分为两种类型，即以空间频率为横坐标绘制的频幅曲线和以到像场中心的距离为横坐标绘制的场幅曲线。 十二、透镜像差​ 在光学系统中，像差指实际成像与理想成像的偏差。普通的像差有如下几种： 1. 球面像差​ 简称球面差、球差，镜头不能使被摄物体中一个光点重现为一个点像。[1]这是因近轴光线和远轴光线经过透镜后折射的程度不同而造成的。 图片引自https://en.wikipedia.org/wiki/Spherical_aberration [1] 常乐，车欣等.电影制作技术手册[M].北京:北京联合出版公司,2017:148. 2. 像散​ 发光物体不处于主光轴时，子午方向入射光线与和弧矢方向的入射光线汇聚于不同平面。像散常会使一个点光源在画面上形成一个十字。它表现为在分辨率(解像力)测试标板上的可分辨的横竖线条的不同。[1] 蓝色子午方向入射光线经过透镜汇聚于S1，红色弧矢方向入射光线经透镜汇聚于T1 图片引自https://zh.wikipedia.org/wiki/%E5%83%8F%E6%95%A3 3. 像场弯曲​ 简称场曲，垂直于主光轴的被摄物体经过透镜折射后，最清晰的实像面不是一个平面，而是一个弯曲的曲面。 图片引自Wikipedia 4. 彗星像差​ 简称彗差，不处于主光轴上的点光源经过透镜后成像变形，产生出类似彗星的尾部。且点光源离视野中心越远，慧差越明显。 图片引自Wikipedia 5. 色差​ 不同波长( 不同颜色)的光线在同一介质中折射率不同，使镜头无法将不同波长的色光汇聚于一点，从而形成色差。 图片引自Wikipedia 十三、电影镜头与相机镜头的几个主要区别1. 对焦2. 无极光圈3. 齐焦(parfocal)4. 呼吸效应的控制c). 快门​ 又称为光闸，是照相机中控制曝光时间的重要部件。快门时间越短，即快门速度越快，曝光时间越短。总体可分为机械快门和电子快门。一些电影摄影机使用的快门称为旋转快门，又称叶子板。 一、机械快门根据机械快门在相机中的位置，可分为： 1. 镜前快门​ 最早的快门就是镜前盖。由于早期感光材料的效率低，需要的曝光时间较长，在当时直接采用摘除镜头盖进行曝光的方法。后来改进为气动二叶快门，多用于微型相机。 2. 镜间快门​ 结构与光圈类似，由金属叶片组成，位于镜头内部，现今不少中画幅及大画幅相机仍采用镜间快门。使用镜间快门可减小拍摄时的相机震动，防止果冻效应，且在所有快门速度下都可做到闪灯同步，但缺点是由于采用的是弹簧结构，受弹簧特性影响最高快门速度较低(一般不超过1/500)，且每一个镜头都需一个快门。 3. 镜后快门​ 结构与镜间快门类似，较镜间快门位置更靠后。 4. 焦平面快门​ 位于胶片或感光元件前方，接近焦平面，因此得名。根据运动方向不同，焦平面快门可分为纵走式和横走式。现今绝大多数单反相机和微单采用焦平面快门。焦平面快门由两块快门帘组成，分别为前帘和后帘。在大多数单反相机中，单个帘幕越过胶片的时间最短时间约为1/60秒或1/125秒。 单反相机中焦平面快门的工作过程 图片引自Wikipedia ​ 为了实现更高的快门速度，焦平面快门采用了逐行曝光的方法。以纵走式为例，对于单反相机，在单反相机未拍照时，反光镜降落，焦平面快门闭合。按下快门后，反光镜升起，后帘上升，之后前帘下降，开始曝光，在前帘下降一段距离后后帘下降，此时前帘和后帘之间的区域进行曝光。待所有像素曝光完成后前、后帘回到初始位置。对于微单，微单未拍照时，焦平面快门为了电子取景处于开放状态。按下快门后，前帘上升，待传感器上电荷清空后前帘下降，开始曝光，在前帘下降一段距离后后帘下降。通过逐行曝光的方法，焦平面快门甚至可实现1/16000秒的快门速度。但采用逐行曝光的方法也带来了果冻效应，以及搭配高速闪光灯时闪光同步的问题。（一些相机在不使用闪光灯高速同步时，会限制最高快门速度） 不同快门速度下焦平面快门的表现 图片引自Wikipedia 二、电子快门​ 在胶片时代，电子快门是指驱动动力由马达或电磁铁提供，或是快门速度由石英计时电路来控制的快门。现今，电子快门多指电子断流快门，它是“以电子方式控制摄像机曝光时间的装置”。以下电子快门均指电子断流快门。电子快门不存在任何机械结构，本质上是电路控制，控制传感器的积分时间。在传感器通电时受到光信号可积累电荷，断电时受到光信号不可积累电荷。 ​ 因此，使用电子快门时，可以得到比机械快门大得多的快门速度，并不会引起机器震动，可实现静音拍摄。但由于缺乏机械遮光，容易产生暗电流校准不良，导致成片曝光错误。为了缓解这种情况，常会搭配电子元件进行“电荷清零”。但“电荷清零”会导致一定的快门延时。电子快门常用于手机和部分数码相机。 ​ 电子快门通常有两种快门方式：卷帘式快门(Rolling Shutter)和全局式快门(Global Shutter)。 3. 卷帘式快门(Rolling Shutter)​ 通过快速扫描来捕获画面的技术，画面中的部分并不是在同一个瞬间记录的。 ​ 卷帘式快门于全局快门不同，它是通过控制芯片逐行曝光的方式实现的。卷帘式快门是通过通断电控制传感器，使其不同部分在不同时间下对光的敏感度不同。逐行进行曝光，直至所有像素点都被曝光。一般情况为1/48至1/60秒。[1] ​ 由于使用卷帘式快门时，其扫描速度比焦平面快门慢，常会引起相较于焦平面快门更严重的果冻效应。卷帘式快门多用于CMOS。 [1] 常乐，车欣等.电影制作技术手册[M].北京:北京联合出版公司,2017:142. 4. 全局式快门(Global Shutter)​ 全局快门可使整幅图片在同一时间曝光。传感器所有像素点在同一时间收集光线，积累电荷，使曝光同时开始。曝光时间到时，传感器断电，同时停止曝光。 ​ 使用全局快门可防止果冻效应。全局快门多用于CCD，但现今也有使用全局快门的CMOS出现。 三、电子前帘快门​ 通过控制芯片来模拟前帘，并使用机械后帘。电子前帘快门通过类似于卷帘式快门的方式开始逐行曝光，并用机械后帘结束曝光。相比于卷帘式快门，它的果冻效应更轻微；相比于焦平面快门，它造成的机器震动更小。 四、叶子板（图片待补充）​ 又称旋转快门。在以前使用胶片拍摄时，一秒会记录24帧，即一秒曝光24格胶片。为了控制曝光时间，并防止胶片移动时持续曝光形成拖尾，胶片摄影机引入了叶子板。叶子板为有着一定开角的圆形，通过不断的旋转控制胶片曝光的时长。当开口移动到胶片前方时，胶片进行曝光。当开口移开后，胶片停止曝光，并前进一格。 ​ 通过控制叶子板的开角大小，可调整胶片的曝光时间。例如，在拍摄24帧每秒时，当叶子板开角为180°时，叶子板旋转一周的时间内有1/2的时间胶片进行曝光，因此胶片曝光时间为1/48。 ​ 一些数字摄影机也采用机械式叶子板作为快门，如ARRI ALEXA Studio。 五、快门速度与快门角度1. 快门速度​ 快门速度是摄影中用于表达曝光时间的术语，表示胶片或传感器整体进行曝光的等效时间。光圈一定时，总的曝光量和快门速度呈正比。对待运动物体时，高速的快门可凝固具有一定速度的物体，减少画面中的运动模糊；慢速的快门则可使运动模糊更明显。常见的快门速度标准有：1，1/2，1/4，1/8，1/15，1/30，1/60，1/125，1/250，1/500，1/1000，1/2000。 ​ 在进行长时间曝光时，除呈数值的快门速度外，还有两个另外的设置： B门：快门按下后开始曝光，释放后结束曝光。 T门：快门按下开始曝光，再次按下结束曝光。 2. 快门角度​ 在以前，快门角度是在胶片摄像机中用于表达曝光时间的术语，即用叶子板的开角角度表示曝光时间。但现今一些不使用叶子板的数字摄像机仍用快门角度来表达曝光时间，如BMPCC 4K。 ​ 快门角度与快门速度的转换公式： 快门速度={快门角度\\over360°}×帧率d). 电子感光器件​ 又称作光电成像器件(photo-electronic imaging device)。是利用光电效应将景物或图像转换为可进行记录、传输、存储、显示以及处理等操作的器件系列的总称。或简述为完成图像信息光电转换的功能器件。 ​ 光电成像器件的类型众多，在影视技术应用中主要有： 固体图像传感器，包括CCD图像传感器和CMOS图像传感器； 摄像管，包括光电发射摄像管和光电导摄像管。[1] 下面给出CCD和CMOS中几个具有相似工作原理的工作环节： 一、光电转换​ 将光信号转换为电信号。一定通量的光子以高于半导体带隙(导带能量最低点与价带能量最高点的能量只差)的能量进入半导体，使处于价带的电子被激发到导带，成为自由电子。这些电子就成为转换后的信号电荷。 二、电荷的收集与积累1. 传感器的电荷积分模式(图片待补充)​ 数码相机的CMOS和CCD图像传感器将光电二极管用作电荷收集器件。例如，二极管P型区域接低电势，N型区域首先被复位到高电势。之后光电二极管保持反偏并进入悬空状态。由于P型区域和N型区域的多数载流子的扩散作用，二极管内产生由N型区域指向P型区域的内建电场。被光子激发出的电子受内建电场作用，在N型区域聚集。在这种情况下，电子就是信号电荷。 三、信号电荷的检测与变换1. 电荷检测​ 即将信号电荷转变为信号电压。其原理在CCD图像传感器和大部分CMOS图像传感器是基本相同的。但CCD和CMOS进行电荷检测的位置不相同，CCD在输出放大器中实现电荷检测，而CMOS是在像素内实现电荷检测。实际上，CCD中有着专门的放大器和模数转换芯片，而CMOS的每一个感光元件都整合了放大器和模数转换逻辑。电荷检测与变换的基本过程为：电压放大器连接势阱以监测阱中信号电荷的变化，若有电荷Qsig进入阱中，则其引起的电压变化为 ΔV_{FD}={Q_{sig}\\over C_{FD}}(1.1)式中，CFD是放大器所连接到的势阱的电容，并充当电荷到电压的转换电容。输出电压的变化如下： ΔV_{OUT}=A_VΔV_{FD}(1.2)式中，AV代表电压放大器的电压增益。[2] 2. 转换增益(Conversion Gain)​ 转换增益(Conversion Gain)表面了在电荷检测节点处，一个电子引起的电压变化大小。由式(1.1)可求得增益如下[1]： C.G={q\\over C_{FD}}(2.1)​ 式中，q表示元电荷，CFD表示输出放大器所连接到的势阱的电容。 [1] 常乐，车欣等.电影制作技术手册[M].北京:北京联合出版公司,2017:137. [2] Junichi Nakamura.数码相机中的图像传感器和信号处理[M].北京:清华大学出版社,2015:40. e). 像元​ 像元即像素点，是组成传感器的最小单元。下图为简化的像素结构 ​ 简化的像素结构 图片引自《数码相机中的图像传感器和信号处理》 Junichi Nakamura 著 一、彩色滤光阵列​ 为使图像传感器能够还原出彩色图像，必须采用分离颜色的技术。对于消费领域的数码相机来说，可以在光敏二极管上用片上彩色滤光阵列(color filter array,CFA),这是一种经济合算的解决方案，可以将色彩信息分离并满足数码相机的微小化需求。 ​ 根据彩色滤光阵列使用的色彩模式的不同，可分为RGB基色滤光阵列和CMY互补色滤光阵列。RGB滤光阵列有着更优的色彩再现能力和更高的彩色信噪比，因为它具有良好的波长敏感性;CMY互补色滤光阵列由于采用的模式的各个互补色滤光片的光穿透范围较宽，可以获得更高的色彩敏感度，量子效率较高。然而，为了输出显示而将互补色成分转换成RGB的减法操作会带来信噪比的下降，色彩再现也通常没有RGB基色滤光那么准确。[1] 1. 拜尔阵列​ 最常用的RGB基色滤光模式叫做“拜尔”模式，采用这种模式的阵列也叫拜尔阵列。拜尔阵列是一种马赛克彩色滤色阵列，由Bryce Edward Bayer提出。考虑到人眼对绿光最敏感的生理特性，这种滤色阵列中，绿色滤光器占50%，红色和蓝色滤光器分别占25%，这种排列方式称为RGGB。要从拜耳阵列传感器采样生成的图像得到全色彩图像必须要去马赛克，进行反马赛克运算。 拜尔阵列 图片引自Wikipedia ​ 在带拜耳阵列的传感器中，当输入信号的最高频率超过一定值(奈奎斯特频率)，接近于感光元件里像素的空间频率时，就会产生信号的混叠。根据差拍原理，即两个频率接近的等幅正弦波叠加，合成信号的幅度将按照两个频率之差变化。在这种情况下，图像上就会产生摩尔纹。 透过重叠两相似图样（转动α度）得到之摩列 图片引自Wikipedia 2. Foveon X3感光元件​ Foveon X3利用可见光不同的波长拥有不同的穿透力的原理感光元件，在每个像素具有三层感光元件所以可以同时侦测红、蓝、绿三种波长的强度。Foveon X3解决了摩尔纹的问题，其采样频率和色彩还原度远高于传统的拜耳阵列。 ​ 但由于图像传感器是垂直叠起的，导致许多电路层设计问题。往往会使信噪比和动态范围下降。Foveon X3用于部分sigma旗下的数码相机。 ​ 传统的拜尔阵列以及一些拜耳阵列的改良型(如富士的X-Trans),这类能在单片结构上感测彩色影像的成像器件属于单片成像器件。Foveon X3这类使用三片成像器件分别感测红、绿、蓝三种原色的器件属于三片成像器件。广播级摄影机多采用三片成像器件。 二、微型透镜阵列​ 片上微型透镜阵列(on-chipmicrolens array,OMA)是由众多片上微透镜组成，用于将入射光汇聚到光电二极管的结构。 三、MOS二极管(图片待补充)​ MOS(Metal Oxide Semiconductor)二极管是由金属—氧化物—半导体构成的光电管。这种结构最上层是金属(常用铝或铝化合物)，中间是氧化物(一般为SiO2),下层为半导体，半导体的基础材料是硅晶体，根据使用的半导体的多数载流子的类型的不同分为P(positive)型衬底和N(negative)型衬底。由于电子迁移率高，所以大多数CCD选用P型硅衬底。[1]当在金属端加上一个偏置电压(栅极电压)，使MOS二极管处于反偏状态时，P型硅衬底的多数载流子(空穴)从硅表面区域被排斥走，随之在硅表面区域形成耗尽层，这样耗尽区就可以收集自由电子。 四、结构1. 前照式结构​ 如图左侧，光子由像素正面入射。使用正面照明的像素结构又被称为前照式结构。光子到达光电二极管前需要经过金属线路，易被阻挡或反射串扰邻近像素。正面入射时量子效率为40%左右。为了解决前照式的开口率小以及光串扰问题，佳能将微透镜阵列进行优化，造出无缝微透镜阵列。而索尼则实现了背照式结构。 2. 背照式结构​ 如图右侧，光子由像素背面入射。使用背面照明的像素结构又被称为背照式结构。背照式结构将金属线路放到光电二极管下面，使传感器可更好地利用入射光线。背面照射时，量子效率可达80%以上。 3. 堆栈式结构​ CMOS图像传感器的像素为有源像素，集合了具有信号放大及输出等功能的电路，使得CMOS的像素表面有一部分为处理回路，这部分无法接收光信号。而堆栈式结构则将处理回路安置在像素区域下方。堆栈式结构可实现更小尺寸的传感器，画质方面也得到了一定的优化。 四、有源像素和无源像素​ 根据电荷包传输出像素时是否经过信号放大，可将像素分为有源像素和无源像素。有源像素即是电荷包在传递出初始像素后，已经经过信号放大。无源像素即是电荷包在传递出初始像素后，未经过信号放大。 ​ CCD图像传感器被归类为无源像素的图像传感器，因为光生电荷在从像素传递到寄存器后端的输出放大器时才发生信号放大。CMOS图像传感器大多为使用有源像素的图像传感器，其中光生电荷在传递出初始像素后已经经过信号放大，放大后的信号再被读出。采用有源像素可以有效地抑制信号读出路径上产生和引入的噪声，采用无源像素可降低单个像素的大小。 [1] Junichi Nakamura.数码相机中的图像传感器和信号处理[M].北京:清华大学出版社,2015:42-43. 势阱一、定义及解释​ 势阱定义：粒子在某立场中运动，势能函数曲线在空间的某一有限范围内势能最小，形如陷阱，称为势阱。在MOS管中，当在金属端加上一个偏置电压(即金属端为高电势，P型衬底为低电势)，使MOS二极管处于反偏状态时，P型硅衬底的多数载流子(空穴)从硅表面区域被排斥走，随之在硅表面区域形成耗尽层。对于电子而言，耗尽层是低势能区，因此耗尽层可俘获电子。当使用同一光源的光线照射到MOS管的硅片上时，势阱内俘获的光子数与光强度成正比。 ​ 势阱的深度与电极上所施加的电压有关，电极上价带电压越高，势阱就越深。一个势阱所收集的光生电荷称为一个点荷包。 二、满阱容量​ 满阱容量(full-well capacity,FWC)是一个光电二极管所能积累的最大电荷量，即一个像元所能积累的最大电荷量。满阱容量与势阱的深度有关，下面给出相应公式： N_{sat}={1\\over q}\\int_{V_{reset}}^{V_{max}}C_{PD}(V)·dV[electrons]​ 式中，Nsat即为满阱容量，q为元电荷，CPD为光电二极管的电容，Vreset与Vmax分别为二极管两侧的初始电压和最大电压。 f). CCD图像传感器一、概念​ CCD(charge coupled device，电荷耦合器件)是一种能够在半导体中以电荷包的形式储存和传输信号电子(少部分传输空穴)的器件。如图4.1(a),CCD的主要结构为MOS电容器。当在金属电极加正电压时，P型硅衬底的多数载流子(空穴)从硅表面区域被排斥走，随之在硅表面区域形成耗尽层，从电极出发的电场线终止于耗尽层中由受主离子形成的负空间电荷区。在这种非热平衡条件下，注入的少数载流子(电子)就会被吸引到电极下的Si-SiO2界面，如图4.1(b)所示，这意味着在Si-SiO2界面形成了一个电子的势阱。通常，我们用如图4.1(c)的流体模型来描述点荷包储存和转移的情况。[1] 图片引自《数码相机中的图像传感器和信号处理》 Junichi Nakamura 著 ​ 之后，我们考虑相邻MOS电容之间的交互作用，即电荷转移。当MOS电容的排列不够紧密时，相临的MOS电容的势阱无法沟通，也就无法转移电荷，如图4.2(a),G1中储存的电荷包无法到达G2。所以，必须使相邻的MOS电容排列更紧密，使其势阱互相沟通。两个MOS电容势阱互相沟通的状态称为耦合。在相邻两个MOS电容耦合之后，储存在G1中的电子电荷包将由G1与G2之下耦合势阱共享，如图4.2(b)所示。因为信号电荷总是向势阱深处转移，我们可以通过调整各个MOS电容的栅极电压来调整各个电容的势阱，进而使电荷包在CCD中按照确定方向转移。如图4.2(c)，即通过降低G1上的电压，将G1中的电荷包完全转移到G2中。 图片引自《数码相机中的图像传感器和信号处理》 Junichi Nakamura 著 二、CCD基本工作流程​ CCD的基本工作流程： ​ 信号电荷产生，即光子电荷转换； ​ 信号电荷储存，即信号电荷的收集与存储，实现光积分； ​ 信号电荷转移，即信号电荷的传输； ​ 信号电荷的检测与变换，即将信号电荷转换成电信号输出。[2] 二、电荷转移机制[1]67-68​ CCD中基本电荷的转移取决于3个机制(或者说3个驱动力)：自激漂移(self-induced drift)、热扩散(thermal diffusion)和边缘场效应(fringing field dirft)。 图片引自《数码相机中的图像传感器和信号处理》 Junichi Nakamura 著 1. 自激漂移​ 如图4.3(a)，当电荷包较大时(例如在电荷转移刚开始的时候)，驱动电荷转移的主要机制为自激漂移。自激漂移是指由载流子的静电排斥作用引起的电荷转移。其中，电荷衰减速度与初始电荷密度大致成正比。 ​ 下面给出转移t时间之后G2下剩余的电荷的相关公式： {Q(t)\\over Q_0}\\approx {t_0\\over (t_0+t)} t_{0}={\\frac{\\pi L^{3}W C_{e f f}}{2\\mu Q_{0}}}={\\frac{\\pi}{2}}\\cdot{\\frac{L^{2}}{\\mu(V_{1}-V_{0})}}式中，L和W分别表示电极G2的长和宽;μ表示载流子(电子)迁移率;Ceff表示单位面积有效储存电容，它与MOS电容中的栅氧化层有关。V1-V0=Q0/LWCeff是将载流子移动至相邻电极G3的初始电压。 2. 热扩散​ 当MOS电容中的剩余电荷产生的沟道电压低至阈值电压时，如图4.3(b)所示，转移过程的驱动力主要是热扩散，这就使得G2下存储的电荷以指数形式减少。热扩散的时间常量τth可以用以下公式表示： τ_{th}={4L^2\\over {\\pi}^2D}式中，D是载流子扩散系数，L和电极G2的长。 3. 边缘场效应​ 在实际情况中，平行电容器的电场线并不都是直线，而是越靠近边缘的地方弯曲程度越大。如图4.3(c),在电荷转移过程中， 边缘场Ey加快了最后阶段的电荷转移。 ​ 边缘场的强度和形状取决于栅氧化层厚度、硅中杂质分布情况和电极的压差。单位载流子通过长度为L的电极的渡越时间ttr为 t_{t r}=\\frac{1}{\\mu} \\int_{0}^{L} \\frac{1}{E_{y}} d y​ 在高速操作中，例如时钟频率为10MHz时，边缘场是最重要的一个电荷转移的驱动力。因此，在设计CCD时必须要考虑到如何增强边缘场。 三、转移沟道​ 根据电荷包在CCD中存储和传输的位置不同，我们可以将CCD分为表面沟道CCD(SCCD)和体沟道CCD(BCCD)。 1. 表面沟道CCD​ 表面沟道CCD(surface CCD,SCCD)是指电荷包在MOS电容的氧化物-半导体分界附近进行存储与传输的CCD。这类CCD的工艺简单，但由于硅表面的晶格极不规则，在硅表面的禁带(在半导体中处于导带与价带之间，禁带宽度及带隙)引入了高密度的载流子陷阱能级，这又被称为表面态或界面态。[1]69即2电荷在表面沟道中转移时易被俘获，导致传输过程中会损失较多电子。因此，这种传输方式不适合大规模CCD。 2.体沟道CCD​ 体沟道(body CCD,BCCD)又被称为掩埋沟道。体沟道CCD的电荷包存储与传输的地方位于衬底内部，此方式有效解决了表面态对电荷传输的影响，提高了传输效率。 CCD掩埋沟道剖面图(参照Walden,R. H. et al. ,BellSyst. Tech. J. ,51,1635-1640,1972.) 四、成像阵列的扫描​ 积累的电荷，或者相应的电压或者电流信号需要从图像传感器芯片的像素中读出到外部电路。这些分布在二维空间的信号应该被转换为时序信号，这个过程称为”扫描“。[1]39 ​ CCD的扫描方式主要有以下几种：帧转移(frame transfer,FT)、全帧转移(full-frame transfer,FFT)、行间转移(interlinetransfer,IT)和帧-行间转移(frame-interline transfer,FIT)结构。下图展示了FTCCD、ITCCD和FITCCD的结构。 图片引自《数码相机中的图像传感器和信号处理》 Junichi Nakamura 著 1. 帧转移CCD(1) 结构及工作方式​ 如图4.18(a),帧转移(frame transfer,FT)CCD由成像区域、电荷存储区域、水平电荷转移CCD(HCCD)和输出电路组成。成像区和电荷存储区由一个多通道垂直转移CCD(VCCD)组成,可以在垂直方向上转移电荷包。存储区和HCCD被金属覆盖以屏蔽入射光。[1]76 ​ 当入射光照射到成像区上，所有像素开始曝光，光子将硅衬底中的电子激发到导带，形成电子-空穴对。这些光生电子被附近的势阱所俘获，形成电荷包，并进行垂直方向上的转移。经过一定的曝光时间后，信号电荷并行传输到存储区。之后，一条水平线上的电荷包转移到水平CCD，并经水平CCD一个一个地转移到输出电路。 (2) 特点​ 像素结构简单，可以相对容易地做成小面积的像素。但由于电荷包在成像区中转移时，光生载流子会叠加到信号中，会产生许多杂散信号，这种现象也叫漏光(在CCD中，漏光现象即是拖尾)。 2. 全帧转移CCD​ 全帧转移(full-frame transfer,FFT)CCD的结构与帧转移CCD相似，但没有存储区域。适用于仅使用机械快门拍摄静止图像，且连拍速度不太快的情况。 3. 行间转移CCD(1) 结构及工作方式​ 行间转移(interlinetransfer,IT)CCD是使用CCD的摄像机和数码相机中最常用的类型。如图4.18(b)所示，ITCCD中光电二极管和垂直转移CCD(VCCD)隔行分布。其中VCCD被遮挡不受光，不作为信号电荷的产生源，而是作为存储区和电荷垂直转移的通道。 ​ 当光电二极管接收到光信号时，其中电子被激发，形成电子-空穴对。这些光生电子被附近的势阱所俘获，形成电荷包。经过极短的时间，光电二极管中的电荷包被转移到VCCD。之后，一条水平线上的电荷包转移到水平CCD，并经水平CCD一个一个地转移到输出电路。 ITCCD像素横截图 图片引自《数码相机中的图像传感器和信号处理》 Junichi Nakamura 著 (2) 特点​ 大大减轻了漏光现象。且因为光电二极管和VCCD分离，不用过多考虑集成问题，因此各自可被设计成最优结构从而提高传感器的性能。 4. 帧-行间转移CCD​ 帧-行间转移(frame-interline transfer,FIT)CCD即有如FTCCD的存储区域，也有如ITCCD光电二极管和VCCD隔行排列的结构。 ​ 尽管以及减轻了许多，但在ITCCD中仍存在漏光现象(转移过程中光电二极管产生光生电子)，而FITCCD则进一步减轻了漏光现象。但由于实现FITCCD需要一块额外的存储区以及较高的时钟频率，导致传感器的面积增大、功耗增大、成本也相应增大。 五、拖尾​ 拖尾是CCD图像传感器的一个特殊现象，它是由那些多余电子产生的，例如在ITCCD电荷转移的过程中，由光电二极管产生扩散到VCCD中的干扰电荷。 ​ 拖尾被定义为低于像素阵列中心有效成像像素10%高度照射下的拖尾信号比，表现为白色垂直条纹图像。当强光照射时，造成造成高光溢出，使拖尾现象尤为明显。 拖尾现象 [1] Junichi Nakamura.数码相机中的图像传感器和信号处理[M].北京:清华大学出版社,2015:66. [2] 常乐，车欣等.电影制作技术手册[M].北京:北京联合出版公司,2017:137. g). CMOS图像传感器一、概念(图片待补充[1]141)​ CMOS(Complementary Metal-Oxide-Semiconductor,互补式金属氧化物半导体)是用于数字信号、模拟信号和混合信号应用的主流技术。CMOS图像传感器即是使用这项材料制作的传感器，其在数码相机、摄影机中尤为常见。 ​ CMOS图像传感器的原理组成如图所示，通常由光(像)敏单元阵列、行驱动器、列时序控制逻辑、A/D转换器(模拟数字转换器,ADC)、数据总线输出接口、控制接口等几部分组成，这几部分通常都被集成在同一块硅片上。[1] 图片引自《电影制作技术手册》 二、CMOS基本工作流程 光电转换 行选择逻辑单元选通相应的行像素单元； 信号通过各自所在列的信号总线传输到对应的模拟信号处理单元以及ADC； 电压输出。[2]141-142 三、CMOS的扫描方式​ CMOS图像传感器常用的扫描方式为X-Y寻址方案(下图b)。CMOS中，视频信号是通过行(垂直)扫描器和列(水平)扫描器对像素阵列进行光栅扫描获得的。一般情况下，行扫描器在每一帧时间内产生一个行选择脉冲和一个复位脉冲并送入选定行的像素中，列扫描器在每一个行周期扫描各列。CMOS 图像传感器中两种常见的扫描器是移位寄存器和解码器。移位寄存器的优点是结构简单，翻转噪声低，在一些改进结构中读出更加灵活。而解码器具有比移位寄存器更大的扫描灵活性，可以应用窗选读出或跳跃式读出。[2]扫描后，时序信号进入ADC，进行模数转换。 ITCCD的扫描方式与CMOS的X-Y寻址扫描方式的对比 图片引自《数码相机中的图像传感器和信号处理》 Junichi Nakamura 著 四、CMOS图像传感器与CCD图像传感器的对比1. 读出灵活性​ 基于CMOS使用的X-Y寻址方案可进行行选择，X-Y寻址方案提供了多个读出方式，如窗选读出和跳跃式读出等。这使CMOS的读出灵活性高于CCD。 2. 能耗​ CMOS在读出时具有行选择，且只有选中的像素才会被激活。此外，CMOS电路的工作电压可低于CCD电路的工作电压及片上功能实现都可降低系统功耗。这些使得CMOS的能耗要远小于CCD。 3. 性能​ 灵敏度：在像素尺寸相同时，因为CMOS有源像素中至少需要3个晶体管(复位晶体管、源跟随器晶体管和行选择晶体管),且它们被遮光金属所覆盖。[2]42这使像素的感光面积减小，填充因子(像素中感光区域与像素面积的比率)小，最终导致CMOS灵敏度低于CCD。 ​ 分辨率：在传感器具有相同尺寸时，CMOS分辨率低于CCD。CMOS单个像素中集成较多元件，使面积增大。 ​ 噪声：CCD的随机噪声较高，CMOS的固定噪声较高。 ​ 读取速度：CMOS读取速度快于CCD。由于所有的电荷都要通过统一的电路转换并输出，因此CCD传感器的读取速度比较慢。当然新一代的CCD在这方面有改善，但是是以牺牲灵敏度为代价的。 4. 成本​ 相同尺寸下，CMOS成本一般远低于CCD。 [1] 常乐，车欣等.电影制作技术手册[M].北京:北京联合出版公司,2017:141. [2] Junichi Nakamura.数码相机中的图像传感器和信号处理[M].北京:清华大学出版社,2015:105. h). 动态范围​ 动态范围(Dynamic range,DR)定义为满阱容量与本底噪声之间的比值(等效于传感器中不过曝下的最大输出与无光子照射时的输出的比值),用于衡量感光元件记录景物亮度范围的大小。动态范围的公式如下： DR=20lg({N_{sat}\\over n_{read}})[dB]式中，Nsat为满阱容量的电子数，nread为本底噪声的电子数。 i). 噪声(分类方式暂定)​ 噪声为接收信号并输出后的图像中的不均匀部分，会导致图像质量的下降。噪声大致可分为：固定模式噪声(fixed-pattern noise,FPN)和暂态噪声。 ​ 固定模式噪声(fixed-pattern noise,FPN)主要由暗信号非一致性、像素随机、阴影、暗电流的非一致性、光响应的非一致性等因素导致。 ​ 暂态噪声主要由读出噪声、放大器噪声、光子散粒噪声等组成。 j). 信噪比​ 信噪比(Signal-to-noise ratio,STR)是给定输入电压下信号和噪声的比值，可以衡量噪声对图像的干扰程度。信噪比越高，图像质量越好。信噪比的公式如下： SNR=20lg({N_{sig}\\over n})[dB]式中，Nsig为信号电平，n为信号电平为Nsig时的总暂态噪声。 k). 感光度(ISO)​ 感光度是指底片或感光元件对光线的灵敏程度。现感光度用ISO表示，感光度又叫ISO值。国际标准组织(International Organization for Standardization ,ISO)制定的胶卷生产标准，现也用于感光元件。在传感器中，ISO的改变实际上是改变电信号的放大程度，并没改变实际曝光量。过度地提高ISO会导致动态范围、色彩灵敏度、信噪比的大幅度下降。 一、原生ISO​ 在CMOS中，由于初始模拟信号过弱，在输出时一般会先经过模拟信号放大，再进行模拟数字信号转换。 ​ 原生ISO(native ISO)是由满阱容量决定的，指电子感光元件在特定的转换增益下，模拟信号不经过数字放大所得到的原始ISO。 l). 增益(Gain)​ 信号强度的改变，ISO的改变实际上就是改变可编程增益放大器中信号的放大程度。模拟增益的对象是模拟信号，处于模数转换之前，因此模拟增益不会造成色阶、亮度断层。在模数转换之后，对数字信号进行的增益为数字增益(数字放大)，后期调整曝光即为数字增益。 一、转换增益(Conversion Gain)​ 转换增益(Conversion Gain)表面了在电荷检测节点处，一个电子引起的电压变化大小。[1]增益可由下式求得(公式详见信号电荷的检测与变换-转换增益)： C.G={q\\over C_{FD}}​ 当输入的光信号导致积累的电荷达到满阱容量时，其对应的输出即为纯白，因此，满阱容量实际也会影响增益(可以从动态范围的定义理解)。增益（Gain）实际上是就通过改变施加给光电二极管的电压，进而改变该像素的满阱容量，起到增益的效果。大阱容可以提高动态范围，但是也意味着低增益，导致的后果就是在弱光情况下，难以压制本底噪声，即对于暗部，本底噪声在信号中占较大比例，造成暗部细节丢失、信噪比低。为了解决这个问题，一些传感器上采用了双增益(Dual Gain)。 [1] Junichi Nakamura.数码相机中的图像传感器和信号处理[M].北京:清华大学出版社,2015:41. m). 双增益和双原生ISO​ 为了兼顾高感光度和低感光度，主要有两种解决方案，分别为双增益(Dual Gain)和双原生ISO(Dual ISO)。 一、双转换增益(Dual Gain)​ 即在不同光线情况下使用不同的转换增益。在光线强时增大传感器的满阱容量，即低ISO模式，以提高传感器保留高光的能力；在光线弱时减小满阱容量，即高ISO模式，压制本底噪声，以获得更好的暗部细节。 二、双原生ISO(Dual ISO)​ 双原生ISO(Dual ISO)也被称为双电路增益。双原生ISO并没有改变传感器的阱容，而是在高ISO和低ISO下使用不同的放大电路，放大模拟信号后进行模数转换。双原生ISO不仅可兼顾高低感，还可用来进行HDR合成。比如小米手机中使用的双原生ISO Fusion技术，即将两条放大电路同时打开，高增益的电路用于还原暗部细节，低增益的电路用于保护高光细节，之后再进行像素的合成。 n). 取景器​ 取景器是摄影机上用来给摄影师提供正确选择被摄景物、检查和修改画面构图以及验证画面清晰程度的必要装置。[1]取景器大体可分为光学取景器和电子取景器两大类，每一大类下又可分为若干小类。 一、光学取景器(Optical View Finder)1. 旁轴取景器​ 旁轴取景器一般用于胶片袖珍相机、早期的消费级卡片型数码相机。具有光学取景的无延迟、无拖影、基本不耗电等特点。但因为取景窗与镜头之间有一段距离，导致拍摄者在取景器中观察到的画面与最终得到的影像有着一定的视差。 2. 反射式取景器(TTL取景器)​ 反射式取景器多用于单反相机，利用反光镜和五棱镜(或五面镜)，将通过镜头的光线反射到取景器的目镜。反射式取景器不光有光学取景的优点，还解决了视差问题。但反光式取景器也有着结构复杂、体积较大等缺点，且因为在按下快门后反光镜升起，相较与无反相机会产生较大的机器震动。​ 在部分使用机械式叶子板的摄影机中，会将叶子板的一侧制成反光材质。在叶子板遮挡胶片时，将叶子板作为反射系统的一部分用于取景。这种方式同样做到了实时、无视差。但由于叶子板存在开口会使取景目镜看到的影像交替出现，出现闪烁感。一些摄影机使用无光黑的反射扇面，将反射镜面分为两部分，使目镜中的影像出现的次数增加为49次/秒，以达到减弱闪烁感的目的。[2] 3. 侧面取景器​ 与旁轴取景器类似，取景器位于摄影机机体侧面用于部分胶片摄影机。机体侧移式取景器​ 这种取景方式用于部分胶片摄影机。取景器位于摄影机机体的侧面，摄影机的机体则安装在一个可侧移到滑轨上。当取景时，将摄影机侧移，使取景器镜头位于原先摄影物镜的位置。取景完成后，将摄影机复位，使摄影物镜位于初始位置。这种取景方式可解决视差问题，当无法做到实时取景，因此不适合拍摄运动物体。 4. 焦平面式取景器​ 将一块磨砂玻璃置于焦平面处，取景时用它来代替胶片，由被摄物体反射来的光线在其上聚焦并形成影像，然后通过棱镜光学系统，观看磨砂玻璃上的取景景物。这种取景器因为取景器是通过拍摄镜头观看被摄景物的，因此不存在视差问题。但是，它不能在拍摄时取景，只能在拍摄前取景，所以也不适于运动拍摄。[3] 5. 分光式取景器​ 多用于小型胶片摄影机。在叶子板前方安装一个分光镜，将进入镜头的光线的一部分反射到取景器。这类取景方式看到的画面是实时且无闪烁的，但由于分光镜会分走一部分光线，导致削减了到达胶片的光线强度。 二、电子取景器(Electronic View Finder)​ 电子取景器将一块微型显示屏放在取景器目镜的内部。根据放置显示器的类型的不同可分为LCD取景器和OLED取景器。取景时快门开启，传感器接收光线，再显示到电子取景器上。相较于光学取景器，电子取景器中看到的画面即是传感器上的实际成像，可以实时查看调节光圈、快门速度等参数给画面带来的影响。但也存在着场景还原度不如光学取景器、耗电较大、不利于传感器的保护等缺点。 ​ [1] 常乐，车欣等.电影制作技术手册[M].北京:北京联合出版公司,2017:137. [2] 常乐，车欣等.电影制作技术手册[M].北京:北京联合出版公司,2017:153. [3] 常乐，车欣等.电影制作技术手册[M].北京:北京联合出版公司,2017:153.","categories":[{"name":"相机","slug":"相机","permalink":"https://whitetail-o.github.io/categories/%E7%9B%B8%E6%9C%BA/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"相机","slug":"相机","permalink":"https://whitetail-o.github.io/tags/%E7%9B%B8%E6%9C%BA/"},{"name":"物理","slug":"物理","permalink":"https://whitetail-o.github.io/tags/%E7%89%A9%E7%90%86/"}]},{"title":"Games202-3 Real-time Environment Mapping","slug":"Games202_03_Real-time Environment Mapping","date":"2023-02-01T08:42:10.000Z","updated":"2023-02-12T13:17:10.225Z","comments":true,"path":"2023/02/01/Games202_03_Real-time Environment Mapping/","link":"","permalink":"https://whitetail-o.github.io/2023/02/01/Games202_03_Real-time%20Environment%20Mapping/","excerpt":"Mesh Distance Fields，Real Shading in Unreal Engine 4 a). Shading from Environment Lighting(IBL) 通过环境贴图着色的方式，又被命名为 Image-Based Lighting (IBL) a.1). How 对于IBL，可以看做是上半球（可以联想下UE中的HDRI）的光照和BRDF的积分； Observation： 对于Glossy，其BRDF支持集很小（Lobe范围小）； 对于Diffuse，其BRDF非常平滑； 联想到上节课渲染方程不等式成立的条件（拆出乘积积分的那个） 这里$\\Omega_{G}$ 指积分域上，$g(x)$有值的区域。 如$g(x)$ 为BRDF，$\\Omega_{G}$ 即为原点向Lobe各点出发，与积分半球相交的区域集合 We can safely take the lighting term out! 我们把渲染方程分为了两部分积分，分别是： 在$\\Omega_{fr}$(即Lobe对应的半球区域)，对光照Radiance积分 在半球内对BRDF积分；","text":"Mesh Distance Fields，Real Shading in Unreal Engine 4 a). Shading from Environment Lighting(IBL) 通过环境贴图着色的方式，又被命名为 Image-Based Lighting (IBL) a.1). How 对于IBL，可以看做是上半球（可以联想下UE中的HDRI）的光照和BRDF的积分； Observation： 对于Glossy，其BRDF支持集很小（Lobe范围小）； 对于Diffuse，其BRDF非常平滑； 联想到上节课渲染方程不等式成立的条件（拆出乘积积分的那个） 这里$\\Omega_{G}$ 指积分域上，$g(x)$有值的区域。 如$g(x)$ 为BRDF，$\\Omega_{G}$ 即为原点向Lobe各点出发，与积分半球相交的区域集合 We can safely take the lighting term out! 我们把渲染方程分为了两部分积分，分别是： 在$\\Omega_{fr}$(即Lobe对应的半球区域)，对光照Radiance积分 在半球内对BRDF积分； a.2). Lighting（对Radiance积分） Lighting： \\frac{\\int_{\\Omega_{f_{r}}} L_{i}\\left(p, \\omega_{i}\\right) \\mathrm{d} \\omega_{i}}{\\int_{\\Omega_{f_{r}}} \\mathrm{~d} \\omega_{i}} 即在$\\Omega_{fr}$(即Lobe对应的半球区域)，对光照Radiance积分，再归一化（normalize，分母用于归一化）； 类比于PCF，就是对Environment Map做滤波； 滤波方法：Mipmap 在Shading中，需要获得Lighting项的值，只需要求得Environment Map对应Mipmap层，Lobe中点(镜面反射方向)方向的结果 和百人计划图形2.5中，做Relief Mapping时在Unity用到的texCUBElod()，对Mipmap采样联系上了； 1fixed3 Reflection = ACESToneMapping(texCUBElod(_CubeMap, float4(worldRef, (255-_Gloss)*8/255)).rgb, 1) * SpecularTint * _EnvIntensity; a.3). 对BRDF积分（Split Sum） \\int_{\\Omega^+}f_r(p,w_i,w_o)cos\\theta_i d\\omega_i假设使用微表面理论的BRDF 做法： 预计算考虑进所有变量（roughness、color等）的可能值的积分； 但是，维度过高，存储成本过高，因此需要降维； 降维过程： 对应微表面BRDF，只考虑Fresnel term($F(i,h)$)和distribution of normals($D(h)$) Fresnel term采用the Schlick’s approximation 至此，积分降维为三维 $R_0$ ：零度菲涅尔值 $\\alpha$ ：可表示为roughness，$\\alpha$ 越大，越粗糙； $\\theta(\\theta_h)$ ：在实时渲染中，我们认为出射角、入射角以及入射角/出射角与半程向量的夹角，这三者是相同性质的（不是说值近似相等，而是指作为积分的元素效果相同） 在对BRDF的积分式中，通过Schlick’s approximation，将$R_0$拆出，即写成下列式子 积分现在被降维为二维（$R_0$被拆出，$f_r$中的菲涅尔项被分母抵消） $\\alpha$ $\\theta$ 至此，我们对积分的两项分别进行预计算，储存在表格或者图片中（R、G通道分别两项积分结果）通过LUT查询即可 而$R_0$ 则可通过BaseColor（Metallic Workflow）、Specular（Specular Workflow）贴图或软件内置（一般默认为4%）即可获得；（看百人计划美术 2.7 Metallic与Speculer流程） 名字由来： Split sum 假设使用Lambert的BRDF \\int_{\\Omega^+}f_r(p,w_i,w_o)cos\\theta_i d\\omega_i $f_r = {1\\over \\pi}$ $\\int_{\\Omega^+}cos\\theta_i d\\omega_i = \\pi$ （看Games101 Lecture 17-18 Materials二重积分） 所以正好BRDF积分为1 b). Shadow from Environment Light 在实时渲染中，没有完美的解决方案； 难以用实时渲染方程（那个不等式）来近似： Support大，为整个半球 带有Gloosy项，不够smooth 工业界方法： 只计算最亮的灯光（如UE中HDRI带一个Direction Light） Related research Imperfect shadow maps Light cuts RTRT (Real-Time Ray Tracing, might be the ultimate solution) Precomputed radiance transfer(PRT) c). Spherical Harmonics(SH, 球面谐波函数)c.1). 前置知识Fourier Transform 这里是偶函数，所以 $sin$ 项系数都为0 Convolution Theorem 时域卷积等于频域乘积 A general understanding product intergral: 相乘后积分，对应离散的情况就是相乘后相加。如： $n$维向量$\\bold{a} = (x_1, x_2,…,x_n)$ 和 $\\bold{b} = (y_1, y_2,…,y_n)$ 进行product intergral，即点乘 $\\bold{a} \\cdot \\bold{b} = x_1y_1+x_2y_2+…+x_ny_n$ 我们认为，函数相乘后积分（product intergral），就是滤波（卷积） 积分结果的频率，取决于频率最低的项（$f(x),g(x)$） Basis Functions（基函数） $c_i$ 为系数 如傅里叶变换中，各项就为正交基； 或者多项式和泰勒展开等 c.2). 简介What？ 球谐函数 是一系列 二维球面函数的正交基函数 球谐函数具有正交、归一、完备性 如 f(\\omega)=\\sum_{i} c_{i} \\cdot B_{i}(\\omega) $f(\\omega)$ 为球面函数，$\\omega$ 为向量 $c_i$ 为系数 $B_{i}(\\omega)$ 则为球谐函数 说明： 每一行（$l=n$），频率相同 对于$l=n$行（第$n$阶），函数数量为$2l+1$ 每一阶各SH都有编号，即$m$ 从$-l$ 到 $l$； How？ 每一阶的SH函数，由勒让德多项式求得； 如何求得$c_i$ 投影（Projection） 类似于傅里叶展开中，函数和各个正交基相乘求系数 c.3). 性质 正交性； 投影性； 旋转方便（旋转$f(x)$，相当于旋转基函数$B(i)$） SH中，旋转后的基函数，可通过同阶的基函数线性组合得到； d). Shading from Environment Lighting(SH, Diffuse项)d.1). 简介 如果不通过IBL方式，计算shading，那可以通过SH展开$L_i(p,\\omega_i)$ ，即展开Environment Map（Environment Map可以写成二维函数） d.2). 分析Diffuse项的BRDF $A_l$ 就是基函数的系数； 由图可见，通过SH分析Diffuse项的BRDF后，可得出结论 当$l\\geq3$ (即第四阶开始)，其 $A_l$ 接近0，说明Diffuse项的BRDF频率低，由SH前三阶表示即可； 积分结果的频率，取决于频率最低的项（$f(x),g(x)$） Diffuse BRDF acts like a low-pass filter 因此，对于Environment Map的展开，只需要SH前三阶即可 d.3). SH展开Environment Map 通过求得各球谐函数的结果后，再通过结果逆变换得到Shading结果 通过ShadingPoint法线，再经过一系列计算（？）得到shading e). Precomputed Radiance Transfer 对于渲染方程，如果我们把它每一项都进行Brute-force（蛮力）计算 $L_i$ : 二维，方位角$\\omega$和俯仰角$\\theta$ $V(i)$ : 二维，方位角和俯仰角 $\\rho(\\mathbf{i}, \\mathbf{o})$ : 四维，入射角和出射角的方位角和俯仰角 存储压力过于大； e.1). PRT 前提： 假设场景中除了Lighting，其他都不变； 将RE分为两项， Lighting变化； light transport不变； $V(i): $ 二维，$\\omega,\\theta$，可烘焙为图像，如CubeMap（场景摆放固定） $\\rho(\\mathbf{i}, \\mathbf{o}): $ BRDF Diffuse Case: 常数 Gloosy Case: 四维，$\\omega_{i},\\theta_i, \\omega_o,\\theta_o$，入射和出射的方位角和俯仰角（相机固定，入射角固定） e.2). Diffuse Case 此处（图形学中，大部分情况都是），积分和求和位置可变； 经过预计算后，求得Shading结果只需要在SH空间中，对向量进行点乘即可； e.2.1). 计算 注意： 此处两次求和复杂度仍然是$O(n)$，因为SH基函数具有正交性； Runtime is independent of transport complexity 计算Light Transport简易理解： 积分形式和渲染方程相似，$B_i(\\bold{i})$ 类似于$L_i(\\bold{i})$ ，可看成是将球谐函数作为光照进行Shading得到Light Transport结果 e.3). Glossy Case 此时，BRDF是关于入射和出射的方位角和俯仰角的四维函数； 做法： 对 $\\bold{o}$ 也进行SH展开；（对于Gloosy不止展开到第三阶） light coefficient与Diffuse Case相同，为SH空间的一维向量； transport matrix则是关于 $\\bold{o}$ 和 $\\bold{i}$ 四维函数（入射和出射的方位角和俯仰角），为SH空间的二维矩阵； reflected radiance coefficient则是关于 $\\bold{o}$ 的二维函数（出射角的方位角和俯仰角），通过SH逆变换，即可得出相应视角（ $\\bold{o}$ ）下的Gloosy radiance； 具体怎么变换的？待实现 e.4). 总结和限制 f). Wavelet(小波) 定义在二维平面上的一系列基函数 A non-linear approximation: 二维函数经过小波变换后，大部分系数接近0，这时可采用只记录系数大于一定值的项来近似原函数； 对于Environment Map，小波变换无法变换球面函数，因此展开为Cubemap后进行小波变换； 每一个矩形经过小波变换后，把高频信息放在右上、右下、左下子块，剩下的低频信息放在左上，继续做小波变换； 其他应用：JPG格式图片压缩， 使用类似与小波变换的DCT（Discrete cosine transform，离散余弦变换）、JPEG2000 效果对比： 缺点： 旋转不方便（不同于SH基函数的旋转简易型，小波旋转需要从Wavelet展开，旋转后再做小波变换）","categories":[{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/categories/Games202/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/tags/Games202/"},{"name":"IBL","slug":"IBL","permalink":"https://whitetail-o.github.io/tags/IBL/"}]},{"title":"Games202-2 Real-Time Shadow","slug":"Games202_02_Real-Time Shadow","date":"2023-02-01T08:23:10.000Z","updated":"2023-02-12T13:17:17.247Z","comments":true,"path":"2023/02/01/Games202_02_Real-Time Shadow/","link":"","permalink":"https://whitetail-o.github.io/2023/02/01/Games202_02_Real-Time%20Shadow/","excerpt":"a). Shadow Mapping A 2-Pass Algorithm Light pass: Generate the SM(Shadow Map) Camera pass: uses the SM An image-space algorithm Pro(优点): no knowledge of scene’s geometry is required Con(缺点): causing self occlusion(自遮挡) and aliasing(走样) issues Pass 1: Render from Light 输出一张光源视角的深度图（Depth Buffer） Pass 2: Render from Eye(Camera) 将光源视角对应的深度转换到View Space, 与Camera视角的深度进行深度比较； 如$Depth_{cam} &gt; Depth_{light}$ ，那说明该点在阴影中（相机可见，光源不可见） 如$Depth_{cam} &lt; Depth_{light}$ ，那说明该点在不在阴影中（相机可见，光源可见） 用于比较的深度值： 经过透视投影中的Squeez矩阵后（具体看Games101 Math笔记），z会被推向远平面 $M_{\\text {persp } \\rightarrow \\text { ortho }}=\\left(\\begin{array}{cccc}n &amp; 0 &amp; 0 &amp; 0 \\\\0 &amp; n &amp; 0 &amp; 0 \\\\0 &amp; 0 &amp; n+f &amp; -nf \\\\0 &amp; 0 &amp; 1 &amp; 0\\end{array}\\right)$ 用于比较的$Depth$ 可以是经过MVP中的深度值（即Depth Buffer中的深度值）； 也可以是该点在同一空间（如模型空间）中，该点到相机/光源的线性距离；","text":"a). Shadow Mapping A 2-Pass Algorithm Light pass: Generate the SM(Shadow Map) Camera pass: uses the SM An image-space algorithm Pro(优点): no knowledge of scene’s geometry is required Con(缺点): causing self occlusion(自遮挡) and aliasing(走样) issues Pass 1: Render from Light 输出一张光源视角的深度图（Depth Buffer） Pass 2: Render from Eye(Camera) 将光源视角对应的深度转换到View Space, 与Camera视角的深度进行深度比较； 如$Depth_{cam} &gt; Depth_{light}$ ，那说明该点在阴影中（相机可见，光源不可见） 如$Depth_{cam} &lt; Depth_{light}$ ，那说明该点在不在阴影中（相机可见，光源可见） 用于比较的深度值： 经过透视投影中的Squeez矩阵后（具体看Games101 Math笔记），z会被推向远平面 $M_{\\text {persp } \\rightarrow \\text { ortho }}=\\left(\\begin{array}{cccc}n &amp; 0 &amp; 0 &amp; 0 \\\\0 &amp; n &amp; 0 &amp; 0 \\\\0 &amp; 0 &amp; n+f &amp; -nf \\\\0 &amp; 0 &amp; 1 &amp; 0\\end{array}\\right)$ 用于比较的$Depth$ 可以是经过MVP中的深度值（即Depth Buffer中的深度值）； 也可以是该点在同一空间（如模型空间）中，该点到相机/光源的线性距离； a.1). Issues in Shadow Mappinga.1.1). Self occlusion(自遮挡) Self occlusion： 阴影自遮挡，造成阴影毛刺的现象； 原因： 如上图， Shadow Map分辨率有限，一个像素内记录的深度值相同。如图中红色和橙色斜线表示Shadow Map中深度相同的位置（$Depth_A = Depth_{A’}$）； 当计算平面中$B$点是否在阴影中时，$Depth_{light} = z1 = Depth_A$，而相机视角下的点$B$转换到光源视角下对应的深度为 $z2$ ，即$Depth_{cam} = z2 = Depth_B$ 因此，$Depth_{cam} &gt; Depth_{light}$ ，说明该点在阴影中，因此造成Self occlusion 解决方法： 引入Bias； 认为对于$B$点，如$Depth_{cam} &gt; Depth_{light}$，但$Depth_{light}$ 处于橙色中，那该点仍然不在阴影中； 即： $Depth_{cam} &gt; Depth_{light}+bias$，才使得该点在阴影中； $Depth_{cam} &lt; Depth_{light}+bias$，该点不在阴影中； 易得，当光源方向垂直于平面时，所需的Bias最小，因此可引入光源与平面法线的夹角 $cos\\alpha$ ，来调整Bias大小； 引入bias会造成的问题：Detached shadow(不接触阴影，Peter Panning) a.1.2). Detached shadow 解决方法： Second-depth shadow mapping 工业界实际没什么人用，只是学术界提出的解决方案 a.1.3). Aliasing b). Mathb.1). Approximation in RTR RTR中常用的不等式； 该不等式“准确”的条件： Support（支撑集，积分的范围）足够小时； $g(x)$ 足够光滑（指频率低，起伏小） b.2). 渲染方程的不等式 $V(p,\\omega_i)$为Visibility，阴影因子； 单独拆出Visibility，即先做shading，后做Visibility，最后相乘 b.3). in Shadow Mapping什么情况下，Shadow Mapping（先着色，后计算阴影）是准确的； Small support 在计算阴影中，支撑集小，意味着光源小； 因此，对于点光源和方向光源，做Shadow Mapping硬阴影结果是准确的； Smooth integrand对于不等式处理后的渲染方程，$g(x)$ 代表光照。 当$g(x)$ 足够光滑（指频率低，起伏小），不等式为准确的； $L_i$ 光滑，对应光源为面光源； BRDF，即$f_r$ 光滑，对应Diffuse项； 即对于光源为面光源的Diffuse项，不等式处理后的渲染方程是准确的； c). PCSS(Percentage-Closer Soft Shadow) c.1). PCF(Percentage Closer Filtering) PCF用于抗锯齿，而不用于软阴影（用于软阴影的叫PCSS，两者实质是一个东西，但应用不同叫法不同） 在生成Shadow Map后，阴影比较时（即对阴影比较的结果），进行Filtering 面光源生成Shadow Map：以面光源的中心点(放置相机)生成shadow map 做法： 不止对着色点与其在Shadow Map中的对应点进行深度比较，而是着色点深度与其在Shadow Map中对应点及其周围点深度进行比较，最后对各个Visibility的结果取平均值（或加权平均） eg1. $P$点在Cam视角下深度为$Depth_p$，转换到光源视角下深度为$Depth_{p’}$，$Depth_{p’}$ 与其在Shadow Map中对应点周围3x3（Filter size）像素进行比较，得到结果 \\begin{array}{l} 1,0,1 \\\\ 1,0,1 \\\\ 1,1,0 \\end{array}取平均得到Visibility为 0.667 Filter size Small -&gt; sharper Large -&gt; softer 为选取合适的Filter size，产生了PCSS c.2). PCSS(Percentage-Closer Soft Shadow)c.2.1). 什么是PCSS？ 关键： 自适应Filter size 观察可得： 钢笔（Blocker）与接收平面（Receiver）的距离越小（笔尖），阴影越硬 钢笔（Blocker）与接收平面（Receiver）的距离越大（笔尖），阴影越软 即阴影的软硬程度，一部分取决于Blocker和Receiver的距离 阴影的软硬取决于 $w_{Light}$ （光源的宽度） $d_{Blocker}$ 与 $d_{BtoR}$ 的比值； Blocker定义： Shading point变换到Light视角，对应深度为$Depth_{scene}$ 。查询区域内，深度值$z &lt; Depth_{scene}$ 的texel即为Blocker； $d_{Blocker}$ 为 Average blocker distance Average blocker distance： Shadow Map一定范围内的Blocker的深度平均值 类似eg1 eg1. $P$点在Cam视角下深度为$Depth_p$，转换到光源视角下深度为$Depth_{p’}$，$Depth_{p’}$ 与其在Shadow Map中对应点周围3x3（Filter size）像素进行比较，得到结果 \\begin{array}{l} 1,0,1 \\\\ 1,0,1 \\\\ 1,1,0 \\end{array}取平均得到Visibility为 0.667 其中，Visibility为0的点，即 处于阴影中，$Depth_{cam} &gt; Depth_{light}+bias$ 的点即为Blocker，对Blocker在Shadow Map中的深度值取平均值，即得到Average blocker distance c.2.2). 做法 首先将shading point点$x$投应到shadow map上,找到其对应的像素点$P$。PCSS算法的实现流程如下： 第一步：Blocker search，即获取某个区域的平均遮挡物深度（在点p附近取一个范围(这个范围是自己定义或动态计算的),将范围内各像素的最小深度与x的实际深度比较,从而判断哪些像素是遮挡物，把所有遮挡物的深度记下来取个平均值作为blocker distance。） 第二步：Penumbra estimation，使用平均遮挡物深度计算滤波核尺寸（用取得的遮挡物深度距离来算在PCF中filtering的范围。） w_{\\text {Penumbra }}=\\left(d_{\\text {Receiver }}-d_{\\text {Blocker }}\\right) \\cdot w_{\\text {Light }} / d_{\\text {Blocker }}第三步：Percentage Closer Filtering，对应该滤波核尺寸应用PCF算法。 如何动态计算Blocker search的“某个范围” Light越远，Region越小；Light越近，Region越大；（好像和图不太对应，如非要对应，就类似与Shadow Map位置不变，Light距离变大/小） 那么PCSS中那些步骤会导致速度变慢？ 第一步：Blocker search，需要多次采样查询深度信息并比较，计算Blocker的平均深度$d_{Blocker}$ 第三步：PCF，阴影越软→滤波核尺寸越大→采样查询次数变多→速度变慢 由此可见，主要是多次采样并比较的方法使得速度变慢； 加速方法： 随机采样，后降噪； 如果觉得区域过大不想对每一个texels都进行比较,就可以通过随机采样其中的texels，而不是全部采样，会得到一个近似的结果,近似的结果就可能会导致出现噪声。工业的处理的方式就是先稀疏采样得到一个有噪声的visibility的图,接着再在图像空间进行降噪。 Variance Soft Shadow Mapping(VSSM) c.2.3). Math V(x)=\\sum_{q \\in \\mathcal{N}(p)} w(p, q) \\cdot \\chi^{+}\\left[D_{\\mathrm{SM}}(q)-D_{\\text {scene }}(x)\\right] 其中$\\chi^{+}$ 类似于$step()$ 函数 $D_{\\mathrm{SM}}(q)-D_{\\text {scene }}(x) \\geq 0$， 即$Depth_{ShadowMap} \\geq Depth_{cam}$，$\\chi^{+}\\left[D_{\\mathrm{SM}}(q)-D_{\\text {scene }}(x)\\right] = 1$ $D_{\\mathrm{SM}}(q)-D_{\\text {scene }}(x) &lt; 0$， 即$Depth_{ShadowMap} &lt; Depth_{cam}$，$\\chi^{+}\\left[D_{\\mathrm{SM}}(q)-D_{\\text {scene }}(x)\\right] = 0$ d). Variance Soft Shadow Mapping(VSSM) vs PCSS: Fast blocker search(step 1) and filtering(step 3) 关键思想： 只用知道有多少（百分比）的 texels 在着色点前面； d.1). Solve step3(PCF) 通过正态分布（Normal distribution），求得着色点的深度在采样点中大概的排位，即可得到近似的结果； 需要定义一个正态分布，需要得知其均值（mean）和方差（variance） Mean: Hardware MIPMAPing (快，但不一定准确); Summed Area Tables (SAT, 积分表); Variance: $Var(X) = E(X^2)-E^2(X)$ ，方差等于平方的均值（均方值）减去均值的平方； 只需要在Depth Buffer的空余通道中多存储一个$depth^2$； 通过求正态分布$P(x&gt;Depth_{cam}) (Depth_{cam}为着色点转换到光源视角的深度)$ 的面积，即求CDF（累积分布函数 ）即可求得Visibility CDF(x) 求解： 查表； 切比雪夫不等式； 切比雪夫不等式（并不需要知道具体的分布情况，而是通过不等式直接得出，如使用切比雪夫就不用正态分布，只需要求得均值和方差即可，但是也需要分布情况较为简单） 通过近似值约等出Visibility的结果，即红色面积； （准确的条件：）$t\\geq mean$ （但一般不管这个，就理解成约等就行） 至此解决了Step3 d.2). Solve step1 Shading point转换到光源下， 关键式： \\frac{N_{1}}{N} z_{\\text {unocc }}+\\frac{N_{2}}{N} z_{o c c}=z_{\\text {Avg }} $\\frac{N_{1}}{N} = P(x&gt;t)$ ，通过切比雪夫不等式求出； $\\frac{N_{2}}{N} = 1-P(x&gt;t)$ $z_{Avg}$：SM中，采样范围深度均值 $z_{unocc}$：近似等于$t$ 最终，由关键式得出$ z_{o c c}$ d.3). Summed Area Tables (SAT, 积分表) SAT为数据结构，使用前缀和算法 2D的SAT：每一个点记录左上角区域的和； 先计算一行的一维SAT； 再对计算后的SAT进行列方向的累加，求出二维的SAT； 求蓝色区域和只需要查询四次SAT即可； SAT的并行性： 由于先进行行方向SAT计算，后进行列方向SAT计算，具有一定的并行性； d.4). 缺陷由于使用了切比雪夫不等式或正态分布，隐含了Shadow Map中对应范围的深度分布要较为简单或接近正态分布 如上右图，分布主要集中在三个值，过于离散，造成VSSM不准确； Light leaking（漏光） e). Moment Shadow Mapping(MSM) VSSM不够准确，需要用更高的矩（Moment）来描述PCF（Use higher order moments to represent a distribution） 矩（Moments）： Quite a few variations on the definition We use the simplest: $x,x^2,x^3,x^4,…$ VSSM中，我们用到了二阶矩（$depth^2$） 有点类似于展开（比如泰勒展开）； f). Distance Field Soft Shadow(SDF, 有向距离场)f.1). Distance functions 定义： 对于空间中任意一点，其值为到物体的最近距离。并且可定义其在内部符号（Signed）为负，在外符号为正，即为有向距离场（Signed Distance Functions, SDF）; An Example: Blending (linear interp.) a moving boundary 背后理论： 最优传输（Optimal Transport） SDF性质： 对于刚体，SDF不需要实时计算； $n$个刚体运动，对于一个点$P$ ，就有$SDF_1(P), SDF_2(P)……SDF_n(P)$，那该点最后的SDF值即为$min(SDF_1(P), SDF_2(P)……SDF_n(P))$ 对于形变的物体，SDF需要实时计算； 用途： Ray marching 软阴影 WARNING：不要看到图形就认为SDF是存储一张图形，SDF是三维存储，对于空间中每一个点都有其SDF值 f.1.1). Ray marching 作用：Ray marching(sphere tracing)用来在SDF中射线与物体求交 关键思想： SDF中一点的值，即是该点与周围物体不相交的“安全距离”。如对于点$P$，在周围半径为$SDF(P)$ 的距离内，不与物体相交； 因此，以图为例，求SDF中射线与物体相交只需要依次步进$SDF(P)$ , $SDF(A)$ , $SDF(P)$，只需要终点的$SDF(Last)$ 小于一定值，即该点为交点（或一定次数步进后仍没交点，说明该点无交点） f.1.2). Soft Shadow 作用： 使用SDF来近似表现遮挡百分比（Visibility） 关键思想： SDF中一点的值，即是该点实现不被某一物体遮挡“安全角度” 如着色点$P$看向面光源$AB$，通过得到射向面光源中点的Ray marching来得到”安全角度”。通过安全角度在总角度中的占比，来近似Visibility Smaller “safe” angle &lt;-&gt; less visibility 安全角度： 缺点： 在shader中涉及反三角函数，开销大； 因此用 \\min \\left\\{\\frac{k \\cdot \\operatorname{SDF}(p)}{|p-o|}, 1.0\\right\\}来替代，并用 $k$ 控制阴影的软硬程度； f.2). Pros and Cons Pros 快（使用角度，不考虑生成） 高质量 Cons 需要预计算 需要额外存储（不仅仅是图形，而是需要三维空间存储） 对于形变物体需要大量实时计算 ……","categories":[{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/categories/Games202/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/tags/Games202/"},{"name":"Shadow","slug":"Shadow","permalink":"https://whitetail-o.github.io/tags/Shadow/"}]},{"title":"Games202-1 Recap of CG Basics","slug":"Games202_01_Recap of CG Basics","date":"2023-02-01T08:15:10.000Z","updated":"2023-02-04T06:32:31.699Z","comments":true,"path":"2023/02/01/Games202_01_Recap of CG Basics/","link":"","permalink":"https://whitetail-o.github.io/2023/02/01/Games202_01_Recap%20of%20CG%20Basics/","excerpt":"a). Graphics Pipeline b). OpenGL A. Place objects/models Model specification(模型信息) Model transformation B. Set up an easel(画架) View transformation Create /use a framebuffer C. Attach a canvas to the easel指定Pass到framebuffer，就和Unity中FS的SV_TARGET一样。 E. you can also paint multiple pictures using the same easel 一个Rendering Pass，使用一个framebuffer，渲染一个或多个texture（shading, depth, etc.）作为输出 即一个framebuffer可以绑定多个纹理（MRT） Multiple Render Target（MRT）是一种指可以使绘制程序在单帧中同时渲染多个Render Target D. Paint to the canvas This is when vertex / fragment shaders will be used For each vertex in parallel OpenGL calls user-specified vertex shader: Transform vertex (ModelView, Projection), other ops For each primitive, OpenGL rasterizes Generates a fragment for each pixel the fragment covers For each fragment in parallel OpenGL calls user-specified fragment shader: Shading and lighting calculations OpenGL handles z-buffer depth test unless overwritten Summary: in each pass Specify objects, camera, MVP, etc. Specify framebuffer and input/output textures Specify vertex / fragment shaders (When you have everything specified on the GPU) Render","text":"a). Graphics Pipeline b). OpenGL A. Place objects/models Model specification(模型信息) Model transformation B. Set up an easel(画架) View transformation Create /use a framebuffer C. Attach a canvas to the easel指定Pass到framebuffer，就和Unity中FS的SV_TARGET一样。 E. you can also paint multiple pictures using the same easel 一个Rendering Pass，使用一个framebuffer，渲染一个或多个texture（shading, depth, etc.）作为输出 即一个framebuffer可以绑定多个纹理（MRT） Multiple Render Target（MRT）是一种指可以使绘制程序在单帧中同时渲染多个Render Target D. Paint to the canvas This is when vertex / fragment shaders will be used For each vertex in parallel OpenGL calls user-specified vertex shader: Transform vertex (ModelView, Projection), other ops For each primitive, OpenGL rasterizes Generates a fragment for each pixel the fragment covers For each fragment in parallel OpenGL calls user-specified fragment shader: Shading and lighting calculations OpenGL handles z-buffer depth test unless overwritten Summary: in each pass Specify objects, camera, MVP, etc. Specify framebuffer and input/output textures Specify vertex / fragment shaders (When you have everything specified on the GPU) Render c). Shading Language(GLSL)c.1). Initializing Create shader(Vertex and Fragment) Compile shader Attach shader to program Link program Use program c.2). Phong Shader in Assignment 0 Vertex Shader attribute: 顶点附带的属性，FS中不会出现 uniform: 全局变量，由CPU直接传递给GPU varying: 需要插值的变量 highp: 高精度 gl_Position: 类似于Unity的SV_Position，裁剪空间中的顶点位置； Fragment Shader","categories":[{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/categories/Games202/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/tags/Games202/"}]},{"title":"Games101_19_20 Cameras Lenses and Light Fileds","slug":"Games101_19_20_Cameras_Lenses_LightFileds","date":"2022-10-03T10:25:10.000Z","updated":"2023-02-04T06:31:58.850Z","comments":true,"path":"2022/10/03/Games101_19_20_Cameras_Lenses_LightFileds/","link":"","permalink":"https://whitetail-o.github.io/2022/10/03/Games101_19_20_Cameras_Lenses_LightFileds/","excerpt":"Lecture19 讲相机的，老本行笔记直接看别人的吧； http://t.csdn.cn/4gODC b). Light Field / Lumingraph(光场) 两者看到的光线信息完全相同，那人眼中的世界就完全相同； b.1). The Plenoptic Function(全光函数) 现实世界可以用一个七维的全光函数进行描述，记录了任意时间，不同位置的不同方向接收光的波长 参数： $\\theta$ ：方位角 $\\phi$：俯仰角 $\\lambda$：波长 $t$：时间 $V_X，V_Y,V_Z$：位置 b.2). Light Field光场则可以认为是记录了任何一个点所接收的任何一个方向的irradiance。 可用四维函数表示，二维描述位置，二维描述方向 光线可由两个点定义，因此这四维可改写成s,t,u,v。即两个平面上的位置； 由此得出，描述一个物体的光场，只需要记录其包围盒上四维的全光函数即可 从uv平面看向st平面，得到的是这个物体从各个方向看的相应的图像； 而从st看向uv，则得到的是这个物体在这个方向的irradiance的集合（不是合起来，而是类似二维数组的集合）即radiance st到uv 记录不同方向的光线radiance（注意和拜耳阵列的区分，这里三色只是代表不同方向）","text":"Lecture19 讲相机的，老本行笔记直接看别人的吧； http://t.csdn.cn/4gODC b). Light Field / Lumingraph(光场) 两者看到的光线信息完全相同，那人眼中的世界就完全相同； b.1). The Plenoptic Function(全光函数) 现实世界可以用一个七维的全光函数进行描述，记录了任意时间，不同位置的不同方向接收光的波长 参数： $\\theta$ ：方位角 $\\phi$：俯仰角 $\\lambda$：波长 $t$：时间 $V_X，V_Y,V_Z$：位置 b.2). Light Field光场则可以认为是记录了任何一个点所接收的任何一个方向的irradiance。 可用四维函数表示，二维描述位置，二维描述方向 光线可由两个点定义，因此这四维可改写成s,t,u,v。即两个平面上的位置； 由此得出，描述一个物体的光场，只需要记录其包围盒上四维的全光函数即可 从uv平面看向st平面，得到的是这个物体从各个方向看的相应的图像； 而从st看向uv，则得到的是这个物体在这个方向的irradiance的集合（不是合起来，而是类似二维数组的集合）即radiance st到uv 记录不同方向的光线radiance（注意和拜耳阵列的区分，这里三色只是代表不同方向） b.3). Light Field Camera 支持先拍照，后期动态调焦、光圈等 Lecture20","categories":[{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/categories/Games101/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/tags/Games101/"}]},{"title":"Games101_17_18 Materials","slug":"Games101_17_18_Materials","date":"2022-10-03T10:20:10.000Z","updated":"2023-02-12T13:17:44.929Z","comments":true,"path":"2022/10/03/Games101_17_18_Materials/","link":"","permalink":"https://whitetail-o.github.io/2022/10/03/Games101_17_18_Materials/","excerpt":"Lecture 17 Materials and AppearancesMaterial == BRDF a). Diffuse / Lambertian Material 对于此类材质，当假定各方向9入射的光线radiance相同，反射的光同样是Uniform的。因为能量守恒（假定不发光，不吸收），使得进入的 Irradiance入 和出去的 Irradiance出 相同； 二重积分 b). Glossy material c). Ideal reflective / refractive material(BSDF) 计算镜面反射方向 几何 方位角 c.1). Specular Refraction 现象：色散、Caustic等 Snell’s Law 可推出只有当光密到光疏介质时，才有可能发生折射；（${n_i\\over n_t}&gt;1$） 折射属于BT(Transmit)DF; BTDF + BRDF = BSDF c.2). Fresnel Reflection(菲涅尔) 反应了特定方向的入射光的反射和折射的比例； 左图是绝缘体的菲涅尔项，右图是导体（金属）的菲涅尔项","text":"Lecture 17 Materials and AppearancesMaterial == BRDF a). Diffuse / Lambertian Material 对于此类材质，当假定各方向9入射的光线radiance相同，反射的光同样是Uniform的。因为能量守恒（假定不发光，不吸收），使得进入的 Irradiance入 和出去的 Irradiance出 相同； 二重积分 b). Glossy material c). Ideal reflective / refractive material(BSDF) 计算镜面反射方向 几何 方位角 c.1). Specular Refraction 现象：色散、Caustic等 Snell’s Law 可推出只有当光密到光疏介质时，才有可能发生折射；（${n_i\\over n_t}&gt;1$） 折射属于BT(Transmit)DF; BTDF + BRDF = BSDF c.2). Fresnel Reflection(菲涅尔) 反应了特定方向的入射光的反射和折射的比例； 左图是绝缘体的菲涅尔项，右图是导体（金属）的菲涅尔项 d). Microfacet Material(微表面材质) 关键： 微表面的法线分布 d.1). Microfacet BRDF 菲涅尔项； Shadowing-masking term 考虑微表面之间的遮挡和阴影； 当光线几乎平行与表面入射时(Grazing angle)，微表面之间遮挡变多 Disterbution of normals e). Isotropic / Anisotropic Materials (BRDFs) Key: directionality of underlying surface e.1). Anisotropic BRDFs 如尼龙、天鹅绒等 f). Properties of BRDFs(BRDF的性质) 非负性 f_{r}\\left(\\omega_{i} \\rightarrow \\omega_{r}\\right) \\geq 0 线性性质 如 高光、漫反射、环境光等的BRDF分开计算最后再求和，和用整体的BRDF和整体的光线一起计算结果相等 可逆性 能量守恒 各向同性时，BRDF可转为三维(两个俯仰角，及方位角之差) Lecture 18 Advanced Topics in Renderinga). Advanced Light Transporta.1). 分类 Unbiased（无偏）： 无论采样多少次，其数学期望和正确的值相同； 否则，则为biased（有偏） 在某种情况下（如采样数增大），其数学期望逐渐向正确的值收敛，则称为consistent（一致的） a.2). Bidirectional Path Tracing(BDPT) 当使用PT，摄影机出发的光线的第一次Bounce大部分是Diffuse时，其不容易得到光线强的方向的贡献，此时BDPT效率更高（语言待优化） a.3). Metropolis Light Transport(MLT) 通过马尔科夫链 在已有样本周围形成新样本，其得到的PDF的形状与被积函数 $f(x)$ 形状一致（此时）方差最小； 优点：适合复杂、困难的光线传播 如：图一和图二SDS(Specular-Diffuse-Specular) 缺点：难以估计何时收敛，不知道采样到什么程度才可以没噪声，造成Dirty； a.4). Photon Mapping(光子映射) 做法之一： 光源发射光子，弹射数次后最终停留在Diffuse表面 摄影机发射光子，弹射数次后最终停留在Diffuse表面 局部密度估值（光子密度越大，该点越亮）； 可使用KD-Tree等加速结构 biased会导致模糊 a.5). Vertex Connection Merging(VCM) 使用BDPT后，对于临近的端点使用Photon Mapping 电影常用 a.6). Instant Radiosity(实时辐射度) 出现亮点原因： 计算直接光照时，换元成了dA，而此处换元依赖于，面积A和立体角w的计算，其中分母是距离的平方，如果距离很接近，那么就会除以一个极小值，使得结果变过大 b). Advanced Appearance Modelingb.1). 分类 b.2). Non-surface modelsb.2.1). Participation media 光在传播过程中，有穿过一个Participation medium，那么它会被吸收、散射 Rendering b.2.2). Hair/Fur Appearance Kajiya_Kay_Model Marschner Model 认为毛发表面类似玻璃柱，其中分为Cuticle（表皮）、Cortex（皮质，吸收光） 光经过毛发被分为3项，R、TT、TRT Double Cylinder Model 考虑了髓质（Medulla，散射光线） 光经过毛发被分为5项，R、TT、TRT、TTs、TRTs b.2.3). Granular Material（颗粒材质） b.3). Surface modelsb.3.1). Translucent(半透明) Material 概念：Translucent实际上和半透明有一定区分，它还涉及到吸收、散射（SSS）等现象。Translucent只是表示光从表面一个地方进入，再从表面一个地方射出（如玉石、人的皮肤、水母等）； Subsurface Scattering BSSRDF： 对BRDF的延伸，一点出射方向的贡献不止有该点，还有周围点的贡献（多了对面积的积分） Dipole Approximation（模拟次表面散射的一种方法） 材质下加入一个光源，材质上也加入一个虚拟光源 b.3.2). Cloth Rendering BRDF 分块，每一块都是Participating Media b.3.3). Detailed Appearance: Motivation $D(h)$ 过于简单，无法模拟细节 Result b.4). Procedural Appearance","categories":[{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/categories/Games101/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/tags/Games101/"},{"name":"Materials","slug":"Materials","permalink":"https://whitetail-o.github.io/tags/Materials/"}]},{"title":"Games101_21_22 Animation","slug":"Games101_21_22_Animation","date":"2022-10-03T10:20:10.000Z","updated":"2023-02-12T13:17:31.677Z","comments":true,"path":"2022/10/03/Games101_21_22_Animation/","link":"","permalink":"https://whitetail-o.github.io/2022/10/03/Games101_21_22_Animation/","excerpt":"Lecture 21 Animationa). Historyb). Keyframec). Physical Simualtion c.1). Mass Spring System Idealized spring 但永远不会停止，因此加入摩擦力 中间项为相对速度在向量$ab$方向的投影，因为（处于原长状态时）如果a点不动，b点绕a点做圆周运动，那$f_b=0$； 但是无法表现剪切力（如对角线拉布，布基本形状不变）、弯曲力（out-of-plane，抗拒被像纸一样完全折叠为两个三角形）等 加入两条对角线，以及skip connection 红色较弱，仅其辅助作用；蓝色较强，其主要作用； 其他方式：FEM (Finite Element Method, 有限元) Instead of Springs，考虑力传导 c.2). Particle System 粒子系统不仅可描述微小粒子，还可以描述一些群落； d). Forward Kinematics(FK) 关节（Joint）分类： e). Inverse Kinematics(IK) 解决多个解的方法：梯度下降 f). Rigging Blend shapes: 混合控制点或骨骼位置 g). Motion Capture / Facial Motion Capture","text":"Lecture 21 Animationa). Historyb). Keyframec). Physical Simualtion c.1). Mass Spring System Idealized spring 但永远不会停止，因此加入摩擦力 中间项为相对速度在向量$ab$方向的投影，因为（处于原长状态时）如果a点不动，b点绕a点做圆周运动，那$f_b=0$； 但是无法表现剪切力（如对角线拉布，布基本形状不变）、弯曲力（out-of-plane，抗拒被像纸一样完全折叠为两个三角形）等 加入两条对角线，以及skip connection 红色较弱，仅其辅助作用；蓝色较强，其主要作用； 其他方式：FEM (Finite Element Method, 有限元) Instead of Springs，考虑力传导 c.2). Particle System 粒子系统不仅可描述微小粒子，还可以描述一些群落； d). Forward Kinematics(FK) 关节（Joint）分类： e). Inverse Kinematics(IK) 解决多个解的方法：梯度下降 f). Rigging Blend shapes: 混合控制点或骨骼位置 g). Motion Capture / Facial Motion Capture Lecture 22a). Single Particle Simulation Velocity vector field: 给定位置，可以得出改点速度。和磁场、电场类似； Oridinary Differential Equation(ODE, 常微分方程) 已知解得 t 时刻，粒子的位置和速度，需求得下一时刻的粒子位置； 方法1：显式欧拉法（Explicit Euler method），用差分代替微分，但会引起误差，且稳定性差； a.1). Euler’s Method 缺点： 存在误差，可通过减小步长（$\\Delta t$）来减少误差； 稳定性差，如速度场为同心圆时，不管步长多小都会逐渐偏移（diverge） a.2). Combating Instability a.2.1). Midpoint Method 计算下一时刻位置后取中点，得到中点速度，在计算下一时刻位置时，使用中点速度 a.2.2). Adaptive Step Size a.2.3). Implicit Euler Method 使用下一时刻的速度和加速度，并求解 、 龙格库塔 a.2.4). Position-Based / Verlet Integration 非基于物理 时间快 b). Rigid Body Simulation 与单粒子类似 c). Fluid Simulationc.1). A Simple Position-Based Method c.2). Eulerian vs. Lagrangian 拉格朗日（质点法）：考虑单个粒子的运动 欧拉（网格法）：考虑不同位置的网格 Material Point Method (MPM ，混合上两种方法)","categories":[{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/categories/Games101/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/tags/Games101/"},{"name":"Animation","slug":"Animation","permalink":"https://whitetail-o.github.io/tags/Animation/"}]},{"title":"Games101-13-16 RayTracing","slug":"Games101_13_16_RayTracing","date":"2022-10-03T10:15:10.000Z","updated":"2023-02-12T13:18:29.194Z","comments":true,"path":"2022/10/03/Games101_13_16_RayTracing/","link":"","permalink":"https://whitetail-o.github.io/2022/10/03/Games101_13_16_RayTracing/","excerpt":"Lecture 13 Ray Tracinga). vs. Rasterization 光栅化难以表现全局（global）效果，如 （软）阴影（Soft shadows） 光线反弹超过一次（Glossy reflection） Indirect illumination（间接光照） Rasterization is fast, but quality is relatively low； b.). Basic Ray-Tracing Algorithm 光追中光线的性质： 光是沿直线传播的； 光相交时，并不产生干扰； 光从光源出发，传播到眼睛（由于光路可逆，也可是光线从眼睛出发，传播到光源） b.1). Ray Casting 做法： Generate an image by casting one ray per pixel;（生成从眼睛出发的光线） Check for shadows by sending a ray to the light;（检查光线投射点是否可传播到光源） 光线由眼睛出发，可不再使用深度缓存； 投射点到光源发射Shadow Ray，查看该点是否在阴影里（是否对光源可见）；","text":"Lecture 13 Ray Tracinga). vs. Rasterization 光栅化难以表现全局（global）效果，如 （软）阴影（Soft shadows） 光线反弹超过一次（Glossy reflection） Indirect illumination（间接光照） Rasterization is fast, but quality is relatively low； b.). Basic Ray-Tracing Algorithm 光追中光线的性质： 光是沿直线传播的； 光相交时，并不产生干扰； 光从光源出发，传播到眼睛（由于光路可逆，也可是光线从眼睛出发，传播到光源） b.1). Ray Casting 做法： Generate an image by casting one ray per pixel;（生成从眼睛出发的光线） Check for shadows by sending a ray to the light;（检查光线投射点是否可传播到光源） 光线由眼睛出发，可不再使用深度缓存； 投射点到光源发射Shadow Ray，查看该点是否在阴影里（是否对光源可见）； c). Whitted-Style Ray Tracing(Recursive, 递归) 过程： 生成眼睛到像素a的光线（Primary ray），打到第一个与光线相交的点； 形成反射（镜面反射）和折射的光线（Secondary rays，之后的都是Secondary rays）； 对每条光线与object的交点做到光源的光线（Shadow rays）； 将所有Shadow rays未被阻挡的光线的着色结果相加，即为像素a的着色结果； c.1). Ray-Surface Intersection（求交点）c.1.1). 与球形相交： 推广：与隐式表面相交 c.1.2). 与三角形求交： 几何上：判断内外； 空间内任意一点为起点做一光线，若该光线与object（封闭）交点数为奇数，则该点在object内；若交点数为奇数，则该点在object外；（缠绕数的奇-偶原则） 计算过程： 即 $r(t)=o+td,0\\leq t &lt; \\infty$ 和 $(p-p’)·N=0$ 联立求 $t$； 之后求得点P是否在三角形内； Möller Trumbore Algorithm 按传统求解，求出 $t$ 后，还需要判断 P 点是否在三角形内，较为繁琐，因此提出Möller Trumbore Algorithm 射线$r(t)=O+tD$ ，与由重心坐标表示的三角形上的点 $P$ 求解（三个式子，三个未知量，根据克拉默必定有解）； 求得交点后，可通过重心坐标得知该点是否在三角形外； c.2). Acclerating Ray-Surface Intersection 原因：当需要求得光线最近的交点时，需要遍历场景所有三角面，速度慢，需要加速； c.2.1). Axis-Aligned Bounding Box(AABB，轴对齐包围盒) Bounding Volumes 思想：当物体不与包围体积相交时，更不可能和物体相交； Bounding Box（AABB for example）： 理解：盒子是3对对立的面的交集； Axis-Aligned Bounding Box(AABB) AABB包围盒的面总在xy/xz/yz平面； 光线与AABB求交： 2D情况下（3D同理） 思想： 光线进入Box：只有当光线进入所有的对立面； 光线出Box：只要光线出射一个对立面； 对于3D的Box，$t_{enter}=max\\{t_{min}\\},t_{exit}=min\\{t_{max}\\}$； 如果 $t_{enter}&lt;t_{exit}$，则光线经过Box； 对于 $t_{enter}$ 和 $t_{exit}$ 正负情况的考虑： $t_{exit}&lt;0$：不相交（Box在光线后边） $t_{exit}&lt;0$ and $t_{enter}&lt;0$：光线起点在盒子里，一定相交 当且仅当 $t_{enter}&lt;t_{exit}\\quad\\&amp;\\&amp;\\quad t_{exit}\\geq0$，光线与AABB相交； 为什么使用AABB：求交方便； Lecture 14&amp;15 Ray Tracing(Acceleration &amp; Radiometry; Light Transport &amp; Global Illumination)a). Uniform Spatial Partitions（统一空间分区） Heuristic: #cells = C * #objs C ≈ 27 in 3D 缺陷： 格子大小相同，浪费空间； 对于空间分布不均匀的场景容易造成“Teapot in a stadium” problem，浪费性能； b). Spatial Partition 常见的空间划分的类型： Oct-Tree（3维中是八叉树，2维中是四叉树；$2^n$叉树，n=维度） 受维度影响； KD-Tree； 每次只划分一次，如果是三维则按x，y，z方向循环划分； BSP-Tree b.1). KD-Tree 预处理：对空间进行划分，对于子空间每次只划分一次（1、2、3划分省略）； 树节点（Internal node）的数据结构： 划分轴：x-, y- , or z-axis; 划分位置：分割平面沿轴的坐标；（？） 子节点； 不存储object； 叶子节点数据结构： object的列表 过程： 光线和叶子节点1（为方便把$1$暂看作叶子节点，尽管个节点应该继续划分，$2,3$同理）相交，判断光线和$1$中储存的object是否相交（无相加，继续）； …… 光线和叶子节点3相交，判断光线和$1$中储存的object是否相交，相交，记录$t_{hit}$； 缺点： 预处理的过程中，物体（三角形）和网格求交难； 如三角形和Box求交，有可能是一个小Box穿过三角形（被三角形“包裹”） 同一个Object可能储存在多个叶子节点中； c). Bounding Volume Hierarchy (BVH) 特征：先将object分为两组，再重新计算包围盒，使得同一个obejct只会在一个叶子节点中出现；（但会造成Bounding Box空间的冗余） 过程： 找到包围盒； 递归地将物体的集分为两个子集； 重新计算子集的包围盒； 满足条件时停止； 储存objects到对应的叶子节点； 划分子节点： 选择一个维度去划分； Heuristic #1: 选择最长的轴去划分； Heuristic #2: 选择中间的object的位置去划分；（快速选择算法） BVHs的数据结构： 非叶子节点： Bounding box Children: pointer to child nodes 叶子节点： Bounding box List of objects Nodes represent subset of primitives in scene BVH Traversal: 空间划分和物体划分: d). Radiometryd.1). Radiant Energy and Flux(Power) Radiant Energy(辐射能量): Definition: Radiant energy is the energy of electromagnetic radiation. It is measured in units of joules, and denoted by the symbol: Q[J=Joule] Flux(辐射通量): Definition: Radiant flux (power) is the energy emitted, reflected, transmitted or received, per unit time. \\Phi \\equiv \\frac{\\mathrm{d} Q}{\\mathrm{~d} t}[\\mathrm{~W}=\\mathrm{Watt}][\\operatorname{lm}=\\text {lumen}] Important Light Measurements of Interest d.2). Radiant Intensity(辐射强度) 定义：单位立体角上，产生的、反射的、接收的辐射通量。符号：I；单位：瓦特/sr、lm/sr、candela、cd。 立体角(solid angle)是有方向的，所以辐射强度是一个方向有关的属性 d.2.1). Solid angle 角度（2D）： 弧长除以半径； $\\theta={l\\over r}$ 立体角：立体角面积除以半径的平方 $\\Omega=\\frac{A}{r^{2}}$ 球体的立体角为$4\\pi$ d.2.2). 计算过程 立体角微分： 二重积分计算，总的立体角 = 球面上无数个单位立体角的加和，即∫∫sinθdθdφ积分限也比较好理解：θ：0 → π，一个半圆弧， φ：0 → 2π，用半圆转一整圈得到球面 通常把ω当做方向向量来理解，这样比较好描述intensity 如果点光源向三维空间中均匀的辐射出能量，怎么描述强度？ I = Φ / 4πΦ：点光源单位时间内，向三维空间中辐射出的能量4π：整个三维空间的总立体角其比值就是单位立体角上的辐射通量 d.2.3). Irradiance(辐照度) 定义：每单位面积（与光线垂直，Lambert’s Cosine Law）的能量 Lambert’s Cosine Law e.g. 太阳高度角造成四季变化 随半径变大，Irradiacne变小，而radiant intensity不变； d.2.4). Radiance(辐亮度) 介绍： Radiance是和光线有关的量； 渲染就是在计算radiance； 单位：The radiance(luminance) is the power emitted. reflected, transmitted or receivedd by a surface, per unit solid angle, per projected unit area. 理解： Radiance定义：power per unit solid angle, per projected unit area. Irradiance: power per projected unit area Intensity: power per solid angle So: Radiance: Irradiance per solid angle ​ - Incident Radiance Radiance: Intensity per projected unit area ​ - Exiting Radiance Incident Radiance: The irradiance per unit solid angle arriving at the surface 即 $\\omega$ 方向的光线对于 $dA$ 的贡献； Exiting Radiance: The intensity per unit projected area leaving the surface 即面积光 $dA$ ，对 $\\omega$ 出射方向的贡献； Irradiance vs. Radiance Irradiance和Radiance的区别在于方向性； 图中，$dA$ 的辐照度 $E(p)$ 为各方向（半圆）对 $dA$ 的贡献。$dA$ 的Radiance $L_i(p,w)$ 为入射方向 $d\\omega$ 对 $dA$ 的贡献； 即，Irradiance $E(p)$ 是 radiance $L_i(p,w)$ 对于各个立体角的积分，$L_i(p,\\omega)$ 是 $E(p)$ 方向 $\\omega$ 的积分； c). BRDF(Bidirectional Reflectance Distribution Function)Ver Games101 过程：光线照射到一点（$p$），该点吸收能量，再辐射出去； 定义： 分母：${\\omega}_i$ 方向入射的radiance $L_i(x,{\\omega}_i)$，被一点吸收后，辐射往各个方向的Irradiance $E_i({\\omega}_i)$； 分子：$E_i({\\omega}_i)$，对 ${\\omega}_r$ 方向radiance的贡献 $L_r(x,{\\omega}_r)$ Ver self: 定义：BRDF（双向反射分布函数, bidirectional reflective distribution function）， 是指当一束光从某个方向( $\\vec l$ )照射到某个点($p$)上时，在某个方向上( $\\vec v$ )的出射辐射通量占总的入射辐射通量的比例 基于物理着色：BRDF - Maple的文章 - 知乎 关于brdf的两件小事 - Dua的文章 - 知乎 可以理解对于某一微小（对立体角）出射光线ωi，某一微小入射光线ωj对其radiance的贡献； 也可以理解成某一微小入射光线ωj，弹射到某一方向的微小立体角ωi的光线强度的比值； 由于为了方便测量，不定义为radiance相除（即如果按照我们一开始对入射方向 微分的方式定义brdf，那么科学家们只需要使用一个极小的光源从 方向入射到点p，就可以测得brdf的值。但是如果定义为radiance相除，就很难输入一个填充立体角刚好等于1的光源。)正常单位为： {1\\over{sr}} d). Rendering equationd.1). 简介 The Reflection Equation $f_r(p,w_i,w_r)$ 为该点的BRDF 问题： incoming radiance 不止来源于光源，也来源于其他反射（递归）； 未考虑自发光情况（加入自发光项，变为渲染方程） The Rendering Equation 加入了自发光项 $L_e(p,{\\omega}_o)$ 考虑多次反射 注意：该方程假定所有方向都是朝外的； $H^2$ 和 $\\Omega$ 表示半球的积分域； d.2). 理解 Reflection Equation: 反射的Radiance是各个方向光源对出射方向Radiance贡献的积分； 未考虑光线多次弹射 Rendering Equation: 考虑多次弹射，即其他物体反射的光线也会对出射方向 ${\\omega}_r$ 的Radiance做出贡献； 对于渲染方程，只有 $L_r(x,{\\omega}_r)$ 和 $L_r(x’,-{\\omega}_i)$ 是未知的； 简化渲染方程： Rendering Equation as Integral Equation Linear Operator Equation $E$ 环境中自发光对应向量，$L$ Radiance对应的向量； $K$ 反射算子（矩阵） 对于Rendering Equation的线性形式，我们可以用以下式子逼近（类似泰勒展开）： Rendering Equation的线性形式对于光追的启示： $E$ 为自发光，$KE$ 为 直接光照（即弹射一次），$K^2E$ 为间接光照（弹射两次） 全局光照（Global illumination, GI）：直接光照+间接光照 基础的光栅化只做了自发光和直接光照，即 $E$ 和 $KE$ 对比 上方玻璃灯：两次弹射时，光线从摄影机出发不能从玻璃罩中射出，因此其为黑色。而四次弹射时，光线从摄影机出发可以从玻璃罩中射出； 当bounce数目增大时，亮度会趋于一个值，而不会无限增大； e). Probability Lecture 16 Ray Tracing 4 (Monte Carlo Path Tracing)a). Monte Carlo Integration 使用原因：一些函数过于复杂，因此对于特定积分域，不求不定积分，只求其积分的结果。（一种数值方法） 过程：对函数的随机样本进行平均来估计函数的数值； 除以 $p(x_i)$ 是一种加权，因为对于积分域上样本的采样可能是不均匀随机采样 均匀采样的情况： Some notes： 采样越多，方差越小 如在$x$上积分，要采样$x$ b). Paht Tracingb.1). vs Whitted-Style Ray Tracing Whitted-Style Ray Tracing 遇到光滑物体会只会 反射/折射（择一进行） 无法表现Glossy reflection 遇到漫反射物体停止弹射 没有Color Blooding(eg.direct illumination)，考虑不到漫反射物体之间的光线传播 But the rendering equation is correct L_{o}\\left(p, \\omega_{o}\\right)=L_{e}\\left(p, \\omega_{o}\\right)+\\int_{\\Omega^{+}} L_{i}\\left(p, \\omega_{i}\\right) f_{r}\\left(p, \\omega_{i}, \\omega_{o}\\right)\\left(n \\cdot \\omega_{i}\\right) \\mathrm{d} \\omega_{i} 需要做的： 解决半球域的定积分 蒙特卡洛积分 递归 b.2). A Simple Monte Carlo Solution(Direct illumination) 渲染一个Pixel（Point），当前 之考虑直接光照 当 $\\omega_i$ 与light相交时，计算该方向的radiance；与Box相交时，则该方向的radiance=0； P-Code b.3). Global illumination(加入递归)b.3.1). GI and problems P-Code Problem1: Explosion of #rays as #bounces go up 解决方法： N=1（N=1即Path Tracing，Distributed Ray Tracing if N != 1） N=1会造成较多的Noise，因此采用Subpixel，即每个像素内多次采样（Samples per pixel, SPP） Problem2: 递归不会停止 现实世界中，光线的弹射次数是无限的 简单地，减少弹射次数 == 减少能量； 解决方法： Russian Roulette(RR, 俄罗斯轮盘赌) b.3.2). Russian Roulette(RR, 俄罗斯轮盘赌) 先前一点的着色结果是 $L_o$，引入RR后 With probability $P$, shoot a ray and return the shading result divided by P: Lo / P With probability $1-P$, don’t shoot a ray and you’ll get 0 由此可得出数学期望 $E=P \\cdot\\left(\\frac{L_{o}}{p}\\right)+(1-P) \\cdot 0=L_{o}$ b.3.3). 优化 计算直接光照时，如对点P向各个方向均匀采样，当光源小时，直接光照的贡献会小，造成较多的噪声； 解决方法： 换元，使渲染方程对光源面积 $A$ 进行积分，pdf = 1/A d \\omega=\\frac{d A \\cos \\theta^{\\prime}}{\\left\\|x^{\\prime}-x\\right\\|^{2}} (Note: \\theta^{\\prime} , not \\theta ) 立体角可以看前面辐射度量学的部分 过程：（直接光照，间接光照分开计算） light source (direct, no need to have RR) other reflectors (indirect, ues RR) P-Code（未考虑遮挡） 遮挡 附上上学期做的光追（借鉴smallpt）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531/*** 采用Monte Carlo Path Tracing* 漫反射采用的是Lambert* 定义了三角面片和球体，其中三角面片可多片合成一个对象，* 与三角面片求交则使用克拉默法则，而基于此做条件上的修改就可构建平行四边形，因此将平行四边形也归入三角面片* 用平行四边形代替两个三角面片在适用且数量较多的情况下可显著提高运算效率* 球体求交运算量小于三角面片，因此墙壁通过大半径的球体构建** 由于想要表现出计算过程，许多数学运算未化简，运算效率不高* 由于未使用BVH等方式约束，三角面片较为影响性能* 目前场景除墙面外中有两个球体（镜面反射以及玻璃），以及一个立方体，通过6个三角面片（平行四边形）构成** 由于为了提高运算效率，本程序中使用的蒙特卡洛采样方向约束在朝向其他对象的方向（射线在必定与其他对象相交的范围内随机），* 但三角面片的约束范围较复杂，因此不支持将三角面片定义为光源** 虽会增加噪声，为了运算效率，除了最大迭代次数，还引入经处理可使radiance的数学期望与原值相同的Russian Roulette，开始RR的次数为最大迭代次数除以2* * 由于运算量大，采样默认设置为1，如想提高运行效率可删除掉三角面片* * 绘制通过glut* 程序输出为ppm格式图片**/#define _CRT_SECURE_NO_WARNINGS#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;math.h&gt;#include &lt;iostream&gt;#include &lt;iomanip&gt;#include &lt;gl/glut.h&gt;#define DEPTH_MAX 10 //最大迭代次数#define WIDTH 512#define HIGHT 385double M_PI = 3.1415926535;double erand48(unsigned short xsubi[3]) &#123; return (double)rand() / (double)RAND_MAX;&#125;struct Vec &#123; double x, y, z; Vec(double _x = 0, double _y = 0, double _z = 0) &#123; x = _x; y = _y; z = _z; &#125;; Vec operator+(const Vec&amp; b) const &#123; return Vec(x + b.x, y + b.y, z + b.z); &#125;; //加 Vec operator-(const Vec&amp; b) const &#123; return Vec(x - b.x, y - b.y, z - b.z); &#125; //减 Vec operator*(double b) const &#123; return Vec(x * b, y * b, z * b); &#125;; //数乘 Vec mult(const Vec&amp; b) const &#123; return Vec(x * b.x, y * b.y, z * b.z); &#125; //数乘 Vec&amp; norm() &#123; return *this = *this * (1 / sqrt(x * x + y * y + z * z)); &#125; //单位向量 double dot(const Vec&amp; b) const &#123; return x * b.x + y * b.y + z * b.z; &#125; //点乘 Vec cross(const Vec&amp; b) const &#123; return Vec(y * b.z - z * b.y, z * b.x - x * b.z, x * b.y - y * b.x); &#125; //叉乘&#125;;struct Ray &#123; Vec o, d; Ray(Vec _o, Vec _d) : o(_o), d(_d) &#123;&#125;;&#125;;enum Refl_t &#123; //反射类型 DIFF, SPEC, REFR&#125;;struct MeshTriangle &#123; // 三角面片 const Vec* verts; // 顶点 const int* vertsIndex; //顶点排序 const int numTris; // 三角形数量 Vec* vertices; Vec e, c; // emission, color Refl_t refl; int isTriangle; //顶点， 顶点列表（决定构建顺序以及法线正负）， 三角面片数量， emission, color， 材质， 是否是三角形（或平行四边形） MeshTriangle(const Vec* _verts, const int* _vertsIndex, const int _numTris, Vec _e, Vec _c, Refl_t _refl, int _isTriangle = 1) : verts(_verts), vertsIndex(_vertsIndex), numTris(_numTris), e(_e), c(_c), refl(_refl), isTriangle(_isTriangle) &#123; vertices = new Vec[3 * numTris]; for (int i = 0; i &lt; numTris; i++) &#123; for (int n = 0; n &lt; 3; n++) &#123; vertices[3 * i + n] = verts[vertsIndex[3 * i + n]]; &#125; &#125; &#125; void move(int x, int y, int z) &#123; // 方便调试 for (int i = 0; i &lt; 3 * numTris; i++) &#123; vertices[i] = vertices[i] + Vec(x, y, z); &#125; &#125; double intersect(const Ray&amp; r, Vec&amp; n) const &#123; // n返回法线 double tnear = 1e20; double tnear_out; //std::cout &lt;&lt; numTris &lt;&lt; std::endl; // Vec temp_normal; double temp = 1e20; bool flag = false; for (int i = 0; i &lt; numTris; i++) &#123; Vec&amp; v0 = vertices[3 * i]; Vec&amp; v1 = vertices[3 * i + 1]; Vec&amp; v2 = vertices[3 * i + 2]; /*std::cout &lt;&lt; &quot;x:&quot; &lt;&lt; v0.x &lt;&lt; &quot;y:&quot; &lt;&lt; v0.y &lt;&lt; &quot;, z:&quot; &lt;&lt; v0.z &lt;&lt; std::endl; std::cout &lt;&lt; &quot;x:&quot; &lt;&lt; v1.x &lt;&lt; &quot;y:&quot; &lt;&lt; v1.y &lt;&lt; &quot;, z:&quot; &lt;&lt; v1.z &lt;&lt; std::endl; std::cout &lt;&lt; &quot;x:&quot; &lt;&lt; v2.x &lt;&lt; &quot;y:&quot; &lt;&lt; v2.y &lt;&lt; &quot;, z:&quot; &lt;&lt; v2.z &lt;&lt; std::endl;*/ Vec E1 = v1 - v0; Vec E2 = v2 - v0; n = E1.cross(E2).norm(); //三角形法线 Vec S = r.o - v0; Vec S1 = (r.d).cross(E2); Vec S2 = S.cross(E1); //tnear为时间 沿着三角形方向 t的为正 //u,v 为重心坐标前的参数 都得为非负的还得小于1 double S1E1 = S1.dot(E1); tnear = 1.0f / S1E1 * S2.dot(E2); double u = 1.0f / S1E1 * S1.dot(S); double v = 1.0f / S1E1 * S2.dot(r.d); double k = 1 - u - v; bool judge; if (isTriangle) &#123; judge = tnear &gt; 0 &amp;&amp; v &gt;= 0 &amp;&amp; v &lt;= 1 &amp;&amp; u &gt;= 0 &amp;&amp; u &lt;= 1 &amp;&amp; k &gt;= 0; &#125; else &#123; judge = tnear &gt; 0 &amp;&amp; v &gt;= 0 &amp;&amp; v &lt;= 1 &amp;&amp; u &gt;= 0 &amp;&amp; u &lt;= 1; &#125; if (judge) &#123; //不加k &gt;= 0 可构建平行四边形 if (!flag) &#123; tnear_out = tnear; temp_normal = n; flag = true; &#125; if (tnear &lt; tnear_out) &#123; tnear_out = tnear; temp_normal = n; &#125; &#125; &#125; if (flag) &#123; n = temp_normal; //std::cout &lt;&lt; tnear_out &lt;&lt; std::endl; return (tnear_out &lt; 1e20 &amp;&amp; tnear_out &gt; 0) ? tnear_out : 0; &#125; else &#123; return 0; &#125; &#125; ~MeshTriangle() &#123; delete[] vertices; &#125;&#125;;struct Sphere &#123; double rad; // radius Vec p, e, c; // position, emission, color Refl_t refl; Sphere(double _rad, Vec _p, Vec _e, Vec _c, Refl_t _refl) : rad(_rad), p(_p), e(_e), c(_c), refl(_refl) &#123;&#125; double intersect(const Ray&amp; r) const &#123; Vec op = p - r.o; double t, eps = 1e-4; double b_12 = op.dot(r.d); // -b / 2 double det_14 = b_12 * b_12 - op.dot(op) + rad * rad; // det / 4 double det_14_sqrt = sqrt(det_14); return (t = b_12 - det_14_sqrt) &gt; eps ? t : ((t = b_12 + det_14_sqrt) &gt; eps ? t : 0); //if (det_14 &lt; 0) &#123; // return 0; //&#125; //else &#123; // t = b_12 - det_14_sqrt; // if (t &gt; eps) return t; //考虑到浮点数的缺陷 // t = b_12 + det_14_sqrt; // if (t &gt; eps) return t; // return 0; //交点为反向延长线，不考虑 //&#125; &#125;&#125;;Sphere spheres[] = &#123;//Scene: radius, position, emission, color, material Sphere(1e5, Vec(1e5 + 1,40.8,81.6), Vec(),Vec(.75,.25,.25),DIFF),//Left Sphere(1e5, Vec(-1e5 + 99,40.8,81.6),Vec(),Vec(.25,.25,.75),DIFF),//Rght Sphere(1e5, Vec(50,40.8, 1e5), Vec(),Vec(.75,.75,.75),DIFF),//Back Sphere(1e5, Vec(50,40.8,-1e5 + 170), Vec(),Vec(.25,.25,.25), DIFF),//Frnt Sphere(1e5, Vec(50, 1e5, 81.6), Vec(),Vec(.75,.75,.75),DIFF),//Botm Sphere(1e5, Vec(50,-1e5 + 81.6,81.6),Vec(),Vec(.75,.75,.75),DIFF),//Top Sphere(12,Vec(27,12.5,47), Vec(),Vec(1,1,1) * .999, SPEC),//Mirr Sphere(16.5,Vec(73,16.5,78), Vec(),Vec(1,1,1) * .999, REFR),//Glas Sphere(1.5, Vec(50,81.6 - 16.5,81.6),Vec(4,4,4) * 100, Vec(), DIFF) //Lite&#125;;Vec verts[8] = &#123; //vertices Vec(26, 0, 95), Vec(41, 0, 90), Vec(31, 0, 110), Vec(46, 0, 105), Vec(26, 40, 95), Vec(41, 40, 90), Vec(31, 40, 110), Vec(46, 40, 105),&#125;;int vertsIndex[18] = &#123; 0, 4, 1, // 顺序影响法线方向 1, 5, 3, 3, 7, 2, 2, 6, 0, 6, 7, 4, 2, 0, 3,&#125;;//int vertsIndex[36] = &#123; 0, 4, 1, // 顺序影响法线方向// 1, 4, 5,// 1, 5, 7,// 1, 7, 3,// 3, 7, 6,// 3, 6, 2,// 2, 6, 0,// 0, 6, 4,// 6, 7, 4,// 7, 5, 4,// 2, 0, 3,// 3, 0, 1,// &#125;;MeshTriangle meshTriangles[] = &#123; MeshTriangle(verts, vertsIndex, 6, Vec(), Vec(.25, .75, .25), DIFF, 0),&#125;; //vertices, vertsIndex, numTris, emission, color, materialint numSphere = sizeof(spheres) / sizeof(Sphere);int numMeshTriangle = sizeof(meshTriangles) / sizeof(MeshTriangle);inline double clamp01(double x) &#123; //截断到01 return x &lt; 0 ? 0 : (x &gt; 1 ? 1 : x);&#125;inline double gamma(double x, float n = 2.2) &#123; return pow(clamp01(x), 1 / n);&#125;inline int toInt255(double x) &#123; //gamma取2.2, 四舍五入 return int(gamma(x) * 255 + .5);&#125;inline void UpdateProgress(float progress) //进度提醒&#123; int barWidth = 70; std::cout &lt;&lt; &quot;[&quot;; int pos = barWidth * progress; for (int i = 0; i &lt; barWidth; ++i) &#123; if (i &lt; pos) std::cout &lt;&lt; &quot;=&quot;; else if (i == pos) std::cout &lt;&lt; &quot;&gt;&quot;; else std::cout &lt;&lt; &quot; &quot;; &#125; //三位小数 std::cout &lt;&lt; &quot;] &quot; &lt;&lt; std::setiosflags(std::ios::fixed) &lt;&lt; std::setiosflags(std::ios::right) &lt;&lt; std::setprecision(3) &lt;&lt; float(progress * 100.0) &lt;&lt; &quot; %\\r&quot;; std::cout.flush();&#125;inline bool intersect(const Ray&amp; r, double&amp; t, int&amp; id, Vec&amp; normal) &#123; //t最短的相交, n 返回法线 double n = sizeof(spheres) / sizeof(Sphere) + numMeshTriangle; double d; double inf = t = 1e20; for (int i = 0; i &lt; n; i++) &#123; //std::cout &lt;&lt; i &lt;&lt; std::endl; // if (i &lt; numSphere) &#123; if ((d = spheres[i].intersect(r)) &amp;&amp; d &lt; t) &#123; // 注意：不自交（真坑啊。。。） t = d; id = i; &#125; &#125; else &#123; d = meshTriangles[i - numSphere].intersect(r, normal); if (d &amp;&amp; d &lt; t) &#123; //std::cout &lt;&lt; d &lt;&lt; std::endl; t = d; id = i; &#125; &#125; &#125; return t &lt; inf;&#125;//Xi:随机种子 E：whether to include emissive colorVec radiance(const Ray&amp; r, int depth, unsigned short* Xi, int E = 1) &#123; double t; //与交点距离 int id = 0; Vec temp_n; if (!intersect(r, t, id, temp_n)) &#123; //id &gt;= numSphere说明是三角面片 return Vec(); //miss &#125; //std::cout &lt;&lt; id &lt;&lt; std::endl; // Vec x = r.o + r.d * t;// Ray hit point Vec n; //normal(射线经过obj内部后,n为负数) Vec f; Refl_t obj_refl; Vec obj_e; if (id &lt; numSphere) &#123; const Sphere&amp; obj = spheres[id]; n = (x - obj.p).norm(); f = obj.c; obj_refl = obj.refl; obj_e = obj.e; &#125; else &#123; //std::cout &lt;&lt; id &lt;&lt; std::endl; //if (x.x == 36) std::cout &lt;&lt; &quot;x:&quot; &lt;&lt; x.x &lt;&lt; &quot;y:&quot; &lt;&lt; x.y &lt;&lt; &quot;, z:&quot; &lt;&lt; x.z &lt;&lt; std::endl; const MeshTriangle&amp; obj = meshTriangles[id - numSphere]; n = temp_n.norm(); f = obj.c; obj_refl = obj.refl; obj_e = obj.e; &#125; if (depth &gt; DEPTH_MAX) &#123; return Vec(); &#125; //Vec n = (x - obj.p).norm(); // sphere normal(射线经过obj内部后,n为负数) Vec n_real = n.dot(r.d) &lt; 0 ? n : n * -1; //sphere normal //std::cout &lt;&lt; &quot;x:&quot; &lt;&lt; f.x &lt;&lt; &quot;y:&quot; &lt;&lt; f.y &lt;&lt; &quot;, z:&quot; &lt;&lt; f.z &lt;&lt; std::endl; // //用rgb最大值作为Russian Roulette不终止的概率p //RR适用因为p * Li * (1/p) + 0 * (1-p) = Li，即数学期望等于Li double p = f.x &gt; f.y &amp;&amp; f.x &gt; f.z ? f.x : f.y &gt; f.z ? f.y : f.z; if (++depth &gt; int(DEPTH_MAX / 2) || !p) if (erand48(Xi) &lt; p) f = f * (1.0 / p); else return obj_e * E; //std::cout &lt;&lt; &quot;miss&quot; &lt;&lt; std::endl; if (obj_refl == DIFF) &#123; //std::cout &lt;&lt; &quot;DIFF&quot; &lt;&lt; std::endl; // //采用Lambert，出射方向任意，以极坐标的方式构建随机弹射光线方向 double r1 = 2 * M_PI * erand48(Xi); double r2 = erand48(Xi); double r2_sqrt = sqrt(r2); //标准正交系 Vec w = n_real; Vec u = ((fabs(w.x) &gt; 0.1 ? Vec(0, 1) : Vec(1)).cross(w)).norm(); Vec v = w.cross(u); Vec d = (u * cos(r1) * r2_sqrt + v * sin(r1) * r2_sqrt + w * sqrt(1 - r2)).norm(); //Ray direction, 即path tracing， N=1的那条射线 Vec e; for (int i = 0; i &lt; numSphere; i++) &#123; const Sphere&amp; s = spheres[i]; if ((s.e.x &lt;= 0 &amp;&amp; s.e.y &lt;= 0 &amp;&amp; s.e.z &lt;= 0) || i &gt;= numSphere) continue; //skip no radiance Vec sw = s.p - x, su = ((fabs(sw.x) &gt; 0.1 ? Vec(0, 1) : Vec(1)).cross(sw)).norm(), sv = sw.cross(su); //x发出射向id=i的范围内随机方向的采样射线 double cos_a_max = sqrt(1 - s.rad * s.rad / (x - s.p).dot(x - s.p)); double eps1 = erand48(Xi), eps2 = erand48(Xi); //double cos_a = 1 - eps1*(1. - cos_a_max); double cos_a = 1 - eps1 + eps1 * cos_a_max; double sin_a = sqrt(1 - cos_a * cos_a); double phi = 2 * M_PI * eps2; Vec l = su * cos(phi) * sin_a + sv * sin(phi) * sin_a + sw * cos_a; l.norm(); // Note: // 根据Monte Carlo Integration得到相应形式的渲染方程(反射率方程) // Lo(p,wo) = (1/N)*∑(i~n) &#123;(Li(p,wi)*fr(p,wi,wo)*(n*wi)) / pdf&#125; // Lo:入射radiance, p:单位半球球心, wo:入射方向（微小立体角） // N:取样数（光线数）, Li wi略 // fr:BRDF, n:法线方向 // pdf: 分布函数 // 由于采用的是path tracing N取1, Lo(p,wo) = (Li(p,wi)*fr(p,wi,wo)*(n*wi)) / pdf // 当采用Lambert漫反射的BRDF可推导出为1/pi // 对半球均匀采样时，pdf=1/单位半圆面积，但射线的方向是在于法线的夹角最大是a_max, 采样的区域被限定 // 球形对角度A(法线方向与某一点的夹角)积分， 得S = ſ 2 * pi * r*r sinA dA = abs(2 * pi * r * r * cosA), r=1 // 易得pdf = 1 / 球部分表面积 = 1 / (2 * pi * r * r(1-cos_a_max)) = 1 / (2 * pi * (1-cos_a_max)) // Lo(p,wo) = (Li(p,wi)*fr(p,wi,wo)*(n*wi)) / pdf = Li(p,wi) * (1 / pi) * cos_a * (2 * pi * (1 - cos_a_max)) Vec temp1; if (intersect(Ray(x, l), t, id, temp1) &amp;&amp; id == i) &#123; double omega = 2 * M_PI * (1 - cos_a_max); e = e + f.mult(s.e * l.dot(n_real) * omega) * (1 / M_PI); //std::cout &lt;&lt; e.x &lt;&lt; std::endl; &#125; &#125; //std::cout &lt;&lt; f.x &lt;&lt; std::endl; return obj_e * E + e + f.mult(radiance(Ray(x, d), depth, Xi, 0)); //TEST:E暂时设置为0 &#125; else if (obj_refl == SPEC) &#123; //std::cout &lt;&lt; &quot;SPEC&quot; &lt;&lt; std::endl; // return obj_e + f.mult(radiance(Ray(x, r.d - n * 2 * n.dot(r.d)), depth, Xi)); &#125; else if (obj_refl == REFR) &#123; //std::cout &lt;&lt; &quot;REFR&quot; &lt;&lt; std::endl; Ray reflRay(x, r.d - n * 2 * n.dot(r.d)); bool into = n.dot(n_real) &gt; 0; double nc = 1;//真空 double nt = 1.5;//玻璃 double nnt = into ? nc / nt : nt / nc; double ddn = r.d.dot(n_real); double cos2_t = 1 - nnt * nnt * (1 - ddn * ddn); //2是平方 if (cos2_t &lt; 0) &#123; //没有折射，发生全反射 return obj_e + f.mult(radiance(reflRay, depth, Xi)); &#125; Vec tdir = (r.d * nnt - n * ((into ? 1 : -1) * (ddn * nnt + sqrt(cos2_t)))).norm(); //考虑到计算量，采用近似算法 double a = nt - nc, b = nt + nc, R0 = a * a / (b * b), c = 1 - (into ? -ddn : tdir.dot(n)); double Re = R0 + (1 - R0) * c * c * c * c * c, Tr = 1 - Re, P = 0.25 + 0.5 * Re, RP = Re / P, TP = Tr / (1 - P); if (depth &gt; 2) &#123; if (erand48(Xi) &lt; P) &#123; // RR return obj_e + f.mult(radiance(reflRay, depth, Xi) * RP); &#125; else &#123; return obj_e + f.mult(radiance(Ray(x, tdir), depth, Xi) * TP); &#125; &#125; else &#123; return obj_e + f.mult(radiance(reflRay, depth, Xi) * Re + radiance(Ray(x, tdir), depth, Xi) * Tr); &#125; &#125;&#125;Vec* c = new Vec[WIDTH * HIGHT]; //图像缓存void Initial(void)&#123; glClearColor(1.0f, 1.0f, 1.0f, 1.0f); glMatrixMode(GL_PROJECTION); int width = glutGet(GLUT_WINDOW_WIDTH); int height = glutGet(GLUT_WINDOW_HEIGHT); gluOrtho2D(0.0, width, 0.0, height);&#125;void myDisplay(void) &#123; glClear(GL_COLOR_BUFFER_BIT); glPointSize(1); for (int y = 0; y &lt; HIGHT; y++) &#123; for (int x = 0; x &lt; WIDTH; x++) &#123; int n = (HIGHT - y - 1) * WIDTH + x; glColor3f(gamma(c[n].x), gamma(c[n].y), gamma(c[n].z)); glBegin(GL_POINTS); glVertex2f(x, y); glEnd(); &#125; &#125; glFlush();&#125; int main(int argc, char* argv[]) &#123; int w = WIDTH, h = HIGHT; int samples = 1; //设置每subpixel采样数 //设置 camera Ray cam(Vec(50, 52, 295.6), Vec(0, -0.042612, -1).norm()); Vec cx = Vec(w * 0.5135 / h); //视场角 Vec cy = (cx.cross(cam.d)).norm() * 0.5135; Vec r; //摄影机射线 auto clock_start = clock();#pragma omp parallel for schedule(dynamic, 1) private(i) meshTriangles[0].move(15, 0, 0); for (int y = 0; y &lt; h; y++) &#123; UpdateProgress((float)y / HIGHT); unsigned short Xi[3] = &#123; 0, 0, y * y * y &#125;; //设置四个子像素 for (unsigned short x = 0; x &lt; w; x++) &#123; for (int sy = 0, i = (h - y - 1) * w + x; sy &lt; 2; sy++) &#123; for (int sx = 0; sx &lt; 2; sx++, r = Vec()) &#123; for (int s = 0; s &lt; samples; s++) &#123; double r1 = 2 * erand48(Xi); double dx = r1 &lt; 1 ? sqrt(r1) - 1 : 1 - sqrt(2 - r1); double r2 = 2 * erand48(Xi); //std::cout &lt;&lt; r1 &lt;&lt; &quot; &quot; &lt;&lt; r2 &lt;&lt; std::endl; double dy = r2 &lt; 1 ? sqrt(r2) - 1 : 1 - sqrt(2 - r2); Vec sample_direct = cx * (((dx + 0.5 + sx) / 2 + x) / w - 0.5) + cy * (((dy + 0.5 + sy) / 2 + y) / h - 0.5) + cam.d; //std::cout &lt;&lt; r.x &lt;&lt; std::endl; r = r + radiance(Ray(cam.o + sample_direct * 140, sample_direct.norm()), 0, Xi) * (1.0 / samples); //std::cout &lt;&lt; &quot;x:&quot; &lt;&lt; r.x &lt;&lt; &quot;y:&quot; &lt;&lt; r.y &lt;&lt; &quot;, z:&quot; &lt;&lt;r.z &lt;&lt; std::endl; // &#125; //std::cout &lt;&lt; c[i].x &lt;&lt; std::endl; // c[i] = c[i] + Vec(clamp01(r.x), clamp01(r.y), clamp01(r.z)) * 0.25; &#125; &#125; &#125; &#125; FILE* f = fopen(&quot;test.ppm&quot;, &quot;wb&quot;); fprintf(f, &quot;P3\\n%d %d\\n%d\\n&quot;, w, h, 255); for (int i = 0; i &lt; w * h; i++) &#123; fprintf(f, &quot;%d %d %d &quot;, toInt255(c[i].x), toInt255(c[i].y), toInt255(c[i].z)); &#125; fclose(f); glutInit(&amp;argc, argv); glutInitDisplayMode(GLUT_RGB | GLUT_SINGLE); glutInitWindowPosition(100, 100); glutInitWindowSize(w, h); glutCreateWindow(&quot;Path Tracing&quot;); Initial(); glutDisplayFunc(&amp;myDisplay); glutMainLoop(); return 0;&#125;","categories":[{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/categories/Games101/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/tags/Games101/"},{"name":"Ray-Tracing","slug":"Ray-Tracing","permalink":"https://whitetail-o.github.io/tags/Ray-Tracing/"}]},{"title":"Games101_10_12 Geometry","slug":"Games101_10_12_Geometry","date":"2022-10-02T08:35:10.000Z","updated":"2023-02-04T06:31:24.720Z","comments":true,"path":"2022/10/02/Games101_10_12_Geometry/","link":"","permalink":"https://whitetail-o.github.io/2022/10/02/Games101_10_12_Geometry/","excerpt":"Lecture 10/11: Geometry 1 2 不可能所有物体都用三角面表示，一些复杂的物体如毛发、水滴等用三角面表示开销极大； a). 几何的表示形式 隐式（Implicit） algebraic surface level sets distance functions … 显式（Explicit） point cloud polygon mesh subdivision, NURBS …","text":"Lecture 10/11: Geometry 1 2 不可能所有物体都用三角面表示，一些复杂的物体如毛发、水滴等用三角面表示开销极大； a). 几何的表示形式 隐式（Implicit） algebraic surface level sets distance functions … 显式（Explicit） point cloud polygon mesh subdivision, NURBS … b). 几何的隐式表示（Implict Representations of Geometry） 基于归类的点 点满足某种特定的关系，但不给你特定的点 e.g. Sphere: 所有三维中的点，满足 $x^2+y^2+z^2=1$； 通用情况：$f(x,y,z)=0$ 缺点： 难以采样（Sampling Can Be Hard，难以得到式子表示的整体形状） 优点： 方便判断点是否在几何体内（Inside/Outside Tests Easy） b.1). Algebraic Surfaces（曲面代数） 难以表达复杂的形状； b.2). Constructive Solid Geometry（CSG, 体素构造表示形式） 对隐式几何体进行布尔运算； b.3). Distance Function（距离函数） 给出各个点到物体的最小距离 Blending Distance Function: 目的：通过混合得到A、B运动的中间状态； 上半部分，blend之后中间1/3是灰的，而理想的结果是左边1/2是黑色，右边1/2是白色 下半部分，对SDF进行混合，再将blend后的结果恢复成shape（找到SDF等于0的情况的所有点），就可得到中间状态的物体； See https://iquilezles.org/www/articles/raymarchingdf/raymarchingdf.htm b.4). Level Set Methods（水平集） 封闭方程（DF）很难描述复杂的形状 备选方案：存储近似函数值的网格（Level Set Methods） 通过找到插值为0的位置确定表面； 提供对形状更明确的控制（如纹理）? 应用： Level Sets from Medical Data (CT, MRI, etc. 三维LSM) 物理模拟：如水平集得到各点到液体边界的距离（距离函数混合水滴） See http://physbam.stanford.edu b.5). Fractals(分形) c). 几何的显式表示（“Explicit” Representations of Geometry） 简介： 直接给出所有的点 或者 通过参数映射（via parameter mapping） 参数映射：给出uv，以及uv到三维空间的映射关系，遍历所有的uv就可找到三维空间所有的点； 采样简单 不方便判断点是否在几何体内（Inside/Outside Tests Hard） 隐式、显式各有优缺点，需要根据需求选择最优的表达方式 c.1). Point Cloud c.2). Polygon Mesh 常用的PolygonMesh文件，Wavefront Object File (.obj) v：顶点位置；vt：纹理位置；vn：normal；f：face，顶点索引/纹理索引/法线索引 c.3). Bézier Curve（贝塞尔曲线） 通过点$p_0$ 、$p_1$，且在这两点切线为$t0$、$t1$（切线前带系数，对于三次贝塞尔曲线系数为3） c.3.1). 计算贝塞尔曲线(德卡斯特里奥算法, De Casteljau’s Algorithm) 二次贝塞尔曲线 三次贝塞尔曲线（Cubic Bezier Curve） Anim： c.3.2). 代数形式 推出Bernstein polynomial（伯恩斯坦多项式）： B_{i}^{n}(t)=C_n^i · t^{i}(1-t)^{n-i} C.3.3). 性质 即（对于三次贝塞尔曲线）： $b_0$ 是起点，$b_3$是终点； 切线为$\\mathbf{b}^{\\prime}(0)=3\\left(\\mathbf{b}_{1}-\\mathbf{b}_{0}\\right) ; \\quad \\mathbf{b}^{\\prime}(1)=3\\left(\\mathbf{b}_{3}-\\mathbf{b}_{2}\\right)$ （切线前带系数，对于三次贝塞尔曲线系数为3，通过求导可得） 仿射不变性（对于贝塞尔曲线做仿射变换，只需要对控制点进行变换） 凸包性质； c.3.4). Piecewise Bézier Curves（分段贝塞尔曲线） 使用原因：解决高阶贝塞尔曲线控制点过多的问题； 分段贝塞尔曲线，常是分段立方贝塞尔（Piecewise cubic Bézier），即每一个曲线存在4个控制点； c.3.4.1). 连续性 C0 连续（C表示Continuity），几何连续：$a_n=b_0$ ； 首尾相接，夹角任意； C1 连续，参数连续：$a_n=b_0={1\\over2}(a_{n-1} + b_1)$ ； 切线相等，即一阶导数连续； 3.5). Other types of splines(待深入) In this course We do not cover B-splines and NURBS We also do not cover operations on curves (e.g. increasing/decreasing orders, etc.) To learn more / deeper, you are welcome to refer to Prof. Shi-Min Hu’s course: https://www.bilibili.com/video/av66548502?from=search&amp;seid=65256805876131485 3.6). Bezier Surface Animation: Steven Wittens, Making Things with Maths, http://acko.net 3.6.1). Evaluating Bézier Surfaces Lecture 13 Geometrya). Subdivision 以下是几种常用的细分方法: a.1). Loop Subdivision(Loop是人名) 细分对象：三角面 首先，创造更多的三角面； 第二，改变他们的位置； 具体做法： 将每个三角形细分为四个； 根据权重分配新的顶点位置； 区分新/老顶点，做不同变换； 对于新顶点： $P_{new} = {3\\over8}(A+B)+{1\\over8}(C+D)$ 对于老顶点： $n:$ 顶点的度（图论，与该顶点关联的边的数目，该处即为与该顶点连接的边的数量） $u:$ $3/16$（如果$n=3$），$3/(8n)$ （其他情况） $P_{new} = (1-nu)original_position + u·neighbor_position_sum$ Loop Subdivision Results： 缺点：Loop只能处理三角面； a.2). Catmull-Clark Subdivision 概念： 奇异点（Extraorinary vertex）：度不为4的点； 具体过程： 第一次细分： 每条边取中点，每个面也取其中一点； 第一次细分后，引入（n个，n=非四边形数目）奇异点，非四边形面消失。之后，奇异点不在增加，因此，之后细分只针对四边面； Catmull-Clark Vertex Update Rules (Quad Mesh) Face point: $$f=","categories":[{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/categories/Games101/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/tags/Games101/"}]},{"title":"Games101-7-9 Shading","slug":"Games101_07_09_Shading","date":"2022-10-02T08:25:10.000Z","updated":"2023-02-04T06:31:20.673Z","comments":true,"path":"2022/10/02/Games101_07_09_Shading/","link":"","permalink":"https://whitetail-o.github.io/2022/10/02/Games101_07_09_Shading/","excerpt":"Lecture 07/08 Shading(Illumination, Shading and Graphics Pipeline)a). Definition b). A Simple Shading Model(Blinn-Phong Reflectance Model)b.1). Fundamental Blinn-Phong是一个经验模型，并不是严格基于物理的； 进入视线内的光照一般有以下构成： 高光（Specualr） 漫反射（Diffuse） 环境光（Ambient） 自发光（Emissive） Shading is Local: Compute light reflected toward camera at a specific shading point No shadows will be generated! (shading ≠ shadow) 阴影会由另外的Shadow Caster来着色； b.2). Diffuse Reflection Blinn-Phong中，漫反射的光均匀散射到各个方向； Lambert’s cosine law：接收到的能量与 $l·n$ 成正比例 Light Falloff 漫反射最终的着色： b.3). Specular Term(Blinn-Phong) Intensity depends on view direction 采用半程向量简化计算。采用半程向量$h$与$n$点乘的是Blinn-Phong模型，而采用镜面反射方向$r$和视线方向$v$点乘的是Phong模型； 指数$p$的作用：Increasing p narrows the reflection lobe 效果总览： b.4). Ambient Term","text":"Lecture 07/08 Shading(Illumination, Shading and Graphics Pipeline)a). Definition b). A Simple Shading Model(Blinn-Phong Reflectance Model)b.1). Fundamental Blinn-Phong是一个经验模型，并不是严格基于物理的； 进入视线内的光照一般有以下构成： 高光（Specualr） 漫反射（Diffuse） 环境光（Ambient） 自发光（Emissive） Shading is Local: Compute light reflected toward camera at a specific shading point No shadows will be generated! (shading ≠ shadow) 阴影会由另外的Shadow Caster来着色； b.2). Diffuse Reflection Blinn-Phong中，漫反射的光均匀散射到各个方向； Lambert’s cosine law：接收到的能量与 $l·n$ 成正比例 Light Falloff 漫反射最终的着色： b.3). Specular Term(Blinn-Phong) Intensity depends on view direction 采用半程向量简化计算。采用半程向量$h$与$n$点乘的是Blinn-Phong模型，而采用镜面反射方向$r$和视线方向$v$点乘的是Phong模型； 指数$p$的作用：Increasing p narrows the reflection lobe 效果总览： b.4). Ambient Term c). Shading Frequenciesc.1). Flat shadingc.2). Gouraud shading c.3). Phong shadingc.4). 对比 不一定Phong着色就比Flat优秀。在极高面数的一些情况下，Flat Shading性能开销比Phong Shading小，且呈现效果相差无几； c.5). 定义顶点/像素法线 顶点法线为相邻三角形的加权平均（权重与三角面的面积有关，当然也可简单平均，但效果较加权平均差）； 逐像素的法线通过对顶点法线进行重心插值（Barycentric interpolation）后归一化（normalize）得到； d). Graphics(Real-time Rendering) Pipeline 这段可看冯的入门精要作为简单的补充 MVP矩阵相关的发生在顶点阶段； 光栅化； Shading可在Vertex Processing阶段，也可在Fragment Processing阶段； Texture mapping Shader： 优秀Shader（到时候好好学习一下） Inigo Quilez, https://youtu.be/XuSnLbB1j6E Lecture 08/09 Shading(Texture Mapping) 可见 百人计划-图形1.3-纹理的秘密 作为补充； a). Interpolation Across Triangles: Barycentric Coordinates 重心插值的作用：通过顶点特定的值（normal、Color、Depth、Texture coordinates…），得到三角形内部片元（像素）上平滑过渡的值； 数学基础： 共面需满足的条件： $α+β+γ=1$，如需要点在三角形内，还需满足$α&gt;0,β&gt;0,γ&gt;0$ 重心坐标求法： 由以上易得，重心坐标$\\begin{aligned}(x, y) &amp;=\\frac{1}{3} A+\\frac{1}{3}B+\\frac{1}{3} C\\end{aligned}$ 通用计算公式： Final： 注意：重心并没有投影不变性，因此进行插值需要在三维空间中进行，而不是在屏幕的二维投影上； b). Texture Magnification(需要放大纹理的情况) 对应情况：纹理过小（如距离物体近，而贴图小） 插值方式： Nearest Bilinear Bicubic b.1). Bilinear Interpolation c). Texture Magnification(需要缩小纹理的情况) 对应情况：纹理过大（如距离物体远，而贴图大） 解决思路： 增大采样率（超采样） 高质量，但性能开销大； 减小贴图频率（Mipmap） c.1). Mipmap c.1). 如何确定Mipmap的level（参考百人计划）：c.2). Mipmap之间的过渡 Visualization of Mipmap Level(D rounded to nearest integer level)： Trilinear Interpolation 作法：对相邻两层的Mipmap做Bilinear Interpolation，根据所得的level，对相邻两层进过插值的结果再进行一次插值；（e.g. D=1.6，则对一层和二层分别进行双线性插值后，再进行$lerp(1.6-1, n_1, n_2)$） Final： d). Applications of Texturesd.1). Environment Map 简介： 对于环境光源，我们认为它来自与无限远处，即没有深度意义，不同位置的同一方向受到的环境光源相同（当然，暂不考虑遮挡） Spherical Environment Map： Problem：不是均匀的描述，在极点会存在较大的扭曲； CubeMap： d.2). Bump Mapping 凹凸贴图（视差贴图/法线贴图）计算法线过程： 思路（一维情况，in flatland）： 原始法线 $n(p)=(0,1)$ 在 p 点的导数 $dp=c·[h(p+1)-h(p)]$ （$c$ 是常数，用于缩放导数，改变其影响程度），得出切线 计算法线（垂直于切线） $n(p)=(-dp,1).normalized()$； 思路（in 3D）： 原始法线 $n(p)=(0,0,1)$； 纹理上的点对 $u$ 方向和 $v$ 方向求偏导，得出切线 $dp/du=c1·[h(u+1)-h(u)]$ $dp/dv=c2·[h(v+1)-h(v)]$ 计算法线（垂直于切线） $n(p)=(-dp/du,-dp/dv,1).normalized()$； 以上计算均在切线空间、局部空间计算（具体看冯-入门精要） Displacement mapping（置换/高度贴图）: 需要足够多的三角面（DX中的Dynamic Tessellation，动态曲面细分） 真正地移动了顶点 d.3). 3D Procedural Noise + Solid Modeling Perlin noise d.4). Provide Precomputed Shading 使用Baking的AO等（也可记录其他信息，如SP中的ID、Position、Curvature等）； d.5). 3D Textures and Volume Rendering 体渲染","categories":[{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/categories/Games101/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/tags/Games101/"}]},{"title":"Games101-5-6 Rasterization","slug":"Games101_05_06_Rasterization","date":"2022-10-02T08:20:10.000Z","updated":"2023-02-04T06:31:12.704Z","comments":true,"path":"2022/10/02/Games101_05_06_Rasterization/","link":"","permalink":"https://whitetail-o.github.io/2022/10/02/Games101_05_06_Rasterization/","excerpt":"Lecture 05 Rasterization(Triangles)a). Perspective Projection 如何定义一个frustum： 近平面宽度、高度（得到宽高比） FOV(Field of View) b). Viewport transformation 经过MVP后，模型空间中点变换到标准立方体（canonical cube, x,y,z[-1, 1]）中。之后就需要进行视口变换（Viewport transformation） 定义屏幕空间 OpenGL屏幕空间坐标原点为左下（上图），DX坐标原点为左上 像素位置该像素（方块）左下角的坐标，如左下角像素坐标为$(0, 0)$，但像素中心为$(0.5, 0.5)$ Viewport transformation c). Rasterization Frame Buffer: Memory for a Raster Display 显存中的一块区域 补充：Render texture（详情见Other/Note） 以下以Unity为例： 渲染过程中，贴图最开始在CPU内存，这时的贴图被称为client-side的texture，最后被送到GPU，这时叫server-side的texture； Render texture是将FrameBufferObject连接到一个server-side的texture； 注意：FrameBufferObject不一定只有一个，也不一定连接屏幕； 详情：http://t.csdn.cn/3JHqA Triangles - Fundamental Shape Primitives 无法分割为其他多边形 保证是一个平面 容易区分内部和外部 内部插值方便 Fundament： What Pixel Values Approximate a Triangle? Sampling（采样）：逐像素中心采样，判断像素是否在三角形内 for (int x = 0; x &lt; xmax; ++x) output[x] = f(x); 判断$(x,y)$是否在三角形内：做三次叉乘，看正负符号是否相同，相同则在三角形内； Edge Cases：要么不做处理，要么特殊处理（OpenGL，DX里规定落于左边和上边算三角形中的点，而落于右边和下边的不算“Top-Left Rule“） 光栅化加速 光栅化中，对每一个像素都判断是否在三角形中性能浪费过大。因此，加入Bounding Box（包围盒）来限定需要进行判断的区域 Incremental Triangle Traversal（找到三角形中每一行最左和最右的像素，但实际上没那么容易，是用于细长并旋转的三角形）","text":"Lecture 05 Rasterization(Triangles)a). Perspective Projection 如何定义一个frustum： 近平面宽度、高度（得到宽高比） FOV(Field of View) b). Viewport transformation 经过MVP后，模型空间中点变换到标准立方体（canonical cube, x,y,z[-1, 1]）中。之后就需要进行视口变换（Viewport transformation） 定义屏幕空间 OpenGL屏幕空间坐标原点为左下（上图），DX坐标原点为左上 像素位置该像素（方块）左下角的坐标，如左下角像素坐标为$(0, 0)$，但像素中心为$(0.5, 0.5)$ Viewport transformation c). Rasterization Frame Buffer: Memory for a Raster Display 显存中的一块区域 补充：Render texture（详情见Other/Note） 以下以Unity为例： 渲染过程中，贴图最开始在CPU内存，这时的贴图被称为client-side的texture，最后被送到GPU，这时叫server-side的texture； Render texture是将FrameBufferObject连接到一个server-side的texture； 注意：FrameBufferObject不一定只有一个，也不一定连接屏幕； 详情：http://t.csdn.cn/3JHqA Triangles - Fundamental Shape Primitives 无法分割为其他多边形 保证是一个平面 容易区分内部和外部 内部插值方便 Fundament： What Pixel Values Approximate a Triangle? Sampling（采样）：逐像素中心采样，判断像素是否在三角形内 for (int x = 0; x &lt; xmax; ++x) output[x] = f(x); 判断$(x,y)$是否在三角形内：做三次叉乘，看正负符号是否相同，相同则在三角形内； Edge Cases：要么不做处理，要么特殊处理（OpenGL，DX里规定落于左边和上边算三角形中的点，而落于右边和下边的不算“Top-Left Rule“） 光栅化加速 光栅化中，对每一个像素都判断是否在三角形中性能浪费过大。因此，加入Bounding Box（包围盒）来限定需要进行判断的区域 Incremental Triangle Traversal（找到三角形中每一行最左和最右的像素，但实际上没那么容易，是用于细长并旋转的三角形） Lecture 6: Rasterization 2(Antialiasing and Z-Buffering)a). Sampling Artifacts(Errors / Mistakes / Inaccuracies) in Computer Graphics 由于采样造成的“Artifacts“ 锯齿（ Jaggies）——空间上采样 摩尔纹（Moire）——欠采样图像 车轮错觉（Wagon wheel effect）——时间上采样 …… 造成错误的原因：信号频率高，而采样频率低（可联系奈奎斯特定理：当采样频率大于信号中最高频率的2倍时(fs&gt;2f)，采样之后的数字信号完整地保留了原始信号中的信息） b). Antialiasing Idea:Blurring (Pre-Filtering) Before Sampling 抗锯齿的思路就是在采样前”模糊“； 注意：先模糊，后采样。对应频域上先低通滤波（或其他操作，如卷积、超采样，FSAA那种图像层面的抗锯齿暂不考虑），后采样（卷积定理：时域信号与冲激信号相乘，等于两者对应的频域信号卷积。反之，也成立）； c). Frequency Domainc.1). Fundamental 傅里叶变换 卷积定理：时域中乘积等于频域上卷积，反之也成立。（时域信号与冲激信号相乘，等于两者对应的频域信号卷积。反之，也成立。） Aliases: 在给定的采样率下，无法区分两个不同频率 c.2). Filtering: Getting rid of certain frequency contents K空间：反应图像进过二维傅里叶变换后的结果，越靠中间，频率越小； 出现十字星的原因：把图像看成类似Wrap Mode的Repeat，即重复的图像。使得其四个方向的高频内容增加，形成十字星； Filter（滤波器）： High-pass filter Low-pass filter Filter Out Low and High Frequencies c.3). Convolution Filtering = Convolution (= Averaging) 注意：只是在这里相等，而滤波和卷积概念上不相同； 对信号进行滤波，就是用卷积核和信号做卷积； Point-wise local averaging in a “sliding window” 卷积定理：在空域（时域）做卷积，等于在频域做乘积；反之亦然。 因此，对图像滤波有两种处理方法； Option 1: 在空域上与滤波器（卷积核）做卷积； Option 2: 将图像和滤波器（卷积核）转换到频域（傅里叶变换）； 两者在频域相乘； 将得到的结果重新变换到空域（逆傅里叶变换）； Box Filter 箱式滤波类似于低通滤波 更大的卷积核意味着更低的频率 c.4). Sampling = Repeating Frequency Contents 锯齿=混叠 d). Antialiasing 解决锯齿的选择： 提高采样率 增大冲激信号在频域的距离； 更高分辨率的显示器； 缺点：成本高，且需要很高的分辨率 抗锯齿 让信号在采样（重复，Repeat）前变“窄”，即在采样前过滤掉高频部分 Antialiasing = Limiting, then repeating Solution: Convolve f(x,y) by a 1-pixel box-blur Recall: convolving = filtering = averaging Then sample at every pixel’s center 通过计算像素平均值来抗锯齿 e). SSAA(Super Sampling Antialiasing) 通过将一个像素分割成NxN个像素来进行采样和shading，最后将每个像素点内部所细分的采样点的颜色值全部加起来再求均值，作为该像素点的抗锯齿之后的颜色值 f). MSAA(Multi-Sampling Antialiasing) MSAA是对SSAA的改进。SSAA的计算量大，一个像素中会有多个点进行shading，而MSAA只是计算究竟有几个采样点会被三角形cover，计算颜色的时候只会利用像素中心坐标进行一次shading。 如图中大点所在的像素块，三角形只覆盖了其中的三个点（左下，右上，右下），则该像素的颜色为$75\\%Color_{origin}$，之后，再对像素中心进行采样 注意：MSAA只是近似Blur，而没提高采样率。要注意和SSAA以及高分辨率的区分 在实际中，子像素的划分并不是均匀划分为NxN，而是通过其他更有效的方法，而且有些样本还会得到复用； SSAA中每个像素点有4个子采样点，每个三角形对每个像素点的4个子采样点各着色1次（共4次），再把计算结果根据深度和覆盖信息保存到对应的子采样点，最后对4个采样点取均值作为最终的像素颜色； MSAA中每个像素点有4个子采样点，每个三角形对每个像素点只在中心点着色1次，再把计算结果根据深度和覆盖信息保存到对应的子采样点，最后对4个采样点取均值作为最终的像素颜色； g). Other AA FXAA(Fast Approximate AA) 图像层面上进行处理，是一个后期处理，先得到有锯齿的图像，再通过图像匹配找到有锯齿的边界，之后，替换为没有锯齿的边界； TAA(Temporal AA) 可以联系UE_NOTE 将空域采样点，均匀分布到时域上； h). Z-bufferh.0). Painter’s Algorithm 画家算法： 对三角形进行排序，先画远的，再画近的； 不能解决相互遮挡问题，因此采用Z-buffer h.1). Z-buffer Idea： 储存每个采样（像素）中最小的深度值； 储存深度值到缓存区（buffer）中； 为了简单起见，我们看作z是正数(smaller z -&gt; closer, larger z -&gt; further)； 深度缓存步骤： 初始化深度缓存，将其中每个值初始化为∞ 遍历每个三角形面上的每一个像素点[x,y]，如果该像素点的深度值z，小于Z-buffer[x,y]中的值，则更新zbuffer[x,y]值为该点深度值z，并同时更新该像素点[x,y]的颜色为该三角形面上的该点的颜色。 伪代码： 时间复杂度$O(n)$。Z-buffer并没有进行排序，只是求得最小（深度）值，因此时间复杂度为线性； 三角形的绘制顺序并不影响最终结果（不考虑不透明等情况）；","categories":[{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/categories/Games101/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/tags/Games101/"}]},{"title":"Games101-2-4 Math","slug":"Games101_02_04_Math","date":"2022-10-02T08:15:10.000Z","updated":"2023-03-17T07:28:30.363Z","comments":true,"path":"2022/10/02/Games101_02_04_Math/","link":"","permalink":"https://whitetail-o.github.io/2022/10/02/Games101_02_04_Math/","excerpt":"Lecture 02 Review of Linear Algebraa). Cross Product 判断相对的左右、前后、内外 判断左右：如$ \\vec{a} \\cdot \\vec{b} &gt; 0$那 $\\vec{b}$ 就在 $\\vec{a}$ 的左侧（按图中的右手坐标系） 判断内外：判断 $\\vec{AB}$ 和 $\\vec{AP}$ 的关系，可判断$P$ 点的在 $\\vec{AB}$ 的左侧，同理可判断$P$ 在 $\\vec{BC}$ 和 $\\vec{CA}$ 的左侧，即均在向量同侧。由此，可判断$P$ 点的在 $ABC$ 的内部 b). Orthonormal Coordinate Frames(正交直角坐标系)","text":"Lecture 02 Review of Linear Algebraa). Cross Product 判断相对的左右、前后、内外 判断左右：如$ \\vec{a} \\cdot \\vec{b} &gt; 0$那 $\\vec{b}$ 就在 $\\vec{a}$ 的左侧（按图中的右手坐标系） 判断内外：判断 $\\vec{AB}$ 和 $\\vec{AP}$ 的关系，可判断$P$ 点的在 $\\vec{AB}$ 的左侧，同理可判断$P$ 在 $\\vec{BC}$ 和 $\\vec{CA}$ 的左侧，即均在向量同侧。由此，可判断$P$ 点的在 $ABC$ 的内部 b). Orthonormal Coordinate Frames(正交直角坐标系) Lecture 03 Transformationa). 2D Transformation Scale Matrix Reflection Matrix Shear Matrix(切变矩阵) Rotation matrix(默认原点(0, 0), CCW/逆时针旋转) b). Homogeneous coordinates(齐次坐标) To solve: 平移不是线性变换，无法用2*2矩阵表示（2D） 为什么点和向量的其次项不同？ 向量具有平移不变性，齐次项为0可使其不受$t_x$、$t_y$的影响 考虑向量与点、向量/点之间的运算 point + point得到两点的中点 所有的仿射变换（Affine Transformation）都可以用齐次坐标系表示 复杂变换，如 c). 3D Transformation 三维空间中使用齐次坐标的变换 \\left(\\begin{array}{l} x^{\\prime} \\\\ y^{\\prime} \\\\ z^{\\prime} \\\\ 1 \\end{array}\\right)=\\left(\\begin{array}{lllc} a & b & c & t_{x} \\\\ d & e & f & t_{y} \\\\ g & h & i & t_{z} \\\\ 0 & 0 & 0 & 1 \\end{array}\\right) \\cdot\\left(\\begin{array}{l} x \\\\ y \\\\ z \\\\ 1 \\end{array}\\right) \\left(\\begin{array}{l} x^{\\prime} \\\\ y^{\\prime} \\\\ z^{\\prime} \\\\ 1 \\end{array}\\right)=\\left(\\begin{array}{lllc} 1 & 0 & 0 & t_{x} \\\\ 0 & 1 & 0 & t_{y} \\\\ 0 & 0 & 1 & t_{z} \\\\ 0 & 0 & 0 & 1 \\end{array}\\right) \\cdot\\left(\\begin{array}{lllc} a & b & c & 0 \\\\ d & e & f & 0 \\\\ g & h & i & 0 \\\\ 0 & 0 & 0 & 1 \\end{array}\\right) \\cdot\\left(\\begin{array}{l} x \\\\ y \\\\ z \\\\ 1 \\end{array}\\right)上述矩阵先线性变换再平移，相当于： \\left(\\begin{array}{l}x^{\\prime} \\\\y^{\\prime} \\\\z^{\\prime} \\\\1\\end{array}\\right)=\\left(\\begin{array}{lllc}1 & 0 & 0 & t_{x} \\\\0 & 1 & 0 & t_{y} \\\\0 & 0 & 1 & t_{z} \\\\0 & 0 & 0 & 1\\end{array}\\right) \\cdot\\left(\\begin{array}{lllc}a & b & c & 0 \\\\d & e & f & 0 \\\\g & h & i & 0 \\\\0 & 0 & 0 & 1\\end{array}\\right) \\cdot\\left(\\begin{array}{l}x \\\\y \\\\z \\\\1\\end{array}\\right) 补充知识：正交矩阵 Lecture 04 Transformation Cont.a). 3D变换a.1) Scale、Translation a.2) 3D Rotations 旋转矩阵： 注意绕y轴旋转和其他的区别（$y=cross(z, x)$） 三轴旋转可以表示3D空间的所有旋转变换，例如飞机（Roll、Pitch、Yaw） 罗德里格旋转公式（表示绕任意经过原点轴的任意旋转） 默认旋转轴经过原点 $\\left(\\begin{array}{ccc}0 &amp; -n_{z} &amp; n_{y} \\\\n_{z} &amp; 0 &amp; -n_{x} \\\\-n_{y} &amp; n_{x} &amp; 0\\end{array}\\right)$是叉乘向量的矩阵形式 四元数多是为了旋转之间的插值用的 四元数待课后补充 b). Viewing Transformation 概念：Viewing Transformation（观测矩阵）相当于MVP中的VP View/Camera transformation Projection transformation Orthographic projection Perspective projection b.1) View Transformaiton Difine the camera: View Space: 相机位于原点，上是$Y$，看向$-Z$ 看成所有相机不动，全是其他物体动 $M_{view}$： in math: 直接应用矩阵空间变换 b.2) Projection transformation这里的投影变换中对xyzw都乘了z，因此最后需要齐次除法（透视除法），转换到NDC(Normalized Device Coordinates) b.2.1 Orthographic Projection 简易理解： 注意$[-1, 1]$ 图形学中的做法： 通过平移将立方体中心化 缩放成标准立方体（“canonical” cube） 这里采用右手坐标系，缺点是$f&lt;n$，远的z值小于近的z值 矩阵形式： M_{\\text {ortho }}=\\left[\\begin{array}{cccc} \\frac{2}{r-l} & 0 & 0 & 0 \\\\ 0 & \\frac{2}{t-b} & 0 & 0 \\\\ 0 & 0 & \\frac{2}{n-f} & 0 \\\\ 0 & 0 & 0 & 1 \\end{array}\\right]\\left[\\begin{array}{cccc} 1 & 0 & 0 & -\\frac{r+l}{2} \\\\ 0 & 1 & 0 & -\\frac{t+b}{2} \\\\ 0 & 0 & 1 & -\\frac{n+f}{2} \\\\ 0 & 0 & 0 & 1 \\end{array}\\right] Caveat: （使用右手坐标系）看向 $-Z$ 使得$f&lt;n$，远的z值小于近的z值 这也是为什么OpenGL使用左手坐标系（但也会造成其他问题） b.2.2 Perspective Projection 前置知识： How to do perspective projection 挤压（squish） $M_{\\text {persp } \\rightarrow \\text { ortho }}=\\left(\\begin{array}{cccc}n &amp; 0 &amp; 0 &amp; 0 \\\\0 &amp; n &amp; 0 &amp; 0 \\\\? &amp; ? &amp; ? &amp; ? \\\\0 &amp; 0 &amp; 1 &amp; 0\\end{array}\\right)$ 不知道经过挤压后$z$的变化（即第三行乘以$\\left(\\begin{array}{l}x \\\\y \\\\n \\\\1\\end{array}\\right)$未知），但知道： 在近平面的点不会变化 在远平面的中点不会变化 $z=n$时，$\\left(\\begin{array}{l}x \\\\y \\\\n \\\\1\\end{array}\\right) \\Rightarrow\\left(\\begin{array}{l}x \\\\y \\\\n \\\\1\\end{array}\\right)==\\left(\\begin{array}{c}n x^{n} \\\\n y \\\\n^{2} \\\\n\\end{array}\\right)$ 易得$\\left(\\begin{array}{llll}0 &amp; 0 &amp; A &amp; B\\end{array}\\right)\\left(\\begin{array}{l}x \\\\y \\\\n \\\\1\\end{array}\\right)=n^{2}$ $An+B=n^2$ $z=f$时，对于远平面中点，$\\left(\\begin{array}{l}0 \\\\0 \\\\f \\\\1\\end{array}\\right) \\Rightarrow\\left(\\begin{array}{l}0 \\\\0 \\\\f \\\\1\\end{array}\\right)==\\left(\\begin{array}{c}0 \\\\0 \\\\f^{2} \\\\f\\end{array}\\right)$ 易得$\\left(\\begin{array}{llll}0 &amp; 0 &amp; A &amp; B\\end{array}\\right)\\left(\\begin{array}{l}0 \\\\0 \\\\f \\\\1\\end{array}\\right)=f^{2}$ $Af+B=f^2$ 得$A=n+f$，$B=-nf$ $M_{\\text {persp } \\rightarrow \\text { ortho }}=\\left(\\begin{array}{cccc}n &amp; 0 &amp; 0 &amp; 0 \\\\0 &amp; n &amp; 0 &amp; 0 \\\\0 &amp; 0 &amp; n+f &amp; -nf \\\\0 &amp; 0 &amp; 1 &amp; 0\\end{array}\\right)$ 之后进行平行投影的变换，得 $\\mathbf{M}_{\\text {per }}=\\left[\\begin{array}{cccc}\\frac{2 n}{r-l} &amp; 0 &amp; \\frac{l+r}{l-r} &amp; 0 \\\\0 &amp; \\frac{2 n}{t-b} &amp; \\frac{b+t}{b-t} &amp; 0 \\\\0 &amp; 0 &amp; \\frac{f+n}{n-f} &amp; \\frac{2 f n}{f-n} \\\\0 &amp; 0 &amp; 1 &amp; 0\\end{array}\\right]$ 【补充】 作业1中用到的绕任意轴旋转： 步骤： 将旋转轴平移至原点 将旋转轴旋转至YOZ平面 将旋转轴旋转至于Z轴重合 绕Z轴旋转θ度 执行步骤3的逆过程 执行步骤2的逆过程 执行步骤1的逆过程 如果旋转轴是过原点的，那么第一步和最后一步的平移操作可以省略，也就是把中间五个矩阵连乘起来，再转置一下，得到下面的绕任意轴旋转的矩阵 \\left[\\begin{array}{cccc} a^{2}+\\left(1-a^{2}\\right) \\cos \\theta & a b(1-\\cos \\theta)+\\operatorname{csin} \\theta & a c(1-\\cos \\theta)-b \\sin \\theta & 0 \\\\ a b(1-\\cos \\theta)-c \\sin \\theta & b^{2}+\\left(1-b^{2}\\right) \\cos \\theta & b c(1-\\cos \\theta)+a \\sin \\theta & 0 \\\\ a c(1-\\cos \\theta)+b \\sin \\theta & b c(1-\\cos \\theta)-a \\sin \\theta & c^{2}+\\left(1-c^{2}\\right) \\cos \\theta & 0 \\\\ 0 & 0 & 0 & 1 \\end{array}\\right]","categories":[{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/categories/Games101/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/tags/Games101/"}]}],"categories":[{"name":"目录","slug":"目录","permalink":"https://whitetail-o.github.io/categories/%E7%9B%AE%E5%BD%95/"},{"name":"Unity","slug":"Unity","permalink":"https://whitetail-o.github.io/categories/Unity/"},{"name":"Demo","slug":"Demo","permalink":"https://whitetail-o.github.io/categories/Demo/"},{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/categories/Games202/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/categories/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"相机","slug":"相机","permalink":"https://whitetail-o.github.io/categories/%E7%9B%B8%E6%9C%BA/"},{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/categories/Games101/"}],"tags":[{"name":"图形 API","slug":"图形-API","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2-API/"},{"name":"Unity","slug":"Unity","permalink":"https://whitetail-o.github.io/tags/Unity/"},{"name":"转载","slug":"转载","permalink":"https://whitetail-o.github.io/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"Demo","slug":"Demo","permalink":"https://whitetail-o.github.io/tags/Demo/"},{"name":"图形学","slug":"图形学","permalink":"https://whitetail-o.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"Games202","slug":"Games202","permalink":"https://whitetail-o.github.io/tags/Games202/"},{"name":"Ray-Tracing","slug":"Ray-Tracing","permalink":"https://whitetail-o.github.io/tags/Ray-Tracing/"},{"name":"Denoise","slug":"Denoise","permalink":"https://whitetail-o.github.io/tags/Denoise/"},{"name":"Materials","slug":"Materials","permalink":"https://whitetail-o.github.io/tags/Materials/"},{"name":"PBR","slug":"PBR","permalink":"https://whitetail-o.github.io/tags/PBR/"},{"name":"百人计划","slug":"百人计划","permalink":"https://whitetail-o.github.io/tags/%E7%99%BE%E4%BA%BA%E8%AE%A1%E5%88%92/"},{"name":"效果","slug":"效果","permalink":"https://whitetail-o.github.io/tags/%E6%95%88%E6%9E%9C/"},{"name":"算法","slug":"算法","permalink":"https://whitetail-o.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"阴影","slug":"阴影","permalink":"https://whitetail-o.github.io/tags/%E9%98%B4%E5%BD%B1/"},{"name":"硬件","slug":"硬件","permalink":"https://whitetail-o.github.io/tags/%E7%A1%AC%E4%BB%B6/"},{"name":"移动端","slug":"移动端","permalink":"https://whitetail-o.github.io/tags/%E7%A7%BB%E5%8A%A8%E7%AB%AF/"},{"name":"架构","slug":"架构","permalink":"https://whitetail-o.github.io/tags/%E6%9E%B6%E6%9E%84/"},{"name":"优化","slug":"优化","permalink":"https://whitetail-o.github.io/tags/%E4%BC%98%E5%8C%96/"},{"name":"纹理","slug":"纹理","permalink":"https://whitetail-o.github.io/tags/%E7%BA%B9%E7%90%86/"},{"name":"延迟渲染","slug":"延迟渲染","permalink":"https://whitetail-o.github.io/tags/%E5%BB%B6%E8%BF%9F%E6%B8%B2%E6%9F%93/"},{"name":"渲染管线","slug":"渲染管线","permalink":"https://whitetail-o.github.io/tags/%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF/"},{"name":"模板测试","slug":"模板测试","permalink":"https://whitetail-o.github.io/tags/%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95/"},{"name":"深度测试","slug":"深度测试","permalink":"https://whitetail-o.github.io/tags/%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95/"},{"name":"曲面细分着色器","slug":"曲面细分着色器","permalink":"https://whitetail-o.github.io/tags/%E6%9B%B2%E9%9D%A2%E7%BB%86%E5%88%86%E7%9D%80%E8%89%B2%E5%99%A8/"},{"name":"几何着色器","slug":"几何着色器","permalink":"https://whitetail-o.github.io/tags/%E5%87%A0%E4%BD%95%E7%9D%80%E8%89%B2%E5%99%A8/"},{"name":"色彩管理","slug":"色彩管理","permalink":"https://whitetail-o.github.io/tags/%E8%89%B2%E5%BD%A9%E7%AE%A1%E7%90%86/"},{"name":"Bump Mapping","slug":"Bump-Mapping","permalink":"https://whitetail-o.github.io/tags/Bump-Mapping/"},{"name":"HLSL","slug":"HLSL","permalink":"https://whitetail-o.github.io/tags/HLSL/"},{"name":"材质","slug":"材质","permalink":"https://whitetail-o.github.io/tags/%E6%9D%90%E8%B4%A8/"},{"name":"模型","slug":"模型","permalink":"https://whitetail-o.github.io/tags/%E6%A8%A1%E5%9E%8B/"},{"name":"美术","slug":"美术","permalink":"https://whitetail-o.github.io/tags/%E7%BE%8E%E6%9C%AF/"},{"name":"动画","slug":"动画","permalink":"https://whitetail-o.github.io/tags/%E5%8A%A8%E7%94%BB/"},{"name":"数学","slug":"数学","permalink":"https://whitetail-o.github.io/tags/%E6%95%B0%E5%AD%A6/"},{"name":"NPR","slug":"NPR","permalink":"https://whitetail-o.github.io/tags/NPR/"},{"name":"GI","slug":"GI","permalink":"https://whitetail-o.github.io/tags/GI/"},{"name":"模型制作流程","slug":"模型制作流程","permalink":"https://whitetail-o.github.io/tags/%E6%A8%A1%E5%9E%8B%E5%88%B6%E4%BD%9C%E6%B5%81%E7%A8%8B/"},{"name":"美术理论","slug":"美术理论","permalink":"https://whitetail-o.github.io/tags/%E7%BE%8E%E6%9C%AF%E7%90%86%E8%AE%BA/"},{"name":"相机","slug":"相机","permalink":"https://whitetail-o.github.io/tags/%E7%9B%B8%E6%9C%BA/"},{"name":"物理","slug":"物理","permalink":"https://whitetail-o.github.io/tags/%E7%89%A9%E7%90%86/"},{"name":"IBL","slug":"IBL","permalink":"https://whitetail-o.github.io/tags/IBL/"},{"name":"Shadow","slug":"Shadow","permalink":"https://whitetail-o.github.io/tags/Shadow/"},{"name":"Games101","slug":"Games101","permalink":"https://whitetail-o.github.io/tags/Games101/"},{"name":"Animation","slug":"Animation","permalink":"https://whitetail-o.github.io/tags/Animation/"}]}